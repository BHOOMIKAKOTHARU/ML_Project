{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c862b2bf",
   "metadata": {},
   "source": [
    "# 25 persons\n",
    "## electrodes : 8, 16, 32, 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ce0f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 10:16:10.666121: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 10:16:10.702142: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-29 10:16:10.702188: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-29 10:16:10.703690: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-29 10:16:10.712088: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-29 10:16:10.713072: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 10:16:11.711419: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081a3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /usr/local/python/3.10.8/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/codespace/.local/lib/python3.10/site-packages (from mne) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.6.3 in /home/codespace/.local/lib/python3.10/site-packages (from mne) (1.11.2)\n",
      "Requirement already satisfied: matplotlib>=3.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from mne) (3.7.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.8/lib/python3.10/site-packages (from mne) (4.66.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from mne) (1.7.0)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.10/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from mne) (23.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from mne) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from pooch>=1.5->mne) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/codespace/.local/lib/python3.10/site-packages (from pooch>=1.5->mne) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->mne) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d4276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_patients=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9085fdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files/S001R03.edf',\n",
       " 'files/S002R03.edf',\n",
       " 'files/S003R03.edf',\n",
       " 'files/S004R03.edf',\n",
       " 'files/S005R03.edf',\n",
       " 'files/S006R03.edf',\n",
       " 'files/S007R03.edf',\n",
       " 'files/S008R03.edf',\n",
       " 'files/S009R03.edf',\n",
       " 'files/S010R03.edf',\n",
       " 'files/S011R03.edf',\n",
       " 'files/S012R03.edf',\n",
       " 'files/S013R03.edf',\n",
       " 'files/S014R03.edf',\n",
       " 'files/S015R03.edf',\n",
       " 'files/S016R03.edf',\n",
       " 'files/S017R03.edf',\n",
       " 'files/S018R03.edf',\n",
       " 'files/S019R03.edf',\n",
       " 'files/S020R03.edf',\n",
       " 'files/S021R03.edf',\n",
       " 'files/S022R03.edf',\n",
       " 'files/S023R03.edf',\n",
       " 'files/S024R03.edf',\n",
       " 'files/S025R03.edf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=sorted(glob('files/*.edf'))\n",
    "train=train[:no_of_patients]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddb63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(i,train_split,valid_split):\n",
    "    raw = mne.io.read_raw_edf(i, preload=True)\n",
    "    eeg_data = raw.get_data()\n",
    "    eeg_channels = [f'Channel_{i}' for i in range(eeg_data.shape[0])]\n",
    "    eeg_df = pd.DataFrame(data=eeg_data.T, columns=eeg_channels)\n",
    "    \n",
    "    eeg_df = eeg_df.iloc[:15000]\n",
    "    eeg_df.sample(frac=1)\n",
    "    \n",
    "    idx1= int(train_split*(len(eeg_df)))\n",
    "    idx2= int(train_split*(len(eeg_df)))+1\n",
    "    eeg_df1=eeg_df.iloc[:idx1]\n",
    "    eeg_df2=eeg_df.iloc[idx2:]\n",
    "    idx3=int(valid_split*(len(eeg_df2)))\n",
    "    idx4=int(valid_split*(len(eeg_df2)))+1\n",
    "    eeg_df3=eeg_df2.iloc[:idx3]\n",
    "    eeg_df4=eeg_df2.iloc[idx4:]\n",
    "    return eeg_df1,eeg_df3,eeg_df4,len(eeg_df1),len(eeg_df3),len(eeg_df4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65857e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "xtemp1=[]\n",
    "xtemp2=[]\n",
    "xtemp3=[]\n",
    "ytemp1=[]\n",
    "ytemp2=[]\n",
    "ytemp3=[]\n",
    "for i in range(no_of_patients):\n",
    "    xtr,xte,xval,ytr,yte,yval=read_data(train[i],0.8,0.5) # xtr=xtrain, xte=xtest, ytr=ytrain, yte=ytest.\n",
    "    xtemp1.append(xtr)\n",
    "    xtemp2.append(xte)\n",
    "    xtemp3.append(xval)\n",
    "    ytemp1.append(ytr)\n",
    "    ytemp2.append(yte)\n",
    "    ytemp3.append(yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aeb31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.concat([xtemp1[i] for i in range(0, len(xtemp1))], ignore_index=True)\n",
    "xtest = pd.concat([xtemp2[i] for i in range(0, len(xtemp2))], ignore_index=True)\n",
    "xvalid=pd.concat([xtemp3[i] for i in range(0,len(xtemp3))],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a47802ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=[]\n",
    "for i in range(len(ytemp1)):\n",
    "    for j in range(ytemp1[i-1]):\n",
    "        ytrain.append(i)\n",
    "ytest=[]\n",
    "for i in range(len(ytemp2)):\n",
    "    for j in range(ytemp2[i-1]):\n",
    "        ytest.append(i)        \n",
    "yvalid=[]\n",
    "for i in range(len(ytemp3)):\n",
    "    for j in range(ytemp3[i-1]):\n",
    "        yvalid.append(i)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "705fd1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 37475, 300000, 37475)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain),len(xtest),len(ytrain),len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec6d73ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.7e-05 -4.5e-05 -2.9e-05 ... -1.1e-05 -1.1e-05 -1.2e-05]\n"
     ]
    }
   ],
   "source": [
    "print(xtest.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8738bdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_0</th>\n",
       "      <th>Channel_1</th>\n",
       "      <th>Channel_2</th>\n",
       "      <th>Channel_3</th>\n",
       "      <th>Channel_4</th>\n",
       "      <th>Channel_5</th>\n",
       "      <th>Channel_6</th>\n",
       "      <th>Channel_7</th>\n",
       "      <th>Channel_8</th>\n",
       "      <th>Channel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Channel_54</th>\n",
       "      <th>Channel_55</th>\n",
       "      <th>Channel_56</th>\n",
       "      <th>Channel_57</th>\n",
       "      <th>Channel_58</th>\n",
       "      <th>Channel_59</th>\n",
       "      <th>Channel_60</th>\n",
       "      <th>Channel_61</th>\n",
       "      <th>Channel_62</th>\n",
       "      <th>Channel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Channel_0  Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  \\\n",
       "0       -0.000057  -0.000013  -0.000015  -0.000012  -0.000013  -0.000008   \n",
       "1       -0.000049  -0.000011  -0.000010  -0.000012  -0.000019  -0.000024   \n",
       "2       -0.000055  -0.000017  -0.000016  -0.000019  -0.000024  -0.000029   \n",
       "3       -0.000073  -0.000042  -0.000040  -0.000037  -0.000037  -0.000040   \n",
       "4       -0.000087  -0.000053  -0.000052  -0.000051  -0.000045  -0.000043   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "299995  -0.000005  -0.000025  -0.000043   0.000008  -0.000020  -0.000024   \n",
       "299996  -0.000013  -0.000029  -0.000046   0.000006  -0.000021  -0.000020   \n",
       "299997  -0.000021  -0.000029  -0.000045   0.000008  -0.000017  -0.000014   \n",
       "299998  -0.000003  -0.000022  -0.000039   0.000013  -0.000012  -0.000010   \n",
       "299999  -0.000013  -0.000023  -0.000037   0.000013  -0.000013  -0.000012   \n",
       "\n",
       "        Channel_6  Channel_7  Channel_8  Channel_9  ...  Channel_54  \\\n",
       "0       -0.000040  -0.000054  -0.000012  -0.000014  ...   -0.000048   \n",
       "1       -0.000058  -0.000051  -0.000019  -0.000023  ...   -0.000055   \n",
       "2       -0.000066  -0.000061  -0.000030  -0.000036  ...   -0.000054   \n",
       "3       -0.000071  -0.000078  -0.000053  -0.000053  ...   -0.000065   \n",
       "4       -0.000071  -0.000087  -0.000065  -0.000064  ...   -0.000075   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "299995  -0.000028  -0.000019  -0.000024  -0.000022  ...    0.000003   \n",
       "299996  -0.000010  -0.000026  -0.000027  -0.000025  ...    0.000001   \n",
       "299997  -0.000005  -0.000028  -0.000028  -0.000026  ...   -0.000005   \n",
       "299998  -0.000012  -0.000020  -0.000021  -0.000021  ...   -0.000005   \n",
       "299999  -0.000010  -0.000019  -0.000018  -0.000017  ...   -0.000003   \n",
       "\n",
       "        Channel_55  Channel_56  Channel_57  Channel_58  Channel_59  \\\n",
       "0        -0.000038   -0.000042   -0.000068   -0.000076   -0.000103   \n",
       "1        -0.000055   -0.000063   -0.000082   -0.000087   -0.000099   \n",
       "2        -0.000063   -0.000072   -0.000091   -0.000092   -0.000091   \n",
       "3        -0.000052   -0.000066   -0.000100   -0.000105   -0.000105   \n",
       "4        -0.000082   -0.000090   -0.000117   -0.000119   -0.000118   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "299995   -0.000007   -0.000014   -0.000004   -0.000009   -0.000003   \n",
       "299996   -0.000016   -0.000020   -0.000005   -0.000011   -0.000008   \n",
       "299997   -0.000008   -0.000015   -0.000004   -0.000011   -0.000008   \n",
       "299998   -0.000005   -0.000011    0.000001   -0.000005    0.000001   \n",
       "299999   -0.000006   -0.000011    0.000002   -0.000005   -0.000004   \n",
       "\n",
       "        Channel_60  Channel_61  Channel_62  Channel_63  \n",
       "0        -0.000051   -0.000056   -0.000124   -0.000028  \n",
       "1        -0.000059   -0.000070   -0.000149   -0.000040  \n",
       "2        -0.000067   -0.000077   -0.000153   -0.000037  \n",
       "3        -0.000067   -0.000072   -0.000148   -0.000026  \n",
       "4        -0.000075   -0.000082   -0.000161   -0.000035  \n",
       "...            ...         ...         ...         ...  \n",
       "299995    0.000001    0.000001   -0.000004    0.000005  \n",
       "299996   -0.000002   -0.000004   -0.000010   -0.000001  \n",
       "299997    0.000000   -0.000003   -0.000012    0.000000  \n",
       "299998    0.000004   -0.000001   -0.000008    0.000002  \n",
       "299999    0.000005    0.000001   -0.000005    0.000006  \n",
       "\n",
       "[300000 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "459d7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(dataframe):\n",
    "    x=dataframe.iloc[:,:-1].values\n",
    "    y=dataframe.iloc[:,-1].values\n",
    "    scaler =StandardScaler()\n",
    "    x=scaler.fit_transform(x)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabeaa2",
   "metadata": {},
   "source": [
    "## 0-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3172e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain8=xtrain.iloc[:,:8]\n",
    "xvalid8=xvalid.iloc[:,:8]\n",
    "xtest8=xtest.iloc[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "904c30f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11878/394288547.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtrain8['id']=ytrain\n",
      "/tmp/ipykernel_11878/394288547.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtest8['id']=ytest\n",
      "/tmp/ipykernel_11878/394288547.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xvalid8['id']=yvalid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_0</th>\n",
       "      <th>Channel_1</th>\n",
       "      <th>Channel_2</th>\n",
       "      <th>Channel_3</th>\n",
       "      <th>Channel_4</th>\n",
       "      <th>Channel_5</th>\n",
       "      <th>Channel_6</th>\n",
       "      <th>Channel_7</th>\n",
       "      <th>Channel_8</th>\n",
       "      <th>Channel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Channel_54</th>\n",
       "      <th>Channel_55</th>\n",
       "      <th>Channel_56</th>\n",
       "      <th>Channel_57</th>\n",
       "      <th>Channel_58</th>\n",
       "      <th>Channel_59</th>\n",
       "      <th>Channel_60</th>\n",
       "      <th>Channel_61</th>\n",
       "      <th>Channel_62</th>\n",
       "      <th>Channel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Channel_0  Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  \\\n",
       "0       -0.000057  -0.000013  -0.000015  -0.000012  -0.000013  -0.000008   \n",
       "1       -0.000049  -0.000011  -0.000010  -0.000012  -0.000019  -0.000024   \n",
       "2       -0.000055  -0.000017  -0.000016  -0.000019  -0.000024  -0.000029   \n",
       "3       -0.000073  -0.000042  -0.000040  -0.000037  -0.000037  -0.000040   \n",
       "4       -0.000087  -0.000053  -0.000052  -0.000051  -0.000045  -0.000043   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "299995  -0.000005  -0.000025  -0.000043   0.000008  -0.000020  -0.000024   \n",
       "299996  -0.000013  -0.000029  -0.000046   0.000006  -0.000021  -0.000020   \n",
       "299997  -0.000021  -0.000029  -0.000045   0.000008  -0.000017  -0.000014   \n",
       "299998  -0.000003  -0.000022  -0.000039   0.000013  -0.000012  -0.000010   \n",
       "299999  -0.000013  -0.000023  -0.000037   0.000013  -0.000013  -0.000012   \n",
       "\n",
       "        Channel_6  Channel_7  Channel_8  Channel_9  ...  Channel_54  \\\n",
       "0       -0.000040  -0.000054  -0.000012  -0.000014  ...   -0.000048   \n",
       "1       -0.000058  -0.000051  -0.000019  -0.000023  ...   -0.000055   \n",
       "2       -0.000066  -0.000061  -0.000030  -0.000036  ...   -0.000054   \n",
       "3       -0.000071  -0.000078  -0.000053  -0.000053  ...   -0.000065   \n",
       "4       -0.000071  -0.000087  -0.000065  -0.000064  ...   -0.000075   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "299995  -0.000028  -0.000019  -0.000024  -0.000022  ...    0.000003   \n",
       "299996  -0.000010  -0.000026  -0.000027  -0.000025  ...    0.000001   \n",
       "299997  -0.000005  -0.000028  -0.000028  -0.000026  ...   -0.000005   \n",
       "299998  -0.000012  -0.000020  -0.000021  -0.000021  ...   -0.000005   \n",
       "299999  -0.000010  -0.000019  -0.000018  -0.000017  ...   -0.000003   \n",
       "\n",
       "        Channel_55  Channel_56  Channel_57  Channel_58  Channel_59  \\\n",
       "0        -0.000038   -0.000042   -0.000068   -0.000076   -0.000103   \n",
       "1        -0.000055   -0.000063   -0.000082   -0.000087   -0.000099   \n",
       "2        -0.000063   -0.000072   -0.000091   -0.000092   -0.000091   \n",
       "3        -0.000052   -0.000066   -0.000100   -0.000105   -0.000105   \n",
       "4        -0.000082   -0.000090   -0.000117   -0.000119   -0.000118   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "299995   -0.000007   -0.000014   -0.000004   -0.000009   -0.000003   \n",
       "299996   -0.000016   -0.000020   -0.000005   -0.000011   -0.000008   \n",
       "299997   -0.000008   -0.000015   -0.000004   -0.000011   -0.000008   \n",
       "299998   -0.000005   -0.000011    0.000001   -0.000005    0.000001   \n",
       "299999   -0.000006   -0.000011    0.000002   -0.000005   -0.000004   \n",
       "\n",
       "        Channel_60  Channel_61  Channel_62  Channel_63  \n",
       "0        -0.000051   -0.000056   -0.000124   -0.000028  \n",
       "1        -0.000059   -0.000070   -0.000149   -0.000040  \n",
       "2        -0.000067   -0.000077   -0.000153   -0.000037  \n",
       "3        -0.000067   -0.000072   -0.000148   -0.000026  \n",
       "4        -0.000075   -0.000082   -0.000161   -0.000035  \n",
       "...            ...         ...         ...         ...  \n",
       "299995    0.000001    0.000001   -0.000004    0.000005  \n",
       "299996   -0.000002   -0.000004   -0.000010   -0.000001  \n",
       "299997    0.000000   -0.000003   -0.000012    0.000000  \n",
       "299998    0.000004   -0.000001   -0.000008    0.000002  \n",
       "299999    0.000005    0.000001   -0.000005    0.000006  \n",
       "\n",
       "[300000 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain8['id']=ytrain\n",
    "xtest8['id']=ytest\n",
    "xvalid8['id']=yvalid\n",
    "display(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b732f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x8,y8=scale_dataset(xtrain8)\n",
    "xt8,yt8=scale_dataset(xtest8)\n",
    "xv8,yv8=scale_dataset(xvalid8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.96110\n",
      "[1]\tvalidation_0-mlogloss:2.85396\n",
      "[2]\tvalidation_0-mlogloss:2.77735\n",
      "[3]\tvalidation_0-mlogloss:2.71245\n",
      "[4]\tvalidation_0-mlogloss:2.66136\n",
      "[5]\tvalidation_0-mlogloss:2.61738\n",
      "[6]\tvalidation_0-mlogloss:2.57786\n",
      "[7]\tvalidation_0-mlogloss:2.54553\n",
      "[8]\tvalidation_0-mlogloss:2.51563\n",
      "[9]\tvalidation_0-mlogloss:2.48513\n",
      "[10]\tvalidation_0-mlogloss:2.46291\n",
      "[11]\tvalidation_0-mlogloss:2.44237\n",
      "[12]\tvalidation_0-mlogloss:2.42190\n",
      "[13]\tvalidation_0-mlogloss:2.40400\n",
      "[14]\tvalidation_0-mlogloss:2.38842\n",
      "[15]\tvalidation_0-mlogloss:2.37250\n",
      "[16]\tvalidation_0-mlogloss:2.35562\n",
      "[17]\tvalidation_0-mlogloss:2.34300\n",
      "[18]\tvalidation_0-mlogloss:2.33208\n",
      "[19]\tvalidation_0-mlogloss:2.31765\n",
      "[20]\tvalidation_0-mlogloss:2.30447\n",
      "[21]\tvalidation_0-mlogloss:2.29316\n",
      "[22]\tvalidation_0-mlogloss:2.28260\n",
      "[23]\tvalidation_0-mlogloss:2.27078\n",
      "[24]\tvalidation_0-mlogloss:2.25778\n",
      "[25]\tvalidation_0-mlogloss:2.24768\n",
      "[26]\tvalidation_0-mlogloss:2.23702\n",
      "[27]\tvalidation_0-mlogloss:2.22651\n",
      "[28]\tvalidation_0-mlogloss:2.21405\n",
      "[29]\tvalidation_0-mlogloss:2.20460\n",
      "[30]\tvalidation_0-mlogloss:2.19309\n",
      "[31]\tvalidation_0-mlogloss:2.18398\n",
      "[32]\tvalidation_0-mlogloss:2.17457\n",
      "[33]\tvalidation_0-mlogloss:2.16785\n",
      "[34]\tvalidation_0-mlogloss:2.15967\n",
      "[35]\tvalidation_0-mlogloss:2.14988\n",
      "[36]\tvalidation_0-mlogloss:2.14113\n",
      "[37]\tvalidation_0-mlogloss:2.13549\n",
      "[38]\tvalidation_0-mlogloss:2.12734\n",
      "[39]\tvalidation_0-mlogloss:2.12284\n",
      "[40]\tvalidation_0-mlogloss:2.11897\n",
      "[41]\tvalidation_0-mlogloss:2.11424\n",
      "[42]\tvalidation_0-mlogloss:2.10839\n",
      "[43]\tvalidation_0-mlogloss:2.10289\n",
      "[44]\tvalidation_0-mlogloss:2.09420\n",
      "[45]\tvalidation_0-mlogloss:2.08904\n",
      "[46]\tvalidation_0-mlogloss:2.08338\n",
      "[47]\tvalidation_0-mlogloss:2.07606\n",
      "[48]\tvalidation_0-mlogloss:2.06829\n",
      "[49]\tvalidation_0-mlogloss:2.06196\n",
      "[50]\tvalidation_0-mlogloss:2.05472\n",
      "[51]\tvalidation_0-mlogloss:2.04827\n",
      "[52]\tvalidation_0-mlogloss:2.04293\n",
      "[53]\tvalidation_0-mlogloss:2.04023\n",
      "[54]\tvalidation_0-mlogloss:2.03594\n",
      "[55]\tvalidation_0-mlogloss:2.03119\n",
      "[56]\tvalidation_0-mlogloss:2.02633\n",
      "[57]\tvalidation_0-mlogloss:2.02288\n",
      "[58]\tvalidation_0-mlogloss:2.01921\n",
      "[59]\tvalidation_0-mlogloss:2.01336\n",
      "[60]\tvalidation_0-mlogloss:2.01013\n",
      "[61]\tvalidation_0-mlogloss:2.00618\n",
      "[62]\tvalidation_0-mlogloss:2.00207\n",
      "[63]\tvalidation_0-mlogloss:1.99796\n",
      "[64]\tvalidation_0-mlogloss:1.99333\n",
      "[65]\tvalidation_0-mlogloss:1.98756\n",
      "[66]\tvalidation_0-mlogloss:1.98324\n",
      "[67]\tvalidation_0-mlogloss:1.97865\n",
      "[68]\tvalidation_0-mlogloss:1.97548\n",
      "[69]\tvalidation_0-mlogloss:1.97281\n",
      "[70]\tvalidation_0-mlogloss:1.97000\n",
      "[71]\tvalidation_0-mlogloss:1.96740\n",
      "[72]\tvalidation_0-mlogloss:1.96433\n",
      "[73]\tvalidation_0-mlogloss:1.96122\n",
      "[74]\tvalidation_0-mlogloss:1.95703\n",
      "[75]\tvalidation_0-mlogloss:1.95534\n",
      "[76]\tvalidation_0-mlogloss:1.95197\n",
      "[77]\tvalidation_0-mlogloss:1.94794\n",
      "[78]\tvalidation_0-mlogloss:1.94569\n",
      "[79]\tvalidation_0-mlogloss:1.94312\n",
      "[80]\tvalidation_0-mlogloss:1.94018\n",
      "[81]\tvalidation_0-mlogloss:1.93769\n",
      "[82]\tvalidation_0-mlogloss:1.93516\n",
      "[83]\tvalidation_0-mlogloss:1.93285\n",
      "[84]\tvalidation_0-mlogloss:1.93043\n",
      "[85]\tvalidation_0-mlogloss:1.92700\n",
      "[86]\tvalidation_0-mlogloss:1.92505\n",
      "[87]\tvalidation_0-mlogloss:1.92159\n",
      "[88]\tvalidation_0-mlogloss:1.91854\n",
      "[89]\tvalidation_0-mlogloss:1.91588\n",
      "[90]\tvalidation_0-mlogloss:1.91389\n",
      "[91]\tvalidation_0-mlogloss:1.91089\n",
      "[92]\tvalidation_0-mlogloss:1.90862\n",
      "[93]\tvalidation_0-mlogloss:1.90728\n",
      "[94]\tvalidation_0-mlogloss:1.90505\n",
      "[95]\tvalidation_0-mlogloss:1.90252\n",
      "[96]\tvalidation_0-mlogloss:1.90020\n",
      "[97]\tvalidation_0-mlogloss:1.89762\n",
      "[98]\tvalidation_0-mlogloss:1.89645\n",
      "[99]\tvalidation_0-mlogloss:1.89496\n",
      "[100]\tvalidation_0-mlogloss:1.89190\n",
      "[101]\tvalidation_0-mlogloss:1.88989\n",
      "[102]\tvalidation_0-mlogloss:1.88710\n",
      "[103]\tvalidation_0-mlogloss:1.88537\n",
      "[104]\tvalidation_0-mlogloss:1.88224\n",
      "[105]\tvalidation_0-mlogloss:1.87929\n",
      "[106]\tvalidation_0-mlogloss:1.87620\n",
      "[107]\tvalidation_0-mlogloss:1.87447\n",
      "[108]\tvalidation_0-mlogloss:1.87245\n",
      "[109]\tvalidation_0-mlogloss:1.87068\n",
      "[110]\tvalidation_0-mlogloss:1.86863\n",
      "[111]\tvalidation_0-mlogloss:1.86553\n",
      "[112]\tvalidation_0-mlogloss:1.86274\n",
      "[113]\tvalidation_0-mlogloss:1.86066\n",
      "[114]\tvalidation_0-mlogloss:1.85833\n",
      "[115]\tvalidation_0-mlogloss:1.85652\n",
      "[116]\tvalidation_0-mlogloss:1.85404\n",
      "[117]\tvalidation_0-mlogloss:1.85254\n",
      "[118]\tvalidation_0-mlogloss:1.84983\n",
      "[119]\tvalidation_0-mlogloss:1.84837\n",
      "[120]\tvalidation_0-mlogloss:1.84642\n",
      "[121]\tvalidation_0-mlogloss:1.84385\n",
      "[122]\tvalidation_0-mlogloss:1.84272\n",
      "[123]\tvalidation_0-mlogloss:1.84060\n",
      "[124]\tvalidation_0-mlogloss:1.83847\n",
      "[125]\tvalidation_0-mlogloss:1.83650\n",
      "[126]\tvalidation_0-mlogloss:1.83457\n",
      "[127]\tvalidation_0-mlogloss:1.83250\n",
      "[128]\tvalidation_0-mlogloss:1.83099\n",
      "[129]\tvalidation_0-mlogloss:1.82858\n",
      "[130]\tvalidation_0-mlogloss:1.82760\n",
      "[131]\tvalidation_0-mlogloss:1.82571\n",
      "[132]\tvalidation_0-mlogloss:1.82429\n",
      "[133]\tvalidation_0-mlogloss:1.82236\n",
      "[134]\tvalidation_0-mlogloss:1.82109\n",
      "[135]\tvalidation_0-mlogloss:1.82031\n",
      "[136]\tvalidation_0-mlogloss:1.81938\n",
      "[137]\tvalidation_0-mlogloss:1.81761\n",
      "[138]\tvalidation_0-mlogloss:1.81651\n",
      "[139]\tvalidation_0-mlogloss:1.81591\n",
      "[140]\tvalidation_0-mlogloss:1.81400\n",
      "[141]\tvalidation_0-mlogloss:1.81280\n",
      "[142]\tvalidation_0-mlogloss:1.81146\n",
      "[143]\tvalidation_0-mlogloss:1.81027\n",
      "[144]\tvalidation_0-mlogloss:1.80980\n",
      "[145]\tvalidation_0-mlogloss:1.80848\n",
      "[146]\tvalidation_0-mlogloss:1.80709\n",
      "[147]\tvalidation_0-mlogloss:1.80599\n",
      "[148]\tvalidation_0-mlogloss:1.80494\n",
      "[149]\tvalidation_0-mlogloss:1.80342\n",
      "[150]\tvalidation_0-mlogloss:1.80214\n",
      "[151]\tvalidation_0-mlogloss:1.80108\n",
      "[152]\tvalidation_0-mlogloss:1.80027\n",
      "[153]\tvalidation_0-mlogloss:1.79888\n",
      "[154]\tvalidation_0-mlogloss:1.79788\n",
      "[155]\tvalidation_0-mlogloss:1.79670\n",
      "[156]\tvalidation_0-mlogloss:1.79611\n",
      "[157]\tvalidation_0-mlogloss:1.79542\n",
      "[158]\tvalidation_0-mlogloss:1.79335\n",
      "[159]\tvalidation_0-mlogloss:1.79143\n",
      "[160]\tvalidation_0-mlogloss:1.79049\n",
      "[161]\tvalidation_0-mlogloss:1.78967\n",
      "[162]\tvalidation_0-mlogloss:1.78808\n",
      "[163]\tvalidation_0-mlogloss:1.78790\n",
      "[164]\tvalidation_0-mlogloss:1.78740\n",
      "[165]\tvalidation_0-mlogloss:1.78610\n",
      "[166]\tvalidation_0-mlogloss:1.78422\n",
      "[167]\tvalidation_0-mlogloss:1.78267\n",
      "[168]\tvalidation_0-mlogloss:1.78237\n",
      "[169]\tvalidation_0-mlogloss:1.78194\n",
      "[170]\tvalidation_0-mlogloss:1.78060\n",
      "[171]\tvalidation_0-mlogloss:1.77989\n",
      "[172]\tvalidation_0-mlogloss:1.77951\n",
      "[173]\tvalidation_0-mlogloss:1.77856\n",
      "[174]\tvalidation_0-mlogloss:1.77834\n",
      "[175]\tvalidation_0-mlogloss:1.77730\n",
      "[176]\tvalidation_0-mlogloss:1.77705\n",
      "[177]\tvalidation_0-mlogloss:1.77644\n",
      "[178]\tvalidation_0-mlogloss:1.77490\n",
      "[179]\tvalidation_0-mlogloss:1.77387\n",
      "[180]\tvalidation_0-mlogloss:1.77369\n",
      "[181]\tvalidation_0-mlogloss:1.77287\n",
      "[182]\tvalidation_0-mlogloss:1.77145\n",
      "[183]\tvalidation_0-mlogloss:1.77074\n",
      "[184]\tvalidation_0-mlogloss:1.77008\n",
      "[185]\tvalidation_0-mlogloss:1.76966\n",
      "[186]\tvalidation_0-mlogloss:1.76925\n",
      "[187]\tvalidation_0-mlogloss:1.76879\n",
      "[188]\tvalidation_0-mlogloss:1.76807\n",
      "[189]\tvalidation_0-mlogloss:1.76747\n",
      "[190]\tvalidation_0-mlogloss:1.76698\n",
      "[191]\tvalidation_0-mlogloss:1.76634\n",
      "[192]\tvalidation_0-mlogloss:1.76565\n",
      "[193]\tvalidation_0-mlogloss:1.76458\n",
      "[194]\tvalidation_0-mlogloss:1.76417\n",
      "[195]\tvalidation_0-mlogloss:1.76306\n",
      "[196]\tvalidation_0-mlogloss:1.76255\n",
      "[197]\tvalidation_0-mlogloss:1.76208\n",
      "[198]\tvalidation_0-mlogloss:1.76221\n",
      "[199]\tvalidation_0-mlogloss:1.76179\n",
      "[200]\tvalidation_0-mlogloss:1.76112\n",
      "[201]\tvalidation_0-mlogloss:1.76098\n",
      "[202]\tvalidation_0-mlogloss:1.76096\n",
      "[203]\tvalidation_0-mlogloss:1.76027\n",
      "[204]\tvalidation_0-mlogloss:1.75935\n",
      "[205]\tvalidation_0-mlogloss:1.75875\n",
      "[206]\tvalidation_0-mlogloss:1.75812\n",
      "[207]\tvalidation_0-mlogloss:1.75783\n",
      "[208]\tvalidation_0-mlogloss:1.75736\n",
      "[209]\tvalidation_0-mlogloss:1.75698\n",
      "[210]\tvalidation_0-mlogloss:1.75659\n",
      "[211]\tvalidation_0-mlogloss:1.75605\n",
      "[212]\tvalidation_0-mlogloss:1.75559\n",
      "[213]\tvalidation_0-mlogloss:1.75492\n",
      "[214]\tvalidation_0-mlogloss:1.75403\n",
      "[215]\tvalidation_0-mlogloss:1.75347\n",
      "[216]\tvalidation_0-mlogloss:1.75198\n",
      "[217]\tvalidation_0-mlogloss:1.75131\n",
      "[218]\tvalidation_0-mlogloss:1.75128\n",
      "[219]\tvalidation_0-mlogloss:1.75129\n",
      "[220]\tvalidation_0-mlogloss:1.75093\n",
      "[221]\tvalidation_0-mlogloss:1.75096\n",
      "[222]\tvalidation_0-mlogloss:1.75085\n",
      "[223]\tvalidation_0-mlogloss:1.75048\n",
      "[224]\tvalidation_0-mlogloss:1.75003\n",
      "[225]\tvalidation_0-mlogloss:1.74880\n",
      "[226]\tvalidation_0-mlogloss:1.74854\n",
      "[227]\tvalidation_0-mlogloss:1.74836\n",
      "[228]\tvalidation_0-mlogloss:1.74785\n",
      "[229]\tvalidation_0-mlogloss:1.74727\n",
      "[230]\tvalidation_0-mlogloss:1.74677\n",
      "[231]\tvalidation_0-mlogloss:1.74728\n",
      "[232]\tvalidation_0-mlogloss:1.74739\n",
      "[233]\tvalidation_0-mlogloss:1.74667\n",
      "[234]\tvalidation_0-mlogloss:1.74630\n",
      "[235]\tvalidation_0-mlogloss:1.74620\n",
      "[236]\tvalidation_0-mlogloss:1.74559\n",
      "[237]\tvalidation_0-mlogloss:1.74520\n",
      "[238]\tvalidation_0-mlogloss:1.74476\n",
      "[239]\tvalidation_0-mlogloss:1.74422\n",
      "[240]\tvalidation_0-mlogloss:1.74337\n",
      "[241]\tvalidation_0-mlogloss:1.74357\n",
      "[242]\tvalidation_0-mlogloss:1.74282\n",
      "[243]\tvalidation_0-mlogloss:1.74214\n",
      "[244]\tvalidation_0-mlogloss:1.74202\n",
      "[245]\tvalidation_0-mlogloss:1.74156\n",
      "[246]\tvalidation_0-mlogloss:1.74098\n",
      "[247]\tvalidation_0-mlogloss:1.73964\n",
      "[248]\tvalidation_0-mlogloss:1.73983\n",
      "[249]\tvalidation_0-mlogloss:1.73954\n",
      "[250]\tvalidation_0-mlogloss:1.73956\n",
      "[251]\tvalidation_0-mlogloss:1.73999\n",
      "[252]\tvalidation_0-mlogloss:1.74006\n",
      "[253]\tvalidation_0-mlogloss:1.73948\n",
      "[254]\tvalidation_0-mlogloss:1.73932\n",
      "[255]\tvalidation_0-mlogloss:1.73914\n",
      "[256]\tvalidation_0-mlogloss:1.73915\n",
      "[257]\tvalidation_0-mlogloss:1.73894\n",
      "[258]\tvalidation_0-mlogloss:1.73843\n",
      "[259]\tvalidation_0-mlogloss:1.73813\n",
      "[260]\tvalidation_0-mlogloss:1.73810\n",
      "[261]\tvalidation_0-mlogloss:1.73737\n",
      "[262]\tvalidation_0-mlogloss:1.73645\n",
      "[263]\tvalidation_0-mlogloss:1.73647\n",
      "[264]\tvalidation_0-mlogloss:1.73676\n",
      "[265]\tvalidation_0-mlogloss:1.73696\n",
      "[266]\tvalidation_0-mlogloss:1.73686\n",
      "[267]\tvalidation_0-mlogloss:1.73668\n",
      "[268]\tvalidation_0-mlogloss:1.73689\n",
      "[269]\tvalidation_0-mlogloss:1.73681\n",
      "[270]\tvalidation_0-mlogloss:1.73666\n",
      "[271]\tvalidation_0-mlogloss:1.73653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.27      0.28      1499\n",
      "           1       0.28      0.32      0.30      1499\n",
      "           2       0.44      0.37      0.40      1499\n",
      "           3       0.59      0.63      0.61      1499\n",
      "           4       0.71      0.72      0.71      1499\n",
      "           5       0.39      0.57      0.46      1499\n",
      "           6       0.46      0.34      0.39      1499\n",
      "           7       0.57      0.41      0.48      1499\n",
      "           8       0.51      0.70      0.59      1499\n",
      "           9       0.71      0.61      0.65      1499\n",
      "          10       0.32      0.30      0.31      1499\n",
      "          11       0.21      0.23      0.22      1499\n",
      "          12       0.49      0.35      0.41      1499\n",
      "          13       0.23      0.17      0.20      1499\n",
      "          14       0.31      0.23      0.26      1499\n",
      "          15       0.43      0.27      0.33      1499\n",
      "          16       0.32      0.17      0.22      1499\n",
      "          17       0.53      0.68      0.59      1499\n",
      "          18       0.23      0.24      0.24      1499\n",
      "          19       0.36      0.51      0.42      1499\n",
      "          20       0.63      0.86      0.73      1499\n",
      "          21       0.66      0.62      0.64      1499\n",
      "          22       0.23      0.24      0.24      1499\n",
      "          23       0.57      0.64      0.60      1499\n",
      "          24       0.65      0.84      0.73      1499\n",
      "\n",
      "    accuracy                           0.45     37475\n",
      "   macro avg       0.44      0.45      0.44     37475\n",
      "weighted avg       0.44      0.45      0.44     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=XGBClassifier(n_estimators=500)\n",
    "model.fit(x8,y8,early_stopping_rounds=10, eval_set=[(xv8, yv8)])\n",
    "y_pred=model.predict(xt8)\n",
    "print(classification_report(yt8,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b271d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(8, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(25, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aee87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 1.8391 - val_loss: 1.9462\n",
      "Epoch 2/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 1.4581 - val_loss: 1.9352\n",
      "Epoch 3/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 1.3045 - val_loss: 1.7063\n",
      "Epoch 4/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 1.1785 - val_loss: 1.7581\n",
      "Epoch 5/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 1.1359 - val_loss: 1.8647\n",
      "Epoch 6/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 1.1074 - val_loss: 1.8822\n",
      "Epoch 7/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 1.0904 - val_loss: 1.9826\n",
      "Epoch 8/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 1.0737 - val_loss: 1.8391\n",
      "Epoch 9/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 1.0607 - val_loss: 1.9776\n",
      "Epoch 10/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 1.0497 - val_loss: 1.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f16c86c2b60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x8,y8,epochs=10,validation_data=(xv8,yv8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "badca670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 186/1172 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 801us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.25      0.28      1499\n",
      "           1       0.27      0.41      0.32      1499\n",
      "           2       0.38      0.50      0.43      1499\n",
      "           3       0.61      0.82      0.70      1499\n",
      "           4       0.75      0.68      0.71      1499\n",
      "           5       0.39      0.53      0.45      1499\n",
      "           6       0.45      0.17      0.25      1499\n",
      "           7       0.53      0.35      0.42      1499\n",
      "           8       0.45      0.78      0.57      1499\n",
      "           9       0.67      0.65      0.66      1499\n",
      "          10       0.28      0.24      0.26      1499\n",
      "          11       0.22      0.32      0.26      1499\n",
      "          12       0.47      0.29      0.36      1499\n",
      "          13       0.22      0.28      0.25      1499\n",
      "          14       0.33      0.22      0.27      1499\n",
      "          15       0.44      0.22      0.29      1499\n",
      "          16       0.19      0.07      0.11      1499\n",
      "          17       0.68      0.33      0.45      1499\n",
      "          18       0.26      0.20      0.23      1499\n",
      "          19       0.34      0.34      0.34      1499\n",
      "          20       0.61      0.82      0.70      1499\n",
      "          21       0.69      0.59      0.63      1499\n",
      "          22       0.21      0.33      0.26      1499\n",
      "          23       0.56      0.69      0.62      1499\n",
      "          24       0.62      0.65      0.64      1499\n",
      "\n",
      "    accuracy                           0.43     37475\n",
      "   macro avg       0.44      0.43      0.42     37475\n",
      "weighted avg       0.44      0.43      0.42     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model.predict(xt8)).numpy(),axis=1)\n",
    "print(classification_report(yt8,y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d7d010",
   "metadata": {},
   "source": [
    "## 0-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "268bff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain16=xtrain.iloc[:,:16]\n",
    "xtest16=xtest.iloc[:,:16]\n",
    "xvalid16=xvalid.iloc[:,:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "000e1a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11878/4039718790.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtrain16['id']=ytrain\n",
      "/tmp/ipykernel_11878/4039718790.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtest16['id']=ytest\n",
      "/tmp/ipykernel_11878/4039718790.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xvalid16['id']=yvalid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_0</th>\n",
       "      <th>Channel_1</th>\n",
       "      <th>Channel_2</th>\n",
       "      <th>Channel_3</th>\n",
       "      <th>Channel_4</th>\n",
       "      <th>Channel_5</th>\n",
       "      <th>Channel_6</th>\n",
       "      <th>Channel_7</th>\n",
       "      <th>Channel_8</th>\n",
       "      <th>Channel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Channel_54</th>\n",
       "      <th>Channel_55</th>\n",
       "      <th>Channel_56</th>\n",
       "      <th>Channel_57</th>\n",
       "      <th>Channel_58</th>\n",
       "      <th>Channel_59</th>\n",
       "      <th>Channel_60</th>\n",
       "      <th>Channel_61</th>\n",
       "      <th>Channel_62</th>\n",
       "      <th>Channel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Channel_0  Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  \\\n",
       "0       -0.000057  -0.000013  -0.000015  -0.000012  -0.000013  -0.000008   \n",
       "1       -0.000049  -0.000011  -0.000010  -0.000012  -0.000019  -0.000024   \n",
       "2       -0.000055  -0.000017  -0.000016  -0.000019  -0.000024  -0.000029   \n",
       "3       -0.000073  -0.000042  -0.000040  -0.000037  -0.000037  -0.000040   \n",
       "4       -0.000087  -0.000053  -0.000052  -0.000051  -0.000045  -0.000043   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "299995  -0.000005  -0.000025  -0.000043   0.000008  -0.000020  -0.000024   \n",
       "299996  -0.000013  -0.000029  -0.000046   0.000006  -0.000021  -0.000020   \n",
       "299997  -0.000021  -0.000029  -0.000045   0.000008  -0.000017  -0.000014   \n",
       "299998  -0.000003  -0.000022  -0.000039   0.000013  -0.000012  -0.000010   \n",
       "299999  -0.000013  -0.000023  -0.000037   0.000013  -0.000013  -0.000012   \n",
       "\n",
       "        Channel_6  Channel_7  Channel_8  Channel_9  ...  Channel_54  \\\n",
       "0       -0.000040  -0.000054  -0.000012  -0.000014  ...   -0.000048   \n",
       "1       -0.000058  -0.000051  -0.000019  -0.000023  ...   -0.000055   \n",
       "2       -0.000066  -0.000061  -0.000030  -0.000036  ...   -0.000054   \n",
       "3       -0.000071  -0.000078  -0.000053  -0.000053  ...   -0.000065   \n",
       "4       -0.000071  -0.000087  -0.000065  -0.000064  ...   -0.000075   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "299995  -0.000028  -0.000019  -0.000024  -0.000022  ...    0.000003   \n",
       "299996  -0.000010  -0.000026  -0.000027  -0.000025  ...    0.000001   \n",
       "299997  -0.000005  -0.000028  -0.000028  -0.000026  ...   -0.000005   \n",
       "299998  -0.000012  -0.000020  -0.000021  -0.000021  ...   -0.000005   \n",
       "299999  -0.000010  -0.000019  -0.000018  -0.000017  ...   -0.000003   \n",
       "\n",
       "        Channel_55  Channel_56  Channel_57  Channel_58  Channel_59  \\\n",
       "0        -0.000038   -0.000042   -0.000068   -0.000076   -0.000103   \n",
       "1        -0.000055   -0.000063   -0.000082   -0.000087   -0.000099   \n",
       "2        -0.000063   -0.000072   -0.000091   -0.000092   -0.000091   \n",
       "3        -0.000052   -0.000066   -0.000100   -0.000105   -0.000105   \n",
       "4        -0.000082   -0.000090   -0.000117   -0.000119   -0.000118   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "299995   -0.000007   -0.000014   -0.000004   -0.000009   -0.000003   \n",
       "299996   -0.000016   -0.000020   -0.000005   -0.000011   -0.000008   \n",
       "299997   -0.000008   -0.000015   -0.000004   -0.000011   -0.000008   \n",
       "299998   -0.000005   -0.000011    0.000001   -0.000005    0.000001   \n",
       "299999   -0.000006   -0.000011    0.000002   -0.000005   -0.000004   \n",
       "\n",
       "        Channel_60  Channel_61  Channel_62  Channel_63  \n",
       "0        -0.000051   -0.000056   -0.000124   -0.000028  \n",
       "1        -0.000059   -0.000070   -0.000149   -0.000040  \n",
       "2        -0.000067   -0.000077   -0.000153   -0.000037  \n",
       "3        -0.000067   -0.000072   -0.000148   -0.000026  \n",
       "4        -0.000075   -0.000082   -0.000161   -0.000035  \n",
       "...            ...         ...         ...         ...  \n",
       "299995    0.000001    0.000001   -0.000004    0.000005  \n",
       "299996   -0.000002   -0.000004   -0.000010   -0.000001  \n",
       "299997    0.000000   -0.000003   -0.000012    0.000000  \n",
       "299998    0.000004   -0.000001   -0.000008    0.000002  \n",
       "299999    0.000005    0.000001   -0.000005    0.000006  \n",
       "\n",
       "[300000 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain16['id']=ytrain\n",
    "xtest16['id']=ytest\n",
    "xvalid16['id']=yvalid\n",
    "display(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03b98fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x16,y16=scale_dataset(xtrain16)\n",
    "xt16,yt16=scale_dataset(xtest16)\n",
    "xv16,yv16=scale_dataset(xvalid16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.91459\n",
      "[1]\tvalidation_0-mlogloss:2.76978\n",
      "[2]\tvalidation_0-mlogloss:2.67245\n",
      "[3]\tvalidation_0-mlogloss:2.59598\n",
      "[4]\tvalidation_0-mlogloss:2.53259\n",
      "[5]\tvalidation_0-mlogloss:2.47844\n",
      "[6]\tvalidation_0-mlogloss:2.43092\n",
      "[7]\tvalidation_0-mlogloss:2.38483\n",
      "[8]\tvalidation_0-mlogloss:2.34447\n",
      "[9]\tvalidation_0-mlogloss:2.30765\n",
      "[10]\tvalidation_0-mlogloss:2.28139\n",
      "[11]\tvalidation_0-mlogloss:2.25515\n",
      "[12]\tvalidation_0-mlogloss:2.22975\n",
      "[13]\tvalidation_0-mlogloss:2.20087\n",
      "[14]\tvalidation_0-mlogloss:2.17669\n",
      "[15]\tvalidation_0-mlogloss:2.15359\n",
      "[16]\tvalidation_0-mlogloss:2.13052\n",
      "[17]\tvalidation_0-mlogloss:2.11277\n",
      "[18]\tvalidation_0-mlogloss:2.09711\n",
      "[19]\tvalidation_0-mlogloss:2.08169\n",
      "[20]\tvalidation_0-mlogloss:2.06526\n",
      "[21]\tvalidation_0-mlogloss:2.04576\n",
      "[22]\tvalidation_0-mlogloss:2.03038\n",
      "[23]\tvalidation_0-mlogloss:2.01305\n",
      "[24]\tvalidation_0-mlogloss:2.00159\n",
      "[25]\tvalidation_0-mlogloss:1.98977\n",
      "[26]\tvalidation_0-mlogloss:1.97729\n",
      "[27]\tvalidation_0-mlogloss:1.96178\n",
      "[28]\tvalidation_0-mlogloss:1.94926\n",
      "[29]\tvalidation_0-mlogloss:1.93339\n",
      "[30]\tvalidation_0-mlogloss:1.92106\n",
      "[31]\tvalidation_0-mlogloss:1.90997\n",
      "[32]\tvalidation_0-mlogloss:1.89608\n",
      "[33]\tvalidation_0-mlogloss:1.88303\n",
      "[34]\tvalidation_0-mlogloss:1.87209\n",
      "[35]\tvalidation_0-mlogloss:1.86217\n",
      "[36]\tvalidation_0-mlogloss:1.85275\n",
      "[37]\tvalidation_0-mlogloss:1.84365\n",
      "[38]\tvalidation_0-mlogloss:1.83290\n",
      "[39]\tvalidation_0-mlogloss:1.82432\n",
      "[40]\tvalidation_0-mlogloss:1.81430\n",
      "[41]\tvalidation_0-mlogloss:1.80486\n",
      "[42]\tvalidation_0-mlogloss:1.79564\n",
      "[43]\tvalidation_0-mlogloss:1.78632\n",
      "[44]\tvalidation_0-mlogloss:1.77690\n",
      "[45]\tvalidation_0-mlogloss:1.76970\n",
      "[46]\tvalidation_0-mlogloss:1.76062\n",
      "[47]\tvalidation_0-mlogloss:1.75304\n",
      "[48]\tvalidation_0-mlogloss:1.74586\n",
      "[49]\tvalidation_0-mlogloss:1.73813\n",
      "[50]\tvalidation_0-mlogloss:1.72987\n",
      "[51]\tvalidation_0-mlogloss:1.72150\n",
      "[52]\tvalidation_0-mlogloss:1.71456\n",
      "[53]\tvalidation_0-mlogloss:1.70852\n",
      "[54]\tvalidation_0-mlogloss:1.70296\n",
      "[55]\tvalidation_0-mlogloss:1.69526\n",
      "[56]\tvalidation_0-mlogloss:1.69040\n",
      "[57]\tvalidation_0-mlogloss:1.68438\n",
      "[58]\tvalidation_0-mlogloss:1.67860\n",
      "[59]\tvalidation_0-mlogloss:1.67320\n",
      "[60]\tvalidation_0-mlogloss:1.66654\n",
      "[61]\tvalidation_0-mlogloss:1.65886\n",
      "[62]\tvalidation_0-mlogloss:1.65248\n",
      "[63]\tvalidation_0-mlogloss:1.64645\n",
      "[64]\tvalidation_0-mlogloss:1.64061\n",
      "[65]\tvalidation_0-mlogloss:1.63297\n",
      "[66]\tvalidation_0-mlogloss:1.62551\n",
      "[67]\tvalidation_0-mlogloss:1.62090\n",
      "[68]\tvalidation_0-mlogloss:1.61555\n",
      "[69]\tvalidation_0-mlogloss:1.61001\n",
      "[70]\tvalidation_0-mlogloss:1.60650\n",
      "[71]\tvalidation_0-mlogloss:1.60066\n",
      "[72]\tvalidation_0-mlogloss:1.59655\n",
      "[73]\tvalidation_0-mlogloss:1.59017\n",
      "[74]\tvalidation_0-mlogloss:1.58481\n",
      "[75]\tvalidation_0-mlogloss:1.57950\n",
      "[76]\tvalidation_0-mlogloss:1.57543\n",
      "[77]\tvalidation_0-mlogloss:1.57173\n",
      "[78]\tvalidation_0-mlogloss:1.56795\n",
      "[79]\tvalidation_0-mlogloss:1.56621\n",
      "[80]\tvalidation_0-mlogloss:1.56233\n",
      "[81]\tvalidation_0-mlogloss:1.55785\n",
      "[82]\tvalidation_0-mlogloss:1.55299\n",
      "[83]\tvalidation_0-mlogloss:1.54988\n",
      "[84]\tvalidation_0-mlogloss:1.54632\n",
      "[85]\tvalidation_0-mlogloss:1.54183\n",
      "[86]\tvalidation_0-mlogloss:1.53754\n",
      "[87]\tvalidation_0-mlogloss:1.53442\n",
      "[88]\tvalidation_0-mlogloss:1.53102\n",
      "[89]\tvalidation_0-mlogloss:1.52682\n",
      "[90]\tvalidation_0-mlogloss:1.52410\n",
      "[91]\tvalidation_0-mlogloss:1.52086\n",
      "[92]\tvalidation_0-mlogloss:1.51887\n",
      "[93]\tvalidation_0-mlogloss:1.51751\n",
      "[94]\tvalidation_0-mlogloss:1.51560\n",
      "[95]\tvalidation_0-mlogloss:1.51341\n",
      "[96]\tvalidation_0-mlogloss:1.51111\n",
      "[97]\tvalidation_0-mlogloss:1.50705\n",
      "[98]\tvalidation_0-mlogloss:1.50431\n",
      "[99]\tvalidation_0-mlogloss:1.50221\n",
      "[100]\tvalidation_0-mlogloss:1.49952\n",
      "[101]\tvalidation_0-mlogloss:1.49611\n",
      "[102]\tvalidation_0-mlogloss:1.49408\n",
      "[103]\tvalidation_0-mlogloss:1.49121\n",
      "[104]\tvalidation_0-mlogloss:1.48799\n",
      "[105]\tvalidation_0-mlogloss:1.48731\n",
      "[106]\tvalidation_0-mlogloss:1.48513\n",
      "[107]\tvalidation_0-mlogloss:1.48099\n",
      "[108]\tvalidation_0-mlogloss:1.47796\n",
      "[109]\tvalidation_0-mlogloss:1.47590\n",
      "[110]\tvalidation_0-mlogloss:1.47314\n",
      "[111]\tvalidation_0-mlogloss:1.47089\n",
      "[112]\tvalidation_0-mlogloss:1.46786\n",
      "[113]\tvalidation_0-mlogloss:1.46582\n",
      "[114]\tvalidation_0-mlogloss:1.46370\n",
      "[115]\tvalidation_0-mlogloss:1.46129\n",
      "[116]\tvalidation_0-mlogloss:1.46029\n",
      "[117]\tvalidation_0-mlogloss:1.45864\n",
      "[118]\tvalidation_0-mlogloss:1.45528\n",
      "[119]\tvalidation_0-mlogloss:1.45173\n",
      "[120]\tvalidation_0-mlogloss:1.45020\n",
      "[121]\tvalidation_0-mlogloss:1.44743\n",
      "[122]\tvalidation_0-mlogloss:1.44469\n",
      "[123]\tvalidation_0-mlogloss:1.44288\n",
      "[124]\tvalidation_0-mlogloss:1.44082\n",
      "[125]\tvalidation_0-mlogloss:1.43924\n",
      "[126]\tvalidation_0-mlogloss:1.43628\n",
      "[127]\tvalidation_0-mlogloss:1.43416\n",
      "[128]\tvalidation_0-mlogloss:1.43349\n",
      "[129]\tvalidation_0-mlogloss:1.43100\n",
      "[130]\tvalidation_0-mlogloss:1.43009\n",
      "[131]\tvalidation_0-mlogloss:1.42860\n",
      "[132]\tvalidation_0-mlogloss:1.42746\n",
      "[133]\tvalidation_0-mlogloss:1.42519\n",
      "[134]\tvalidation_0-mlogloss:1.42301\n",
      "[135]\tvalidation_0-mlogloss:1.42155\n",
      "[136]\tvalidation_0-mlogloss:1.41980\n",
      "[137]\tvalidation_0-mlogloss:1.41777\n",
      "[138]\tvalidation_0-mlogloss:1.41611\n",
      "[139]\tvalidation_0-mlogloss:1.41481\n",
      "[140]\tvalidation_0-mlogloss:1.41272\n",
      "[141]\tvalidation_0-mlogloss:1.41035\n",
      "[142]\tvalidation_0-mlogloss:1.40873\n",
      "[143]\tvalidation_0-mlogloss:1.40646\n",
      "[144]\tvalidation_0-mlogloss:1.40605\n",
      "[145]\tvalidation_0-mlogloss:1.40521\n",
      "[146]\tvalidation_0-mlogloss:1.40296\n",
      "[147]\tvalidation_0-mlogloss:1.40266\n",
      "[148]\tvalidation_0-mlogloss:1.40158\n",
      "[149]\tvalidation_0-mlogloss:1.39949\n",
      "[150]\tvalidation_0-mlogloss:1.39878\n",
      "[151]\tvalidation_0-mlogloss:1.39701\n",
      "[152]\tvalidation_0-mlogloss:1.39515\n",
      "[153]\tvalidation_0-mlogloss:1.39398\n",
      "[154]\tvalidation_0-mlogloss:1.39189\n",
      "[155]\tvalidation_0-mlogloss:1.39053\n",
      "[156]\tvalidation_0-mlogloss:1.38969\n",
      "[157]\tvalidation_0-mlogloss:1.38745\n",
      "[158]\tvalidation_0-mlogloss:1.38662\n",
      "[159]\tvalidation_0-mlogloss:1.38485\n",
      "[160]\tvalidation_0-mlogloss:1.38338\n",
      "[161]\tvalidation_0-mlogloss:1.38219\n",
      "[162]\tvalidation_0-mlogloss:1.38098\n",
      "[163]\tvalidation_0-mlogloss:1.38038\n",
      "[164]\tvalidation_0-mlogloss:1.37992\n",
      "[165]\tvalidation_0-mlogloss:1.37954\n",
      "[166]\tvalidation_0-mlogloss:1.37804\n",
      "[167]\tvalidation_0-mlogloss:1.37662\n",
      "[168]\tvalidation_0-mlogloss:1.37550\n",
      "[169]\tvalidation_0-mlogloss:1.37358\n",
      "[170]\tvalidation_0-mlogloss:1.37239\n",
      "[171]\tvalidation_0-mlogloss:1.37135\n",
      "[172]\tvalidation_0-mlogloss:1.37087\n",
      "[173]\tvalidation_0-mlogloss:1.36932\n",
      "[174]\tvalidation_0-mlogloss:1.36821\n",
      "[175]\tvalidation_0-mlogloss:1.36672\n",
      "[176]\tvalidation_0-mlogloss:1.36559\n",
      "[177]\tvalidation_0-mlogloss:1.36461\n",
      "[178]\tvalidation_0-mlogloss:1.36366\n",
      "[179]\tvalidation_0-mlogloss:1.36271\n",
      "[180]\tvalidation_0-mlogloss:1.36187\n",
      "[181]\tvalidation_0-mlogloss:1.36170\n",
      "[182]\tvalidation_0-mlogloss:1.36179\n",
      "[183]\tvalidation_0-mlogloss:1.36162\n",
      "[184]\tvalidation_0-mlogloss:1.36124\n",
      "[185]\tvalidation_0-mlogloss:1.36040\n",
      "[186]\tvalidation_0-mlogloss:1.35970\n",
      "[187]\tvalidation_0-mlogloss:1.35851\n",
      "[188]\tvalidation_0-mlogloss:1.35909\n",
      "[189]\tvalidation_0-mlogloss:1.35872\n",
      "[190]\tvalidation_0-mlogloss:1.35759\n",
      "[191]\tvalidation_0-mlogloss:1.35678\n",
      "[192]\tvalidation_0-mlogloss:1.35558\n",
      "[193]\tvalidation_0-mlogloss:1.35509\n",
      "[194]\tvalidation_0-mlogloss:1.35457\n",
      "[195]\tvalidation_0-mlogloss:1.35466\n",
      "[196]\tvalidation_0-mlogloss:1.35452\n",
      "[197]\tvalidation_0-mlogloss:1.35369\n",
      "[198]\tvalidation_0-mlogloss:1.35256\n",
      "[199]\tvalidation_0-mlogloss:1.35202\n",
      "[200]\tvalidation_0-mlogloss:1.35173\n",
      "[201]\tvalidation_0-mlogloss:1.35086\n",
      "[202]\tvalidation_0-mlogloss:1.34990\n",
      "[203]\tvalidation_0-mlogloss:1.35037\n",
      "[204]\tvalidation_0-mlogloss:1.35000\n",
      "[205]\tvalidation_0-mlogloss:1.34801\n",
      "[206]\tvalidation_0-mlogloss:1.34633\n",
      "[207]\tvalidation_0-mlogloss:1.34556\n",
      "[208]\tvalidation_0-mlogloss:1.34521\n",
      "[209]\tvalidation_0-mlogloss:1.34471\n",
      "[210]\tvalidation_0-mlogloss:1.34441\n",
      "[211]\tvalidation_0-mlogloss:1.34342\n",
      "[212]\tvalidation_0-mlogloss:1.34286\n",
      "[213]\tvalidation_0-mlogloss:1.34141\n",
      "[214]\tvalidation_0-mlogloss:1.34162\n",
      "[215]\tvalidation_0-mlogloss:1.34092\n",
      "[216]\tvalidation_0-mlogloss:1.34059\n",
      "[217]\tvalidation_0-mlogloss:1.34136\n",
      "[218]\tvalidation_0-mlogloss:1.34057\n",
      "[219]\tvalidation_0-mlogloss:1.34010\n",
      "[220]\tvalidation_0-mlogloss:1.34022\n",
      "[221]\tvalidation_0-mlogloss:1.33924\n",
      "[222]\tvalidation_0-mlogloss:1.33858\n",
      "[223]\tvalidation_0-mlogloss:1.33793\n",
      "[224]\tvalidation_0-mlogloss:1.33764\n",
      "[225]\tvalidation_0-mlogloss:1.33674\n",
      "[226]\tvalidation_0-mlogloss:1.33620\n",
      "[227]\tvalidation_0-mlogloss:1.33532\n",
      "[228]\tvalidation_0-mlogloss:1.33460\n",
      "[229]\tvalidation_0-mlogloss:1.33408\n",
      "[230]\tvalidation_0-mlogloss:1.33280\n",
      "[231]\tvalidation_0-mlogloss:1.33264\n",
      "[232]\tvalidation_0-mlogloss:1.33154\n",
      "[233]\tvalidation_0-mlogloss:1.33094\n",
      "[234]\tvalidation_0-mlogloss:1.32971\n",
      "[235]\tvalidation_0-mlogloss:1.32838\n",
      "[236]\tvalidation_0-mlogloss:1.32690\n",
      "[237]\tvalidation_0-mlogloss:1.32546\n",
      "[238]\tvalidation_0-mlogloss:1.32545\n",
      "[239]\tvalidation_0-mlogloss:1.32439\n",
      "[240]\tvalidation_0-mlogloss:1.32438\n",
      "[241]\tvalidation_0-mlogloss:1.32477\n",
      "[242]\tvalidation_0-mlogloss:1.32520\n",
      "[243]\tvalidation_0-mlogloss:1.32503\n",
      "[244]\tvalidation_0-mlogloss:1.32457\n",
      "[245]\tvalidation_0-mlogloss:1.32456\n",
      "[246]\tvalidation_0-mlogloss:1.32406\n",
      "[247]\tvalidation_0-mlogloss:1.32360\n",
      "[248]\tvalidation_0-mlogloss:1.32308\n",
      "[249]\tvalidation_0-mlogloss:1.32306\n",
      "[250]\tvalidation_0-mlogloss:1.32322\n",
      "[251]\tvalidation_0-mlogloss:1.32302\n",
      "[252]\tvalidation_0-mlogloss:1.32148\n",
      "[253]\tvalidation_0-mlogloss:1.32032\n",
      "[254]\tvalidation_0-mlogloss:1.31955\n",
      "[255]\tvalidation_0-mlogloss:1.31985\n",
      "[256]\tvalidation_0-mlogloss:1.32030\n",
      "[257]\tvalidation_0-mlogloss:1.32048\n",
      "[258]\tvalidation_0-mlogloss:1.31993\n",
      "[259]\tvalidation_0-mlogloss:1.31913\n",
      "[260]\tvalidation_0-mlogloss:1.31909\n",
      "[261]\tvalidation_0-mlogloss:1.31844\n",
      "[262]\tvalidation_0-mlogloss:1.31820\n",
      "[263]\tvalidation_0-mlogloss:1.31777\n",
      "[264]\tvalidation_0-mlogloss:1.31807\n",
      "[265]\tvalidation_0-mlogloss:1.31809\n",
      "[266]\tvalidation_0-mlogloss:1.31781\n",
      "[267]\tvalidation_0-mlogloss:1.31690\n",
      "[268]\tvalidation_0-mlogloss:1.31659\n",
      "[269]\tvalidation_0-mlogloss:1.31661\n",
      "[270]\tvalidation_0-mlogloss:1.31620\n",
      "[271]\tvalidation_0-mlogloss:1.31564\n",
      "[272]\tvalidation_0-mlogloss:1.31570\n",
      "[273]\tvalidation_0-mlogloss:1.31572\n",
      "[274]\tvalidation_0-mlogloss:1.31564\n",
      "[275]\tvalidation_0-mlogloss:1.31500\n",
      "[276]\tvalidation_0-mlogloss:1.31520\n",
      "[277]\tvalidation_0-mlogloss:1.31459\n",
      "[278]\tvalidation_0-mlogloss:1.31399\n",
      "[279]\tvalidation_0-mlogloss:1.31264\n",
      "[280]\tvalidation_0-mlogloss:1.31204\n",
      "[281]\tvalidation_0-mlogloss:1.31133\n",
      "[282]\tvalidation_0-mlogloss:1.31080\n",
      "[283]\tvalidation_0-mlogloss:1.31094\n",
      "[284]\tvalidation_0-mlogloss:1.31128\n",
      "[285]\tvalidation_0-mlogloss:1.31136\n",
      "[286]\tvalidation_0-mlogloss:1.31174\n",
      "[287]\tvalidation_0-mlogloss:1.31183\n",
      "[288]\tvalidation_0-mlogloss:1.31182\n",
      "[289]\tvalidation_0-mlogloss:1.31201\n",
      "[290]\tvalidation_0-mlogloss:1.31174\n",
      "[291]\tvalidation_0-mlogloss:1.31174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.57      0.53      1499\n",
      "           1       0.47      0.54      0.50      1499\n",
      "           2       0.51      0.45      0.47      1499\n",
      "           3       0.83      0.55      0.66      1499\n",
      "           4       0.87      0.85      0.86      1499\n",
      "           5       0.58      0.57      0.58      1499\n",
      "           6       0.81      0.75      0.78      1499\n",
      "           7       0.87      0.80      0.84      1499\n",
      "           8       0.60      0.86      0.70      1499\n",
      "           9       0.86      0.77      0.81      1499\n",
      "          10       0.71      0.71      0.71      1499\n",
      "          11       0.58      0.56      0.57      1499\n",
      "          12       0.56      0.65      0.60      1499\n",
      "          13       0.40      0.45      0.42      1499\n",
      "          14       0.37      0.47      0.42      1499\n",
      "          15       0.51      0.13      0.21      1499\n",
      "          16       0.80      0.41      0.54      1499\n",
      "          17       0.91      0.90      0.90      1499\n",
      "          18       0.44      0.57      0.50      1499\n",
      "          19       0.56      0.57      0.57      1499\n",
      "          20       0.79      0.93      0.86      1499\n",
      "          21       0.78      0.74      0.76      1499\n",
      "          22       0.38      0.43      0.40      1499\n",
      "          23       0.68      0.82      0.75      1499\n",
      "          24       0.88      0.82      0.85      1499\n",
      "\n",
      "    accuracy                           0.63     37475\n",
      "   macro avg       0.65      0.63      0.63     37475\n",
      "weighted avg       0.65      0.63      0.63     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2=XGBClassifier(n_estimators=500)\n",
    "model2.fit(x16,y16,early_stopping_rounds=10, eval_set=[(xv16, yv16)])\n",
    "y_pred=model2.predict(xt16)\n",
    "print(classification_report(yt16,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7844baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model1 = Sequential(\n",
    "    [\n",
    "        Dense(16, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(25, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7980b449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 13s 1ms/step - loss: 1.2853 - val_loss: 1.8553\n",
      "Epoch 2/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 0.7151 - val_loss: 1.9334\n",
      "Epoch 3/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.5800 - val_loss: 2.0008\n",
      "Epoch 4/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 0.5135 - val_loss: 2.3795\n",
      "Epoch 5/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 0.4749 - val_loss: 2.1545\n",
      "Epoch 6/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.4481 - val_loss: 2.2653\n",
      "Epoch 7/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 0.4290 - val_loss: 2.2852\n",
      "Epoch 8/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 0.4122 - val_loss: 2.2804\n",
      "Epoch 9/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 0.3997 - val_loss: 2.3937\n",
      "Epoch 10/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 0.3886 - val_loss: 2.4583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f168013ceb0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model1.fit(\n",
    "    x16,y16,epochs=10,validation_data=(xv16,yv16)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d07cf8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 797us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.48      0.50      1499\n",
      "           1       0.43      0.63      0.51      1499\n",
      "           2       0.40      0.42      0.41      1499\n",
      "           3       0.77      0.64      0.70      1499\n",
      "           4       0.79      0.88      0.84      1499\n",
      "           5       0.63      0.66      0.65      1499\n",
      "           6       0.94      0.52      0.67      1499\n",
      "           7       0.87      0.84      0.85      1499\n",
      "           8       0.56      0.86      0.68      1499\n",
      "           9       0.65      0.77      0.71      1499\n",
      "          10       0.74      0.25      0.37      1499\n",
      "          11       0.66      0.39      0.49      1499\n",
      "          12       0.50      0.54      0.52      1499\n",
      "          13       0.28      0.55      0.37      1499\n",
      "          14       0.37      0.48      0.41      1499\n",
      "          15       0.72      0.09      0.16      1499\n",
      "          16       0.62      0.55      0.58      1499\n",
      "          17       0.98      0.79      0.88      1499\n",
      "          18       0.49      0.40      0.44      1499\n",
      "          19       0.50      0.43      0.47      1499\n",
      "          20       0.84      0.87      0.85      1499\n",
      "          21       0.67      0.72      0.69      1499\n",
      "          22       0.32      0.52      0.40      1499\n",
      "          23       0.66      0.88      0.75      1499\n",
      "          24       0.86      0.48      0.62      1499\n",
      "\n",
      "    accuracy                           0.59     37475\n",
      "   macro avg       0.63      0.59      0.58     37475\n",
      "weighted avg       0.63      0.59      0.58     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model1.predict(xt16)).numpy(),axis=1)\n",
    "print(classification_report(yt16,y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e57e7",
   "metadata": {},
   "source": [
    "## 0-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a408e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain32=xtrain.iloc[:,:32]\n",
    "xtest32=xtest.iloc[:,:32]\n",
    "xvalid32=xvalid.iloc[:,:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26f15468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11878/1675347936.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtrain32['id']=ytrain\n",
      "/tmp/ipykernel_11878/1675347936.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtest32['id']=ytest\n",
      "/tmp/ipykernel_11878/1675347936.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xvalid32['id']=yvalid\n"
     ]
    }
   ],
   "source": [
    "xtrain32['id']=ytrain\n",
    "xtest32['id']=ytest\n",
    "xvalid32['id']=yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ddddf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x32,y32=scale_dataset(xtrain32)\n",
    "xt32,yt32=scale_dataset(xtest32)\n",
    "xv32,yv32=scale_dataset(xvalid32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.71878\n",
      "[1]\tvalidation_0-mlogloss:2.50676\n",
      "[2]\tvalidation_0-mlogloss:2.36490\n",
      "[3]\tvalidation_0-mlogloss:2.24633\n",
      "[4]\tvalidation_0-mlogloss:2.15235\n",
      "[5]\tvalidation_0-mlogloss:2.07357\n",
      "[6]\tvalidation_0-mlogloss:1.99772\n",
      "[7]\tvalidation_0-mlogloss:1.93303\n",
      "[8]\tvalidation_0-mlogloss:1.87601\n",
      "[9]\tvalidation_0-mlogloss:1.82581\n",
      "[10]\tvalidation_0-mlogloss:1.78118\n",
      "[11]\tvalidation_0-mlogloss:1.73730\n",
      "[12]\tvalidation_0-mlogloss:1.70069\n",
      "[13]\tvalidation_0-mlogloss:1.66820\n",
      "[14]\tvalidation_0-mlogloss:1.63405\n",
      "[15]\tvalidation_0-mlogloss:1.60492\n",
      "[16]\tvalidation_0-mlogloss:1.57434\n",
      "[17]\tvalidation_0-mlogloss:1.54717\n",
      "[18]\tvalidation_0-mlogloss:1.52182\n",
      "[19]\tvalidation_0-mlogloss:1.49684\n",
      "[20]\tvalidation_0-mlogloss:1.47122\n",
      "[21]\tvalidation_0-mlogloss:1.44978\n",
      "[22]\tvalidation_0-mlogloss:1.43164\n",
      "[23]\tvalidation_0-mlogloss:1.41168\n",
      "[24]\tvalidation_0-mlogloss:1.39337\n",
      "[25]\tvalidation_0-mlogloss:1.37522\n",
      "[26]\tvalidation_0-mlogloss:1.35565\n",
      "[27]\tvalidation_0-mlogloss:1.33657\n",
      "[28]\tvalidation_0-mlogloss:1.31939\n",
      "[29]\tvalidation_0-mlogloss:1.30517\n",
      "[30]\tvalidation_0-mlogloss:1.28975\n",
      "[31]\tvalidation_0-mlogloss:1.27437\n",
      "[32]\tvalidation_0-mlogloss:1.26037\n",
      "[33]\tvalidation_0-mlogloss:1.24757\n",
      "[34]\tvalidation_0-mlogloss:1.23642\n",
      "[35]\tvalidation_0-mlogloss:1.22239\n",
      "[36]\tvalidation_0-mlogloss:1.20869\n",
      "[37]\tvalidation_0-mlogloss:1.19740\n",
      "[38]\tvalidation_0-mlogloss:1.18611\n",
      "[39]\tvalidation_0-mlogloss:1.17605\n",
      "[40]\tvalidation_0-mlogloss:1.16718\n",
      "[41]\tvalidation_0-mlogloss:1.15537\n",
      "[42]\tvalidation_0-mlogloss:1.14454\n",
      "[43]\tvalidation_0-mlogloss:1.13303\n",
      "[44]\tvalidation_0-mlogloss:1.12420\n",
      "[45]\tvalidation_0-mlogloss:1.11349\n",
      "[46]\tvalidation_0-mlogloss:1.10599\n",
      "[47]\tvalidation_0-mlogloss:1.09775\n",
      "[48]\tvalidation_0-mlogloss:1.08771\n",
      "[49]\tvalidation_0-mlogloss:1.07959\n",
      "[50]\tvalidation_0-mlogloss:1.07074\n",
      "[51]\tvalidation_0-mlogloss:1.06334\n",
      "[52]\tvalidation_0-mlogloss:1.05518\n",
      "[53]\tvalidation_0-mlogloss:1.04855\n",
      "[54]\tvalidation_0-mlogloss:1.04197\n",
      "[55]\tvalidation_0-mlogloss:1.03297\n",
      "[56]\tvalidation_0-mlogloss:1.02764\n",
      "[57]\tvalidation_0-mlogloss:1.02106\n",
      "[58]\tvalidation_0-mlogloss:1.01326\n",
      "[59]\tvalidation_0-mlogloss:1.00623\n",
      "[60]\tvalidation_0-mlogloss:0.99980\n",
      "[61]\tvalidation_0-mlogloss:0.99288\n",
      "[62]\tvalidation_0-mlogloss:0.98719\n",
      "[63]\tvalidation_0-mlogloss:0.98000\n",
      "[64]\tvalidation_0-mlogloss:0.97342\n",
      "[65]\tvalidation_0-mlogloss:0.96822\n",
      "[66]\tvalidation_0-mlogloss:0.96157\n",
      "[67]\tvalidation_0-mlogloss:0.95634\n",
      "[68]\tvalidation_0-mlogloss:0.95087\n",
      "[69]\tvalidation_0-mlogloss:0.94633\n",
      "[70]\tvalidation_0-mlogloss:0.94138\n",
      "[71]\tvalidation_0-mlogloss:0.93524\n",
      "[72]\tvalidation_0-mlogloss:0.92894\n",
      "[73]\tvalidation_0-mlogloss:0.92326\n",
      "[74]\tvalidation_0-mlogloss:0.91810\n",
      "[75]\tvalidation_0-mlogloss:0.91440\n",
      "[76]\tvalidation_0-mlogloss:0.91032\n",
      "[77]\tvalidation_0-mlogloss:0.90657\n",
      "[78]\tvalidation_0-mlogloss:0.90191\n",
      "[79]\tvalidation_0-mlogloss:0.89935\n",
      "[80]\tvalidation_0-mlogloss:0.89482\n",
      "[81]\tvalidation_0-mlogloss:0.88943\n",
      "[82]\tvalidation_0-mlogloss:0.88579\n",
      "[83]\tvalidation_0-mlogloss:0.88142\n",
      "[84]\tvalidation_0-mlogloss:0.87744\n",
      "[85]\tvalidation_0-mlogloss:0.87461\n",
      "[86]\tvalidation_0-mlogloss:0.87141\n",
      "[87]\tvalidation_0-mlogloss:0.86746\n",
      "[88]\tvalidation_0-mlogloss:0.86485\n",
      "[89]\tvalidation_0-mlogloss:0.86042\n",
      "[90]\tvalidation_0-mlogloss:0.85641\n",
      "[91]\tvalidation_0-mlogloss:0.85307\n",
      "[92]\tvalidation_0-mlogloss:0.84818\n",
      "[93]\tvalidation_0-mlogloss:0.84417\n",
      "[94]\tvalidation_0-mlogloss:0.83989\n",
      "[95]\tvalidation_0-mlogloss:0.83668\n",
      "[96]\tvalidation_0-mlogloss:0.83227\n",
      "[97]\tvalidation_0-mlogloss:0.82883\n",
      "[98]\tvalidation_0-mlogloss:0.82655\n",
      "[99]\tvalidation_0-mlogloss:0.82411\n",
      "[100]\tvalidation_0-mlogloss:0.82149\n",
      "[101]\tvalidation_0-mlogloss:0.81846\n",
      "[102]\tvalidation_0-mlogloss:0.81556\n",
      "[103]\tvalidation_0-mlogloss:0.81367\n",
      "[104]\tvalidation_0-mlogloss:0.81175\n",
      "[105]\tvalidation_0-mlogloss:0.81044\n",
      "[106]\tvalidation_0-mlogloss:0.80780\n",
      "[107]\tvalidation_0-mlogloss:0.80455\n",
      "[108]\tvalidation_0-mlogloss:0.80296\n",
      "[109]\tvalidation_0-mlogloss:0.79898\n",
      "[110]\tvalidation_0-mlogloss:0.79611\n",
      "[111]\tvalidation_0-mlogloss:0.79444\n",
      "[112]\tvalidation_0-mlogloss:0.79165\n",
      "[113]\tvalidation_0-mlogloss:0.78863\n",
      "[114]\tvalidation_0-mlogloss:0.78644\n",
      "[115]\tvalidation_0-mlogloss:0.78414\n",
      "[116]\tvalidation_0-mlogloss:0.78201\n",
      "[117]\tvalidation_0-mlogloss:0.78087\n",
      "[118]\tvalidation_0-mlogloss:0.77908\n",
      "[119]\tvalidation_0-mlogloss:0.77715\n",
      "[120]\tvalidation_0-mlogloss:0.77530\n",
      "[121]\tvalidation_0-mlogloss:0.77258\n",
      "[122]\tvalidation_0-mlogloss:0.77160\n",
      "[123]\tvalidation_0-mlogloss:0.76952\n",
      "[124]\tvalidation_0-mlogloss:0.76583\n",
      "[125]\tvalidation_0-mlogloss:0.76552\n",
      "[126]\tvalidation_0-mlogloss:0.76434\n",
      "[127]\tvalidation_0-mlogloss:0.76287\n",
      "[128]\tvalidation_0-mlogloss:0.76081\n",
      "[129]\tvalidation_0-mlogloss:0.75974\n",
      "[130]\tvalidation_0-mlogloss:0.75801\n",
      "[131]\tvalidation_0-mlogloss:0.75664\n",
      "[132]\tvalidation_0-mlogloss:0.75559\n",
      "[133]\tvalidation_0-mlogloss:0.75444\n",
      "[134]\tvalidation_0-mlogloss:0.75228\n",
      "[135]\tvalidation_0-mlogloss:0.75093\n",
      "[136]\tvalidation_0-mlogloss:0.75042\n",
      "[137]\tvalidation_0-mlogloss:0.74831\n",
      "[138]\tvalidation_0-mlogloss:0.74638\n",
      "[139]\tvalidation_0-mlogloss:0.74464\n",
      "[140]\tvalidation_0-mlogloss:0.74359\n",
      "[141]\tvalidation_0-mlogloss:0.74198\n",
      "[142]\tvalidation_0-mlogloss:0.74061\n",
      "[143]\tvalidation_0-mlogloss:0.73895\n",
      "[144]\tvalidation_0-mlogloss:0.73711\n",
      "[145]\tvalidation_0-mlogloss:0.73535\n",
      "[146]\tvalidation_0-mlogloss:0.73474\n",
      "[147]\tvalidation_0-mlogloss:0.73334\n",
      "[148]\tvalidation_0-mlogloss:0.73191\n",
      "[149]\tvalidation_0-mlogloss:0.73018\n",
      "[150]\tvalidation_0-mlogloss:0.72802\n",
      "[151]\tvalidation_0-mlogloss:0.72678\n",
      "[152]\tvalidation_0-mlogloss:0.72507\n",
      "[153]\tvalidation_0-mlogloss:0.72446\n",
      "[154]\tvalidation_0-mlogloss:0.72349\n",
      "[155]\tvalidation_0-mlogloss:0.72197\n",
      "[156]\tvalidation_0-mlogloss:0.72152\n",
      "[157]\tvalidation_0-mlogloss:0.72107\n",
      "[158]\tvalidation_0-mlogloss:0.71981\n",
      "[159]\tvalidation_0-mlogloss:0.71867\n",
      "[160]\tvalidation_0-mlogloss:0.71693\n",
      "[161]\tvalidation_0-mlogloss:0.71453\n",
      "[162]\tvalidation_0-mlogloss:0.71336\n",
      "[163]\tvalidation_0-mlogloss:0.71191\n",
      "[164]\tvalidation_0-mlogloss:0.71122\n",
      "[165]\tvalidation_0-mlogloss:0.70996\n",
      "[166]\tvalidation_0-mlogloss:0.70957\n",
      "[167]\tvalidation_0-mlogloss:0.70910\n",
      "[168]\tvalidation_0-mlogloss:0.70837\n",
      "[169]\tvalidation_0-mlogloss:0.70820\n",
      "[170]\tvalidation_0-mlogloss:0.70732\n",
      "[171]\tvalidation_0-mlogloss:0.70624\n",
      "[172]\tvalidation_0-mlogloss:0.70549\n",
      "[173]\tvalidation_0-mlogloss:0.70539\n",
      "[174]\tvalidation_0-mlogloss:0.70405\n",
      "[175]\tvalidation_0-mlogloss:0.70241\n",
      "[176]\tvalidation_0-mlogloss:0.70285\n",
      "[177]\tvalidation_0-mlogloss:0.70174\n",
      "[178]\tvalidation_0-mlogloss:0.70130\n",
      "[179]\tvalidation_0-mlogloss:0.70042\n",
      "[180]\tvalidation_0-mlogloss:0.69894\n",
      "[181]\tvalidation_0-mlogloss:0.69763\n",
      "[182]\tvalidation_0-mlogloss:0.69589\n",
      "[183]\tvalidation_0-mlogloss:0.69606\n",
      "[184]\tvalidation_0-mlogloss:0.69509\n",
      "[185]\tvalidation_0-mlogloss:0.69549\n",
      "[186]\tvalidation_0-mlogloss:0.69443\n",
      "[187]\tvalidation_0-mlogloss:0.69399\n",
      "[188]\tvalidation_0-mlogloss:0.69279\n",
      "[189]\tvalidation_0-mlogloss:0.69205\n",
      "[190]\tvalidation_0-mlogloss:0.69059\n",
      "[191]\tvalidation_0-mlogloss:0.68996\n",
      "[192]\tvalidation_0-mlogloss:0.68966\n",
      "[193]\tvalidation_0-mlogloss:0.68892\n",
      "[194]\tvalidation_0-mlogloss:0.68795\n",
      "[195]\tvalidation_0-mlogloss:0.68744\n",
      "[196]\tvalidation_0-mlogloss:0.68770\n",
      "[197]\tvalidation_0-mlogloss:0.68697\n",
      "[198]\tvalidation_0-mlogloss:0.68655\n",
      "[199]\tvalidation_0-mlogloss:0.68636\n",
      "[200]\tvalidation_0-mlogloss:0.68607\n",
      "[201]\tvalidation_0-mlogloss:0.68534\n",
      "[202]\tvalidation_0-mlogloss:0.68432\n",
      "[203]\tvalidation_0-mlogloss:0.68397\n",
      "[204]\tvalidation_0-mlogloss:0.68347\n",
      "[205]\tvalidation_0-mlogloss:0.68297\n",
      "[206]\tvalidation_0-mlogloss:0.68210\n",
      "[207]\tvalidation_0-mlogloss:0.68094\n",
      "[208]\tvalidation_0-mlogloss:0.68025\n",
      "[209]\tvalidation_0-mlogloss:0.68015\n",
      "[210]\tvalidation_0-mlogloss:0.67941\n",
      "[211]\tvalidation_0-mlogloss:0.67901\n",
      "[212]\tvalidation_0-mlogloss:0.67816\n",
      "[213]\tvalidation_0-mlogloss:0.67805\n",
      "[214]\tvalidation_0-mlogloss:0.67717\n",
      "[215]\tvalidation_0-mlogloss:0.67669\n",
      "[216]\tvalidation_0-mlogloss:0.67648\n",
      "[217]\tvalidation_0-mlogloss:0.67597\n",
      "[218]\tvalidation_0-mlogloss:0.67668\n",
      "[219]\tvalidation_0-mlogloss:0.67599\n",
      "[220]\tvalidation_0-mlogloss:0.67545\n",
      "[221]\tvalidation_0-mlogloss:0.67586\n",
      "[222]\tvalidation_0-mlogloss:0.67510\n",
      "[223]\tvalidation_0-mlogloss:0.67486\n",
      "[224]\tvalidation_0-mlogloss:0.67475\n",
      "[225]\tvalidation_0-mlogloss:0.67564\n",
      "[226]\tvalidation_0-mlogloss:0.67491\n",
      "[227]\tvalidation_0-mlogloss:0.67459\n",
      "[228]\tvalidation_0-mlogloss:0.67381\n",
      "[229]\tvalidation_0-mlogloss:0.67300\n",
      "[230]\tvalidation_0-mlogloss:0.67237\n",
      "[231]\tvalidation_0-mlogloss:0.67168\n",
      "[232]\tvalidation_0-mlogloss:0.67087\n",
      "[233]\tvalidation_0-mlogloss:0.67008\n",
      "[234]\tvalidation_0-mlogloss:0.66913\n",
      "[235]\tvalidation_0-mlogloss:0.66770\n",
      "[236]\tvalidation_0-mlogloss:0.66704\n",
      "[237]\tvalidation_0-mlogloss:0.66631\n",
      "[238]\tvalidation_0-mlogloss:0.66545\n",
      "[239]\tvalidation_0-mlogloss:0.66478\n",
      "[240]\tvalidation_0-mlogloss:0.66362\n",
      "[241]\tvalidation_0-mlogloss:0.66290\n",
      "[242]\tvalidation_0-mlogloss:0.66254\n",
      "[243]\tvalidation_0-mlogloss:0.66303\n",
      "[244]\tvalidation_0-mlogloss:0.66251\n",
      "[245]\tvalidation_0-mlogloss:0.66261\n",
      "[246]\tvalidation_0-mlogloss:0.66225\n",
      "[247]\tvalidation_0-mlogloss:0.66160\n",
      "[248]\tvalidation_0-mlogloss:0.66160\n",
      "[249]\tvalidation_0-mlogloss:0.66093\n",
      "[250]\tvalidation_0-mlogloss:0.66022\n",
      "[251]\tvalidation_0-mlogloss:0.65938\n",
      "[252]\tvalidation_0-mlogloss:0.65835\n",
      "[253]\tvalidation_0-mlogloss:0.65782\n",
      "[254]\tvalidation_0-mlogloss:0.65763\n",
      "[255]\tvalidation_0-mlogloss:0.65785\n",
      "[256]\tvalidation_0-mlogloss:0.65813\n",
      "[257]\tvalidation_0-mlogloss:0.65738\n",
      "[258]\tvalidation_0-mlogloss:0.65720\n",
      "[259]\tvalidation_0-mlogloss:0.65610\n",
      "[260]\tvalidation_0-mlogloss:0.65617\n",
      "[261]\tvalidation_0-mlogloss:0.65613\n",
      "[262]\tvalidation_0-mlogloss:0.65553\n",
      "[263]\tvalidation_0-mlogloss:0.65573\n",
      "[264]\tvalidation_0-mlogloss:0.65533\n",
      "[265]\tvalidation_0-mlogloss:0.65463\n",
      "[266]\tvalidation_0-mlogloss:0.65447\n",
      "[267]\tvalidation_0-mlogloss:0.65472\n",
      "[268]\tvalidation_0-mlogloss:0.65474\n",
      "[269]\tvalidation_0-mlogloss:0.65481\n",
      "[270]\tvalidation_0-mlogloss:0.65425\n",
      "[271]\tvalidation_0-mlogloss:0.65375\n",
      "[272]\tvalidation_0-mlogloss:0.65310\n",
      "[273]\tvalidation_0-mlogloss:0.65315\n",
      "[274]\tvalidation_0-mlogloss:0.65282\n",
      "[275]\tvalidation_0-mlogloss:0.65294\n",
      "[276]\tvalidation_0-mlogloss:0.65157\n",
      "[277]\tvalidation_0-mlogloss:0.65085\n",
      "[278]\tvalidation_0-mlogloss:0.65098\n",
      "[279]\tvalidation_0-mlogloss:0.65137\n",
      "[280]\tvalidation_0-mlogloss:0.65110\n",
      "[281]\tvalidation_0-mlogloss:0.65040\n",
      "[282]\tvalidation_0-mlogloss:0.64989\n",
      "[283]\tvalidation_0-mlogloss:0.64975\n",
      "[284]\tvalidation_0-mlogloss:0.64929\n",
      "[285]\tvalidation_0-mlogloss:0.64977\n",
      "[286]\tvalidation_0-mlogloss:0.64923\n",
      "[287]\tvalidation_0-mlogloss:0.64903\n",
      "[288]\tvalidation_0-mlogloss:0.64883\n",
      "[289]\tvalidation_0-mlogloss:0.64861\n",
      "[290]\tvalidation_0-mlogloss:0.64830\n",
      "[291]\tvalidation_0-mlogloss:0.64809\n",
      "[292]\tvalidation_0-mlogloss:0.64717\n",
      "[293]\tvalidation_0-mlogloss:0.64681\n",
      "[294]\tvalidation_0-mlogloss:0.64650\n",
      "[295]\tvalidation_0-mlogloss:0.64618\n",
      "[296]\tvalidation_0-mlogloss:0.64582\n",
      "[297]\tvalidation_0-mlogloss:0.64547\n",
      "[298]\tvalidation_0-mlogloss:0.64571\n",
      "[299]\tvalidation_0-mlogloss:0.64529\n",
      "[300]\tvalidation_0-mlogloss:0.64484\n",
      "[301]\tvalidation_0-mlogloss:0.64457\n",
      "[302]\tvalidation_0-mlogloss:0.64442\n",
      "[303]\tvalidation_0-mlogloss:0.64436\n",
      "[304]\tvalidation_0-mlogloss:0.64377\n",
      "[305]\tvalidation_0-mlogloss:0.64360\n",
      "[306]\tvalidation_0-mlogloss:0.64326\n",
      "[307]\tvalidation_0-mlogloss:0.64284\n",
      "[308]\tvalidation_0-mlogloss:0.64264\n",
      "[309]\tvalidation_0-mlogloss:0.64217\n",
      "[310]\tvalidation_0-mlogloss:0.64217\n",
      "[311]\tvalidation_0-mlogloss:0.64184\n",
      "[312]\tvalidation_0-mlogloss:0.64249\n",
      "[313]\tvalidation_0-mlogloss:0.64213\n",
      "[314]\tvalidation_0-mlogloss:0.64203\n",
      "[315]\tvalidation_0-mlogloss:0.64126\n",
      "[316]\tvalidation_0-mlogloss:0.64139\n",
      "[317]\tvalidation_0-mlogloss:0.64133\n",
      "[318]\tvalidation_0-mlogloss:0.64073\n",
      "[319]\tvalidation_0-mlogloss:0.63971\n",
      "[320]\tvalidation_0-mlogloss:0.63951\n",
      "[321]\tvalidation_0-mlogloss:0.63910\n",
      "[322]\tvalidation_0-mlogloss:0.63880\n",
      "[323]\tvalidation_0-mlogloss:0.63851\n",
      "[324]\tvalidation_0-mlogloss:0.63783\n",
      "[325]\tvalidation_0-mlogloss:0.63727\n",
      "[326]\tvalidation_0-mlogloss:0.63661\n",
      "[327]\tvalidation_0-mlogloss:0.63677\n",
      "[328]\tvalidation_0-mlogloss:0.63652\n",
      "[329]\tvalidation_0-mlogloss:0.63638\n",
      "[330]\tvalidation_0-mlogloss:0.63613\n",
      "[331]\tvalidation_0-mlogloss:0.63591\n",
      "[332]\tvalidation_0-mlogloss:0.63556\n",
      "[333]\tvalidation_0-mlogloss:0.63598\n",
      "[334]\tvalidation_0-mlogloss:0.63556\n",
      "[335]\tvalidation_0-mlogloss:0.63457\n",
      "[336]\tvalidation_0-mlogloss:0.63415\n",
      "[337]\tvalidation_0-mlogloss:0.63415\n",
      "[338]\tvalidation_0-mlogloss:0.63436\n",
      "[339]\tvalidation_0-mlogloss:0.63389\n",
      "[340]\tvalidation_0-mlogloss:0.63377\n",
      "[341]\tvalidation_0-mlogloss:0.63475\n",
      "[342]\tvalidation_0-mlogloss:0.63466\n",
      "[343]\tvalidation_0-mlogloss:0.63401\n",
      "[344]\tvalidation_0-mlogloss:0.63401\n",
      "[345]\tvalidation_0-mlogloss:0.63415\n",
      "[346]\tvalidation_0-mlogloss:0.63397\n",
      "[347]\tvalidation_0-mlogloss:0.63354\n",
      "[348]\tvalidation_0-mlogloss:0.63361\n",
      "[349]\tvalidation_0-mlogloss:0.63335\n",
      "[350]\tvalidation_0-mlogloss:0.63286\n",
      "[351]\tvalidation_0-mlogloss:0.63283\n",
      "[352]\tvalidation_0-mlogloss:0.63302\n",
      "[353]\tvalidation_0-mlogloss:0.63265\n",
      "[354]\tvalidation_0-mlogloss:0.63278\n",
      "[355]\tvalidation_0-mlogloss:0.63210\n",
      "[356]\tvalidation_0-mlogloss:0.63207\n",
      "[357]\tvalidation_0-mlogloss:0.63176\n",
      "[358]\tvalidation_0-mlogloss:0.63165\n",
      "[359]\tvalidation_0-mlogloss:0.63151\n",
      "[360]\tvalidation_0-mlogloss:0.63188\n",
      "[361]\tvalidation_0-mlogloss:0.63213\n",
      "[362]\tvalidation_0-mlogloss:0.63213\n",
      "[363]\tvalidation_0-mlogloss:0.63197\n",
      "[364]\tvalidation_0-mlogloss:0.63189\n",
      "[365]\tvalidation_0-mlogloss:0.63144\n",
      "[366]\tvalidation_0-mlogloss:0.63110\n",
      "[367]\tvalidation_0-mlogloss:0.63087\n",
      "[368]\tvalidation_0-mlogloss:0.63027\n",
      "[369]\tvalidation_0-mlogloss:0.62994\n",
      "[370]\tvalidation_0-mlogloss:0.62997\n",
      "[371]\tvalidation_0-mlogloss:0.63005\n",
      "[372]\tvalidation_0-mlogloss:0.62976\n",
      "[373]\tvalidation_0-mlogloss:0.62938\n",
      "[374]\tvalidation_0-mlogloss:0.62958\n",
      "[375]\tvalidation_0-mlogloss:0.62882\n",
      "[376]\tvalidation_0-mlogloss:0.62853\n",
      "[377]\tvalidation_0-mlogloss:0.62860\n",
      "[378]\tvalidation_0-mlogloss:0.62822\n",
      "[379]\tvalidation_0-mlogloss:0.62833\n",
      "[380]\tvalidation_0-mlogloss:0.62816\n",
      "[381]\tvalidation_0-mlogloss:0.62790\n",
      "[382]\tvalidation_0-mlogloss:0.62783\n",
      "[383]\tvalidation_0-mlogloss:0.62770\n",
      "[384]\tvalidation_0-mlogloss:0.62744\n",
      "[385]\tvalidation_0-mlogloss:0.62732\n",
      "[386]\tvalidation_0-mlogloss:0.62736\n",
      "[387]\tvalidation_0-mlogloss:0.62714\n",
      "[388]\tvalidation_0-mlogloss:0.62685\n",
      "[389]\tvalidation_0-mlogloss:0.62689\n",
      "[390]\tvalidation_0-mlogloss:0.62639\n",
      "[391]\tvalidation_0-mlogloss:0.62659\n",
      "[392]\tvalidation_0-mlogloss:0.62627\n",
      "[393]\tvalidation_0-mlogloss:0.62614\n",
      "[394]\tvalidation_0-mlogloss:0.62583\n",
      "[395]\tvalidation_0-mlogloss:0.62549\n",
      "[396]\tvalidation_0-mlogloss:0.62534\n",
      "[397]\tvalidation_0-mlogloss:0.62475\n",
      "[398]\tvalidation_0-mlogloss:0.62460\n",
      "[399]\tvalidation_0-mlogloss:0.62433\n",
      "[400]\tvalidation_0-mlogloss:0.62419\n",
      "[401]\tvalidation_0-mlogloss:0.62376\n",
      "[402]\tvalidation_0-mlogloss:0.62394\n",
      "[403]\tvalidation_0-mlogloss:0.62392\n",
      "[404]\tvalidation_0-mlogloss:0.62454\n",
      "[405]\tvalidation_0-mlogloss:0.62445\n",
      "[406]\tvalidation_0-mlogloss:0.62437\n",
      "[407]\tvalidation_0-mlogloss:0.62422\n",
      "[408]\tvalidation_0-mlogloss:0.62422\n",
      "[409]\tvalidation_0-mlogloss:0.62433\n",
      "[410]\tvalidation_0-mlogloss:0.62441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.78      1499\n",
      "           1       0.76      0.86      0.81      1499\n",
      "           2       0.74      0.75      0.75      1499\n",
      "           3       0.86      0.50      0.63      1499\n",
      "           4       0.96      0.95      0.95      1499\n",
      "           5       0.91      0.93      0.92      1499\n",
      "           6       0.80      0.97      0.88      1499\n",
      "           7       0.90      0.80      0.85      1499\n",
      "           8       0.61      0.91      0.73      1499\n",
      "           9       0.91      0.76      0.83      1499\n",
      "          10       0.97      0.93      0.95      1499\n",
      "          11       0.94      0.95      0.95      1499\n",
      "          12       0.75      0.89      0.82      1499\n",
      "          13       0.89      0.91      0.90      1499\n",
      "          14       0.59      0.80      0.68      1499\n",
      "          15       0.89      0.36      0.52      1499\n",
      "          16       0.85      0.34      0.48      1499\n",
      "          17       0.95      0.96      0.95      1499\n",
      "          18       0.74      0.83      0.79      1499\n",
      "          19       0.82      0.81      0.81      1499\n",
      "          20       0.97      0.99      0.98      1499\n",
      "          21       0.90      0.86      0.88      1499\n",
      "          22       0.74      0.84      0.78      1499\n",
      "          23       0.90      0.98      0.94      1499\n",
      "          24       0.97      0.95      0.96      1499\n",
      "\n",
      "    accuracy                           0.83     37475\n",
      "   macro avg       0.84      0.83      0.82     37475\n",
      "weighted avg       0.84      0.83      0.82     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3=XGBClassifier(n_estimators=500)\n",
    "model3.fit(x32,y32,early_stopping_rounds=10, eval_set=[(xv32, yv32)])\n",
    "y_pred=model3.predict(xt32)\n",
    "print(classification_report(yt32,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8f654ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model2 = Sequential(\n",
    "    [\n",
    "        Dense(32, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(25, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "300aa492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.7853 - val_loss: 1.1422\n",
      "Epoch 2/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.2606 - val_loss: 1.1094\n",
      "Epoch 3/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.1876 - val_loss: 1.1059\n",
      "Epoch 4/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 0.1566 - val_loss: 1.1714\n",
      "Epoch 5/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.1365 - val_loss: 1.4676\n",
      "Epoch 6/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 0.1229 - val_loss: 1.3416\n",
      "Epoch 7/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.1118 - val_loss: 1.2175\n",
      "Epoch 8/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.1040 - val_loss: 1.1426\n",
      "Epoch 9/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.0983 - val_loss: 1.2305\n",
      "Epoch 10/10\n",
      "9375/9375 [==============================] - 12s 1ms/step - loss: 0.0928 - val_loss: 1.3561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1662e8cbb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model2.fit(\n",
    "    x32,y32,epochs=10,validation_data=(xv32,yv32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eedffd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  62/1172 [>.............................] - ETA: 0s  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 845us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.71      0.81      1499\n",
      "           1       0.62      0.89      0.73      1499\n",
      "           2       0.71      0.82      0.76      1499\n",
      "           3       0.77      0.66      0.71      1499\n",
      "           4       0.93      0.93      0.93      1499\n",
      "           5       0.82      0.97      0.89      1499\n",
      "           6       0.95      0.91      0.93      1499\n",
      "           7       0.86      0.81      0.83      1499\n",
      "           8       0.71      0.85      0.77      1499\n",
      "           9       0.83      0.92      0.87      1499\n",
      "          10       0.83      0.93      0.87      1499\n",
      "          11       0.96      0.92      0.94      1499\n",
      "          12       0.68      0.86      0.76      1499\n",
      "          13       0.73      0.94      0.82      1499\n",
      "          14       0.63      0.73      0.68      1499\n",
      "          15       0.92      0.26      0.41      1499\n",
      "          16       0.82      0.53      0.65      1499\n",
      "          17       0.99      0.86      0.92      1499\n",
      "          18       0.75      0.88      0.81      1499\n",
      "          19       0.72      0.39      0.51      1499\n",
      "          20       0.99      0.92      0.95      1499\n",
      "          21       0.89      0.83      0.86      1499\n",
      "          22       0.78      0.85      0.81      1499\n",
      "          23       0.88      0.98      0.93      1499\n",
      "          24       0.94      0.94      0.94      1499\n",
      "\n",
      "    accuracy                           0.81     37475\n",
      "   macro avg       0.83      0.81      0.80     37475\n",
      "weighted avg       0.83      0.81      0.80     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model2.predict(xt32)).numpy(),axis=1)\n",
    "print(classification_report(yt32,y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead93bfd",
   "metadata": {},
   "source": [
    "## 0-64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85c5c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain['id']=ytrain\n",
    "xtest['id']=ytest\n",
    "xvalid['id']=yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21e76096",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=scale_dataset(xtrain)\n",
    "xt,yt=scale_dataset(xtest)\n",
    "xv,yv=scale_dataset(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.39438\n",
      "[1]\tvalidation_0-mlogloss:2.13400\n",
      "[2]\tvalidation_0-mlogloss:1.95841\n",
      "[3]\tvalidation_0-mlogloss:1.81615\n",
      "[4]\tvalidation_0-mlogloss:1.70165\n",
      "[5]\tvalidation_0-mlogloss:1.60782\n",
      "[6]\tvalidation_0-mlogloss:1.52455\n",
      "[7]\tvalidation_0-mlogloss:1.45587\n",
      "[8]\tvalidation_0-mlogloss:1.39223\n",
      "[9]\tvalidation_0-mlogloss:1.33762\n",
      "[10]\tvalidation_0-mlogloss:1.28236\n",
      "[11]\tvalidation_0-mlogloss:1.23707\n",
      "[12]\tvalidation_0-mlogloss:1.19231\n",
      "[13]\tvalidation_0-mlogloss:1.15230\n",
      "[14]\tvalidation_0-mlogloss:1.11473\n",
      "[15]\tvalidation_0-mlogloss:1.08032\n",
      "[16]\tvalidation_0-mlogloss:1.05018\n",
      "[17]\tvalidation_0-mlogloss:1.02044\n",
      "[18]\tvalidation_0-mlogloss:0.99517\n",
      "[19]\tvalidation_0-mlogloss:0.96680\n",
      "[20]\tvalidation_0-mlogloss:0.94445\n",
      "[21]\tvalidation_0-mlogloss:0.92306\n",
      "[22]\tvalidation_0-mlogloss:0.90142\n",
      "[23]\tvalidation_0-mlogloss:0.88116\n",
      "[24]\tvalidation_0-mlogloss:0.86300\n",
      "[25]\tvalidation_0-mlogloss:0.84671\n",
      "[26]\tvalidation_0-mlogloss:0.83118\n",
      "[27]\tvalidation_0-mlogloss:0.81669\n",
      "[28]\tvalidation_0-mlogloss:0.80152\n",
      "[29]\tvalidation_0-mlogloss:0.78625\n",
      "[30]\tvalidation_0-mlogloss:0.77380\n",
      "[31]\tvalidation_0-mlogloss:0.76022\n",
      "[32]\tvalidation_0-mlogloss:0.74747\n",
      "[33]\tvalidation_0-mlogloss:0.73359\n",
      "[34]\tvalidation_0-mlogloss:0.72281\n",
      "[35]\tvalidation_0-mlogloss:0.71055\n",
      "[36]\tvalidation_0-mlogloss:0.69985\n",
      "[37]\tvalidation_0-mlogloss:0.69158\n",
      "[38]\tvalidation_0-mlogloss:0.68179\n",
      "[39]\tvalidation_0-mlogloss:0.67267\n",
      "[40]\tvalidation_0-mlogloss:0.66351\n",
      "[41]\tvalidation_0-mlogloss:0.65514\n",
      "[42]\tvalidation_0-mlogloss:0.64546\n",
      "[43]\tvalidation_0-mlogloss:0.63725\n",
      "[44]\tvalidation_0-mlogloss:0.62952\n",
      "[45]\tvalidation_0-mlogloss:0.61969\n",
      "[46]\tvalidation_0-mlogloss:0.61075\n",
      "[47]\tvalidation_0-mlogloss:0.60324\n",
      "[48]\tvalidation_0-mlogloss:0.59421\n",
      "[49]\tvalidation_0-mlogloss:0.58777\n",
      "[50]\tvalidation_0-mlogloss:0.58056\n",
      "[51]\tvalidation_0-mlogloss:0.57542\n",
      "[52]\tvalidation_0-mlogloss:0.56771\n",
      "[53]\tvalidation_0-mlogloss:0.56172\n",
      "[54]\tvalidation_0-mlogloss:0.55550\n",
      "[55]\tvalidation_0-mlogloss:0.55025\n",
      "[56]\tvalidation_0-mlogloss:0.54423\n",
      "[57]\tvalidation_0-mlogloss:0.53685\n",
      "[58]\tvalidation_0-mlogloss:0.53278\n",
      "[59]\tvalidation_0-mlogloss:0.52868\n",
      "[60]\tvalidation_0-mlogloss:0.52190\n",
      "[61]\tvalidation_0-mlogloss:0.51665\n",
      "[62]\tvalidation_0-mlogloss:0.51233\n",
      "[63]\tvalidation_0-mlogloss:0.50841\n",
      "[64]\tvalidation_0-mlogloss:0.50398\n",
      "[65]\tvalidation_0-mlogloss:0.50035\n",
      "[66]\tvalidation_0-mlogloss:0.49573\n",
      "[67]\tvalidation_0-mlogloss:0.49115\n",
      "[68]\tvalidation_0-mlogloss:0.48729\n",
      "[69]\tvalidation_0-mlogloss:0.48316\n",
      "[70]\tvalidation_0-mlogloss:0.48008\n",
      "[71]\tvalidation_0-mlogloss:0.47609\n",
      "[72]\tvalidation_0-mlogloss:0.47208\n",
      "[73]\tvalidation_0-mlogloss:0.46884\n",
      "[74]\tvalidation_0-mlogloss:0.46533\n",
      "[75]\tvalidation_0-mlogloss:0.46214\n",
      "[76]\tvalidation_0-mlogloss:0.45909\n",
      "[77]\tvalidation_0-mlogloss:0.45559\n",
      "[78]\tvalidation_0-mlogloss:0.45242\n",
      "[79]\tvalidation_0-mlogloss:0.44927\n",
      "[80]\tvalidation_0-mlogloss:0.44516\n",
      "[81]\tvalidation_0-mlogloss:0.44107\n",
      "[82]\tvalidation_0-mlogloss:0.43833\n",
      "[83]\tvalidation_0-mlogloss:0.43519\n",
      "[84]\tvalidation_0-mlogloss:0.43342\n",
      "[85]\tvalidation_0-mlogloss:0.43140\n",
      "[86]\tvalidation_0-mlogloss:0.42845\n",
      "[87]\tvalidation_0-mlogloss:0.42577\n",
      "[88]\tvalidation_0-mlogloss:0.42247\n",
      "[89]\tvalidation_0-mlogloss:0.41945\n",
      "[90]\tvalidation_0-mlogloss:0.41703\n",
      "[91]\tvalidation_0-mlogloss:0.41431\n",
      "[92]\tvalidation_0-mlogloss:0.41218\n",
      "[93]\tvalidation_0-mlogloss:0.40993\n",
      "[94]\tvalidation_0-mlogloss:0.40684\n",
      "[95]\tvalidation_0-mlogloss:0.40409\n",
      "[96]\tvalidation_0-mlogloss:0.40200\n",
      "[97]\tvalidation_0-mlogloss:0.39972\n",
      "[98]\tvalidation_0-mlogloss:0.39772\n",
      "[99]\tvalidation_0-mlogloss:0.39456\n",
      "[100]\tvalidation_0-mlogloss:0.39207\n",
      "[101]\tvalidation_0-mlogloss:0.38942\n",
      "[102]\tvalidation_0-mlogloss:0.38804\n",
      "[103]\tvalidation_0-mlogloss:0.38580\n",
      "[104]\tvalidation_0-mlogloss:0.38288\n",
      "[105]\tvalidation_0-mlogloss:0.38074\n",
      "[106]\tvalidation_0-mlogloss:0.37872\n",
      "[107]\tvalidation_0-mlogloss:0.37677\n",
      "[108]\tvalidation_0-mlogloss:0.37470\n",
      "[109]\tvalidation_0-mlogloss:0.37284\n",
      "[110]\tvalidation_0-mlogloss:0.37109\n",
      "[111]\tvalidation_0-mlogloss:0.36872\n",
      "[112]\tvalidation_0-mlogloss:0.36667\n",
      "[113]\tvalidation_0-mlogloss:0.36523\n",
      "[114]\tvalidation_0-mlogloss:0.36335\n",
      "[115]\tvalidation_0-mlogloss:0.36077\n",
      "[116]\tvalidation_0-mlogloss:0.35895\n",
      "[117]\tvalidation_0-mlogloss:0.35699\n",
      "[118]\tvalidation_0-mlogloss:0.35532\n",
      "[119]\tvalidation_0-mlogloss:0.35455\n",
      "[120]\tvalidation_0-mlogloss:0.35332\n",
      "[121]\tvalidation_0-mlogloss:0.35180\n",
      "[122]\tvalidation_0-mlogloss:0.35006\n",
      "[123]\tvalidation_0-mlogloss:0.34870\n",
      "[124]\tvalidation_0-mlogloss:0.34709\n",
      "[125]\tvalidation_0-mlogloss:0.34487\n",
      "[126]\tvalidation_0-mlogloss:0.34403\n",
      "[127]\tvalidation_0-mlogloss:0.34322\n",
      "[128]\tvalidation_0-mlogloss:0.34153\n",
      "[129]\tvalidation_0-mlogloss:0.33962\n",
      "[130]\tvalidation_0-mlogloss:0.33896\n",
      "[131]\tvalidation_0-mlogloss:0.33767\n",
      "[132]\tvalidation_0-mlogloss:0.33630\n",
      "[133]\tvalidation_0-mlogloss:0.33500\n",
      "[134]\tvalidation_0-mlogloss:0.33378\n",
      "[135]\tvalidation_0-mlogloss:0.33234\n",
      "[136]\tvalidation_0-mlogloss:0.33143\n",
      "[137]\tvalidation_0-mlogloss:0.33002\n",
      "[138]\tvalidation_0-mlogloss:0.32884\n",
      "[139]\tvalidation_0-mlogloss:0.32785\n",
      "[140]\tvalidation_0-mlogloss:0.32689\n",
      "[141]\tvalidation_0-mlogloss:0.32662\n",
      "[142]\tvalidation_0-mlogloss:0.32611\n",
      "[143]\tvalidation_0-mlogloss:0.32502\n",
      "[144]\tvalidation_0-mlogloss:0.32417\n",
      "[145]\tvalidation_0-mlogloss:0.32308\n",
      "[146]\tvalidation_0-mlogloss:0.32216\n",
      "[147]\tvalidation_0-mlogloss:0.32099\n",
      "[148]\tvalidation_0-mlogloss:0.32024\n",
      "[149]\tvalidation_0-mlogloss:0.31945\n",
      "[150]\tvalidation_0-mlogloss:0.31834\n",
      "[151]\tvalidation_0-mlogloss:0.31791\n",
      "[152]\tvalidation_0-mlogloss:0.31641\n",
      "[153]\tvalidation_0-mlogloss:0.31539\n",
      "[154]\tvalidation_0-mlogloss:0.31483\n",
      "[155]\tvalidation_0-mlogloss:0.31401\n",
      "[156]\tvalidation_0-mlogloss:0.31322\n",
      "[157]\tvalidation_0-mlogloss:0.31259\n",
      "[158]\tvalidation_0-mlogloss:0.31204\n",
      "[159]\tvalidation_0-mlogloss:0.31119\n",
      "[160]\tvalidation_0-mlogloss:0.31059\n",
      "[161]\tvalidation_0-mlogloss:0.31005\n",
      "[162]\tvalidation_0-mlogloss:0.30889\n",
      "[163]\tvalidation_0-mlogloss:0.30820\n",
      "[164]\tvalidation_0-mlogloss:0.30769\n",
      "[165]\tvalidation_0-mlogloss:0.30720\n",
      "[166]\tvalidation_0-mlogloss:0.30697\n",
      "[167]\tvalidation_0-mlogloss:0.30623\n",
      "[168]\tvalidation_0-mlogloss:0.30622\n",
      "[169]\tvalidation_0-mlogloss:0.30579\n",
      "[170]\tvalidation_0-mlogloss:0.30570\n",
      "[171]\tvalidation_0-mlogloss:0.30481\n",
      "[172]\tvalidation_0-mlogloss:0.30415\n",
      "[173]\tvalidation_0-mlogloss:0.30326\n",
      "[174]\tvalidation_0-mlogloss:0.30284\n",
      "[175]\tvalidation_0-mlogloss:0.30183\n",
      "[176]\tvalidation_0-mlogloss:0.30090\n",
      "[177]\tvalidation_0-mlogloss:0.29976\n",
      "[178]\tvalidation_0-mlogloss:0.29902\n",
      "[179]\tvalidation_0-mlogloss:0.29838\n",
      "[180]\tvalidation_0-mlogloss:0.29777\n",
      "[181]\tvalidation_0-mlogloss:0.29712\n",
      "[182]\tvalidation_0-mlogloss:0.29663\n",
      "[183]\tvalidation_0-mlogloss:0.29588\n",
      "[184]\tvalidation_0-mlogloss:0.29484\n",
      "[185]\tvalidation_0-mlogloss:0.29430\n",
      "[186]\tvalidation_0-mlogloss:0.29337\n",
      "[187]\tvalidation_0-mlogloss:0.29307\n",
      "[188]\tvalidation_0-mlogloss:0.29239\n",
      "[189]\tvalidation_0-mlogloss:0.29217\n",
      "[190]\tvalidation_0-mlogloss:0.29120\n",
      "[191]\tvalidation_0-mlogloss:0.29060\n",
      "[192]\tvalidation_0-mlogloss:0.28983\n",
      "[193]\tvalidation_0-mlogloss:0.28940\n",
      "[194]\tvalidation_0-mlogloss:0.28913\n",
      "[195]\tvalidation_0-mlogloss:0.28855\n",
      "[196]\tvalidation_0-mlogloss:0.28834\n",
      "[197]\tvalidation_0-mlogloss:0.28791\n",
      "[198]\tvalidation_0-mlogloss:0.28765\n",
      "[199]\tvalidation_0-mlogloss:0.28705\n",
      "[200]\tvalidation_0-mlogloss:0.28638\n",
      "[201]\tvalidation_0-mlogloss:0.28614\n",
      "[202]\tvalidation_0-mlogloss:0.28543\n",
      "[203]\tvalidation_0-mlogloss:0.28474\n",
      "[204]\tvalidation_0-mlogloss:0.28442\n",
      "[205]\tvalidation_0-mlogloss:0.28395\n",
      "[206]\tvalidation_0-mlogloss:0.28345\n",
      "[207]\tvalidation_0-mlogloss:0.28250\n",
      "[208]\tvalidation_0-mlogloss:0.28199\n",
      "[209]\tvalidation_0-mlogloss:0.28156\n",
      "[210]\tvalidation_0-mlogloss:0.28113\n",
      "[211]\tvalidation_0-mlogloss:0.28080\n",
      "[212]\tvalidation_0-mlogloss:0.28044\n",
      "[213]\tvalidation_0-mlogloss:0.28011\n",
      "[214]\tvalidation_0-mlogloss:0.28035\n",
      "[215]\tvalidation_0-mlogloss:0.27998\n",
      "[216]\tvalidation_0-mlogloss:0.27947\n",
      "[217]\tvalidation_0-mlogloss:0.27901\n",
      "[218]\tvalidation_0-mlogloss:0.27860\n",
      "[219]\tvalidation_0-mlogloss:0.27818\n",
      "[220]\tvalidation_0-mlogloss:0.27763\n",
      "[221]\tvalidation_0-mlogloss:0.27771\n",
      "[222]\tvalidation_0-mlogloss:0.27756\n",
      "[223]\tvalidation_0-mlogloss:0.27703\n",
      "[224]\tvalidation_0-mlogloss:0.27674\n",
      "[225]\tvalidation_0-mlogloss:0.27641\n",
      "[226]\tvalidation_0-mlogloss:0.27601\n",
      "[227]\tvalidation_0-mlogloss:0.27576\n",
      "[228]\tvalidation_0-mlogloss:0.27558\n",
      "[229]\tvalidation_0-mlogloss:0.27557\n",
      "[230]\tvalidation_0-mlogloss:0.27536\n",
      "[231]\tvalidation_0-mlogloss:0.27462\n",
      "[232]\tvalidation_0-mlogloss:0.27443\n",
      "[233]\tvalidation_0-mlogloss:0.27412\n",
      "[234]\tvalidation_0-mlogloss:0.27360\n",
      "[235]\tvalidation_0-mlogloss:0.27360\n",
      "[236]\tvalidation_0-mlogloss:0.27310\n",
      "[237]\tvalidation_0-mlogloss:0.27309\n",
      "[238]\tvalidation_0-mlogloss:0.27288\n",
      "[239]\tvalidation_0-mlogloss:0.27305\n",
      "[240]\tvalidation_0-mlogloss:0.27253\n",
      "[241]\tvalidation_0-mlogloss:0.27223\n",
      "[242]\tvalidation_0-mlogloss:0.27178\n",
      "[243]\tvalidation_0-mlogloss:0.27139\n",
      "[244]\tvalidation_0-mlogloss:0.27105\n",
      "[245]\tvalidation_0-mlogloss:0.27079\n",
      "[246]\tvalidation_0-mlogloss:0.27033\n",
      "[247]\tvalidation_0-mlogloss:0.27019\n",
      "[248]\tvalidation_0-mlogloss:0.26979\n",
      "[249]\tvalidation_0-mlogloss:0.26952\n",
      "[250]\tvalidation_0-mlogloss:0.26928\n",
      "[251]\tvalidation_0-mlogloss:0.26865\n",
      "[252]\tvalidation_0-mlogloss:0.26825\n",
      "[253]\tvalidation_0-mlogloss:0.26789\n",
      "[254]\tvalidation_0-mlogloss:0.26747\n",
      "[255]\tvalidation_0-mlogloss:0.26699\n",
      "[256]\tvalidation_0-mlogloss:0.26685\n",
      "[257]\tvalidation_0-mlogloss:0.26639\n",
      "[258]\tvalidation_0-mlogloss:0.26562\n",
      "[259]\tvalidation_0-mlogloss:0.26566\n",
      "[260]\tvalidation_0-mlogloss:0.26560\n",
      "[261]\tvalidation_0-mlogloss:0.26538\n",
      "[262]\tvalidation_0-mlogloss:0.26524\n",
      "[263]\tvalidation_0-mlogloss:0.26493\n",
      "[264]\tvalidation_0-mlogloss:0.26492\n",
      "[265]\tvalidation_0-mlogloss:0.26483\n",
      "[266]\tvalidation_0-mlogloss:0.26486\n",
      "[267]\tvalidation_0-mlogloss:0.26455\n",
      "[268]\tvalidation_0-mlogloss:0.26457\n",
      "[269]\tvalidation_0-mlogloss:0.26426\n",
      "[270]\tvalidation_0-mlogloss:0.26393\n",
      "[271]\tvalidation_0-mlogloss:0.26348\n",
      "[272]\tvalidation_0-mlogloss:0.26323\n",
      "[273]\tvalidation_0-mlogloss:0.26310\n",
      "[274]\tvalidation_0-mlogloss:0.26315\n",
      "[275]\tvalidation_0-mlogloss:0.26310\n",
      "[276]\tvalidation_0-mlogloss:0.26271\n",
      "[277]\tvalidation_0-mlogloss:0.26238\n",
      "[278]\tvalidation_0-mlogloss:0.26195\n",
      "[279]\tvalidation_0-mlogloss:0.26189\n",
      "[280]\tvalidation_0-mlogloss:0.26145\n",
      "[281]\tvalidation_0-mlogloss:0.26132\n",
      "[282]\tvalidation_0-mlogloss:0.26117\n",
      "[283]\tvalidation_0-mlogloss:0.26115\n",
      "[284]\tvalidation_0-mlogloss:0.26104\n",
      "[285]\tvalidation_0-mlogloss:0.26065\n",
      "[286]\tvalidation_0-mlogloss:0.26047\n",
      "[287]\tvalidation_0-mlogloss:0.26029\n",
      "[288]\tvalidation_0-mlogloss:0.26012\n",
      "[289]\tvalidation_0-mlogloss:0.25999\n",
      "[290]\tvalidation_0-mlogloss:0.25947\n",
      "[291]\tvalidation_0-mlogloss:0.25943\n",
      "[292]\tvalidation_0-mlogloss:0.25910\n",
      "[293]\tvalidation_0-mlogloss:0.25880\n",
      "[294]\tvalidation_0-mlogloss:0.25861\n",
      "[295]\tvalidation_0-mlogloss:0.25805\n",
      "[296]\tvalidation_0-mlogloss:0.25764\n",
      "[297]\tvalidation_0-mlogloss:0.25774\n",
      "[298]\tvalidation_0-mlogloss:0.25740\n",
      "[299]\tvalidation_0-mlogloss:0.25715\n",
      "[300]\tvalidation_0-mlogloss:0.25728\n",
      "[301]\tvalidation_0-mlogloss:0.25712\n",
      "[302]\tvalidation_0-mlogloss:0.25688\n",
      "[303]\tvalidation_0-mlogloss:0.25674\n",
      "[304]\tvalidation_0-mlogloss:0.25659\n",
      "[305]\tvalidation_0-mlogloss:0.25625\n",
      "[306]\tvalidation_0-mlogloss:0.25596\n",
      "[307]\tvalidation_0-mlogloss:0.25585\n",
      "[308]\tvalidation_0-mlogloss:0.25594\n",
      "[309]\tvalidation_0-mlogloss:0.25587\n",
      "[310]\tvalidation_0-mlogloss:0.25599\n",
      "[311]\tvalidation_0-mlogloss:0.25555\n",
      "[312]\tvalidation_0-mlogloss:0.25563\n",
      "[313]\tvalidation_0-mlogloss:0.25556\n",
      "[314]\tvalidation_0-mlogloss:0.25515\n",
      "[315]\tvalidation_0-mlogloss:0.25501\n",
      "[316]\tvalidation_0-mlogloss:0.25470\n",
      "[317]\tvalidation_0-mlogloss:0.25460\n",
      "[318]\tvalidation_0-mlogloss:0.25433\n",
      "[319]\tvalidation_0-mlogloss:0.25413\n",
      "[320]\tvalidation_0-mlogloss:0.25380\n",
      "[321]\tvalidation_0-mlogloss:0.25361\n",
      "[322]\tvalidation_0-mlogloss:0.25330\n",
      "[323]\tvalidation_0-mlogloss:0.25342\n",
      "[324]\tvalidation_0-mlogloss:0.25324\n",
      "[325]\tvalidation_0-mlogloss:0.25321\n",
      "[326]\tvalidation_0-mlogloss:0.25307\n",
      "[327]\tvalidation_0-mlogloss:0.25309\n",
      "[328]\tvalidation_0-mlogloss:0.25295\n",
      "[329]\tvalidation_0-mlogloss:0.25304\n",
      "[330]\tvalidation_0-mlogloss:0.25301\n",
      "[331]\tvalidation_0-mlogloss:0.25272\n",
      "[332]\tvalidation_0-mlogloss:0.25282\n",
      "[333]\tvalidation_0-mlogloss:0.25284\n",
      "[334]\tvalidation_0-mlogloss:0.25281\n",
      "[335]\tvalidation_0-mlogloss:0.25264\n",
      "[336]\tvalidation_0-mlogloss:0.25250\n",
      "[337]\tvalidation_0-mlogloss:0.25245\n",
      "[338]\tvalidation_0-mlogloss:0.25239\n",
      "[339]\tvalidation_0-mlogloss:0.25229\n",
      "[340]\tvalidation_0-mlogloss:0.25199\n",
      "[341]\tvalidation_0-mlogloss:0.25184\n",
      "[342]\tvalidation_0-mlogloss:0.25178\n",
      "[343]\tvalidation_0-mlogloss:0.25178\n",
      "[344]\tvalidation_0-mlogloss:0.25137\n",
      "[345]\tvalidation_0-mlogloss:0.25125\n",
      "[346]\tvalidation_0-mlogloss:0.25129\n",
      "[347]\tvalidation_0-mlogloss:0.25110\n",
      "[348]\tvalidation_0-mlogloss:0.25105\n",
      "[349]\tvalidation_0-mlogloss:0.25111\n",
      "[350]\tvalidation_0-mlogloss:0.25100\n",
      "[351]\tvalidation_0-mlogloss:0.25086\n",
      "[352]\tvalidation_0-mlogloss:0.25065\n",
      "[353]\tvalidation_0-mlogloss:0.25058\n",
      "[354]\tvalidation_0-mlogloss:0.25055\n",
      "[355]\tvalidation_0-mlogloss:0.25048\n",
      "[356]\tvalidation_0-mlogloss:0.25046\n",
      "[357]\tvalidation_0-mlogloss:0.25037\n",
      "[358]\tvalidation_0-mlogloss:0.25020\n",
      "[359]\tvalidation_0-mlogloss:0.25007\n",
      "[360]\tvalidation_0-mlogloss:0.24989\n",
      "[361]\tvalidation_0-mlogloss:0.24989\n",
      "[362]\tvalidation_0-mlogloss:0.24966\n",
      "[363]\tvalidation_0-mlogloss:0.24973\n",
      "[364]\tvalidation_0-mlogloss:0.24941\n",
      "[365]\tvalidation_0-mlogloss:0.24934\n",
      "[366]\tvalidation_0-mlogloss:0.24926\n",
      "[367]\tvalidation_0-mlogloss:0.24919\n",
      "[368]\tvalidation_0-mlogloss:0.24924\n",
      "[369]\tvalidation_0-mlogloss:0.24926\n",
      "[370]\tvalidation_0-mlogloss:0.24938\n",
      "[371]\tvalidation_0-mlogloss:0.24946\n",
      "[372]\tvalidation_0-mlogloss:0.24958\n",
      "[373]\tvalidation_0-mlogloss:0.24960\n",
      "[374]\tvalidation_0-mlogloss:0.24917\n",
      "[375]\tvalidation_0-mlogloss:0.24877\n",
      "[376]\tvalidation_0-mlogloss:0.24872\n",
      "[377]\tvalidation_0-mlogloss:0.24863\n",
      "[378]\tvalidation_0-mlogloss:0.24862\n",
      "[379]\tvalidation_0-mlogloss:0.24861\n",
      "[380]\tvalidation_0-mlogloss:0.24871\n",
      "[381]\tvalidation_0-mlogloss:0.24838\n",
      "[382]\tvalidation_0-mlogloss:0.24845\n",
      "[383]\tvalidation_0-mlogloss:0.24845\n",
      "[384]\tvalidation_0-mlogloss:0.24834\n",
      "[385]\tvalidation_0-mlogloss:0.24838\n",
      "[386]\tvalidation_0-mlogloss:0.24838\n",
      "[387]\tvalidation_0-mlogloss:0.24834\n",
      "[388]\tvalidation_0-mlogloss:0.24832\n",
      "[389]\tvalidation_0-mlogloss:0.24827\n",
      "[390]\tvalidation_0-mlogloss:0.24823\n",
      "[391]\tvalidation_0-mlogloss:0.24823\n",
      "[392]\tvalidation_0-mlogloss:0.24826\n",
      "[393]\tvalidation_0-mlogloss:0.24818\n",
      "[394]\tvalidation_0-mlogloss:0.24816\n",
      "[395]\tvalidation_0-mlogloss:0.24810\n",
      "[396]\tvalidation_0-mlogloss:0.24807\n",
      "[397]\tvalidation_0-mlogloss:0.24790\n",
      "[398]\tvalidation_0-mlogloss:0.24799\n",
      "[399]\tvalidation_0-mlogloss:0.24784\n",
      "[400]\tvalidation_0-mlogloss:0.24792\n",
      "[401]\tvalidation_0-mlogloss:0.24795\n",
      "[402]\tvalidation_0-mlogloss:0.24771\n",
      "[403]\tvalidation_0-mlogloss:0.24777\n",
      "[404]\tvalidation_0-mlogloss:0.24766\n",
      "[405]\tvalidation_0-mlogloss:0.24764\n",
      "[406]\tvalidation_0-mlogloss:0.24730\n",
      "[407]\tvalidation_0-mlogloss:0.24716\n",
      "[408]\tvalidation_0-mlogloss:0.24720\n",
      "[409]\tvalidation_0-mlogloss:0.24720\n",
      "[410]\tvalidation_0-mlogloss:0.24705\n",
      "[411]\tvalidation_0-mlogloss:0.24709\n",
      "[412]\tvalidation_0-mlogloss:0.24693\n",
      "[413]\tvalidation_0-mlogloss:0.24673\n",
      "[414]\tvalidation_0-mlogloss:0.24664\n",
      "[415]\tvalidation_0-mlogloss:0.24661\n",
      "[416]\tvalidation_0-mlogloss:0.24669\n",
      "[417]\tvalidation_0-mlogloss:0.24663\n",
      "[418]\tvalidation_0-mlogloss:0.24649\n",
      "[419]\tvalidation_0-mlogloss:0.24643\n",
      "[420]\tvalidation_0-mlogloss:0.24618\n",
      "[421]\tvalidation_0-mlogloss:0.24621\n",
      "[422]\tvalidation_0-mlogloss:0.24587\n",
      "[423]\tvalidation_0-mlogloss:0.24567\n",
      "[424]\tvalidation_0-mlogloss:0.24577\n",
      "[425]\tvalidation_0-mlogloss:0.24569\n",
      "[426]\tvalidation_0-mlogloss:0.24556\n",
      "[427]\tvalidation_0-mlogloss:0.24556\n",
      "[428]\tvalidation_0-mlogloss:0.24545\n",
      "[429]\tvalidation_0-mlogloss:0.24548\n",
      "[430]\tvalidation_0-mlogloss:0.24538\n",
      "[431]\tvalidation_0-mlogloss:0.24522\n",
      "[432]\tvalidation_0-mlogloss:0.24508\n",
      "[433]\tvalidation_0-mlogloss:0.24511\n",
      "[434]\tvalidation_0-mlogloss:0.24510\n",
      "[435]\tvalidation_0-mlogloss:0.24484\n",
      "[436]\tvalidation_0-mlogloss:0.24472\n",
      "[437]\tvalidation_0-mlogloss:0.24472\n",
      "[438]\tvalidation_0-mlogloss:0.24465\n",
      "[439]\tvalidation_0-mlogloss:0.24467\n",
      "[440]\tvalidation_0-mlogloss:0.24452\n",
      "[441]\tvalidation_0-mlogloss:0.24439\n",
      "[442]\tvalidation_0-mlogloss:0.24425\n",
      "[443]\tvalidation_0-mlogloss:0.24436\n",
      "[444]\tvalidation_0-mlogloss:0.24432\n",
      "[445]\tvalidation_0-mlogloss:0.24427\n",
      "[446]\tvalidation_0-mlogloss:0.24416\n",
      "[447]\tvalidation_0-mlogloss:0.24417\n",
      "[448]\tvalidation_0-mlogloss:0.24431\n",
      "[449]\tvalidation_0-mlogloss:0.24433\n",
      "[450]\tvalidation_0-mlogloss:0.24417\n",
      "[451]\tvalidation_0-mlogloss:0.24411\n",
      "[452]\tvalidation_0-mlogloss:0.24410\n",
      "[453]\tvalidation_0-mlogloss:0.24411\n",
      "[454]\tvalidation_0-mlogloss:0.24397\n",
      "[455]\tvalidation_0-mlogloss:0.24402\n",
      "[456]\tvalidation_0-mlogloss:0.24394\n",
      "[457]\tvalidation_0-mlogloss:0.24395\n",
      "[458]\tvalidation_0-mlogloss:0.24380\n",
      "[459]\tvalidation_0-mlogloss:0.24392\n",
      "[460]\tvalidation_0-mlogloss:0.24387\n",
      "[461]\tvalidation_0-mlogloss:0.24372\n",
      "[462]\tvalidation_0-mlogloss:0.24366\n",
      "[463]\tvalidation_0-mlogloss:0.24361\n",
      "[464]\tvalidation_0-mlogloss:0.24348\n",
      "[465]\tvalidation_0-mlogloss:0.24341\n",
      "[466]\tvalidation_0-mlogloss:0.24332\n",
      "[467]\tvalidation_0-mlogloss:0.24314\n",
      "[468]\tvalidation_0-mlogloss:0.24297\n",
      "[469]\tvalidation_0-mlogloss:0.24288\n",
      "[470]\tvalidation_0-mlogloss:0.24309\n",
      "[471]\tvalidation_0-mlogloss:0.24289\n",
      "[472]\tvalidation_0-mlogloss:0.24273\n",
      "[473]\tvalidation_0-mlogloss:0.24278\n",
      "[474]\tvalidation_0-mlogloss:0.24267\n",
      "[475]\tvalidation_0-mlogloss:0.24247\n",
      "[476]\tvalidation_0-mlogloss:0.24257\n",
      "[477]\tvalidation_0-mlogloss:0.24241\n",
      "[478]\tvalidation_0-mlogloss:0.24245\n",
      "[479]\tvalidation_0-mlogloss:0.24236\n",
      "[480]\tvalidation_0-mlogloss:0.24235\n",
      "[481]\tvalidation_0-mlogloss:0.24220\n",
      "[482]\tvalidation_0-mlogloss:0.24207\n",
      "[483]\tvalidation_0-mlogloss:0.24205\n",
      "[484]\tvalidation_0-mlogloss:0.24209\n",
      "[485]\tvalidation_0-mlogloss:0.24213\n",
      "[486]\tvalidation_0-mlogloss:0.24202\n",
      "[487]\tvalidation_0-mlogloss:0.24203\n",
      "[488]\tvalidation_0-mlogloss:0.24197\n",
      "[489]\tvalidation_0-mlogloss:0.24205\n",
      "[490]\tvalidation_0-mlogloss:0.24215\n",
      "[491]\tvalidation_0-mlogloss:0.24192\n",
      "[492]\tvalidation_0-mlogloss:0.24174\n",
      "[493]\tvalidation_0-mlogloss:0.24178\n",
      "[494]\tvalidation_0-mlogloss:0.24177\n",
      "[495]\tvalidation_0-mlogloss:0.24187\n",
      "[496]\tvalidation_0-mlogloss:0.24188\n",
      "[497]\tvalidation_0-mlogloss:0.24202\n",
      "[498]\tvalidation_0-mlogloss:0.24204\n",
      "[499]\tvalidation_0-mlogloss:0.24201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      1499\n",
      "           1       0.96      0.98      0.97      1499\n",
      "           2       0.88      0.77      0.82      1499\n",
      "           3       0.98      0.95      0.97      1499\n",
      "           4       0.98      0.99      0.99      1499\n",
      "           5       0.99      1.00      1.00      1499\n",
      "           6       0.98      0.99      0.98      1499\n",
      "           7       0.94      0.94      0.94      1499\n",
      "           8       0.67      0.96      0.79      1499\n",
      "           9       0.97      0.86      0.91      1499\n",
      "          10       0.97      0.97      0.97      1499\n",
      "          11       0.99      0.99      0.99      1499\n",
      "          12       0.84      0.95      0.89      1499\n",
      "          13       0.97      0.97      0.97      1499\n",
      "          14       0.80      0.94      0.87      1499\n",
      "          15       0.97      0.73      0.83      1499\n",
      "          16       0.93      0.50      0.65      1499\n",
      "          17       0.95      0.99      0.97      1499\n",
      "          18       0.92      0.90      0.91      1499\n",
      "          19       0.97      0.90      0.93      1499\n",
      "          20       0.99      1.00      1.00      1499\n",
      "          21       0.89      0.96      0.93      1499\n",
      "          22       0.81      0.85      0.83      1499\n",
      "          23       0.99      1.00      0.99      1499\n",
      "          24       0.97      0.97      0.97      1499\n",
      "\n",
      "    accuracy                           0.92     37475\n",
      "   macro avg       0.93      0.92      0.92     37475\n",
      "weighted avg       0.93      0.92      0.92     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4=XGBClassifier(n_estimators=500)\n",
    "model4.fit(x,y,early_stopping_rounds=10, eval_set=[(xv, yv)])\n",
    "y_pred=model4.predict(xt)\n",
    "print(classification_report(yt,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1dad4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model3 = Sequential(\n",
    "    [\n",
    "        Dense(64, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(25, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3361defb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.4762 - val_loss: 1.1126\n",
      "Epoch 2/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.1566 - val_loss: 0.9054\n",
      "Epoch 3/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.1129 - val_loss: 0.9296\n",
      "Epoch 4/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.0930 - val_loss: 1.0749\n",
      "Epoch 5/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.0798 - val_loss: 0.9580\n",
      "Epoch 6/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.0705 - val_loss: 1.0339\n",
      "Epoch 7/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.0631 - val_loss: 0.8885\n",
      "Epoch 8/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.0584 - val_loss: 0.9629\n",
      "Epoch 9/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.0543 - val_loss: 0.8999\n",
      "Epoch 10/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.0509 - val_loss: 0.8847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f16625ee4a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model3.fit(\n",
    "    x,y,epochs=10,validation_data=(xv,yv)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43017064",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 123/1172 [==>...........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 824us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.73      0.81      1499\n",
      "           1       0.91      0.96      0.93      1499\n",
      "           2       0.83      0.78      0.80      1499\n",
      "           3       0.73      0.98      0.84      1499\n",
      "           4       0.95      0.99      0.97      1499\n",
      "           5       0.94      0.99      0.96      1499\n",
      "           6       0.94      0.99      0.96      1499\n",
      "           7       0.97      0.77      0.86      1499\n",
      "           8       0.77      0.88      0.82      1499\n",
      "           9       0.87      0.85      0.86      1499\n",
      "          10       0.88      0.69      0.78      1499\n",
      "          11       0.93      0.90      0.91      1499\n",
      "          12       0.74      0.92      0.82      1499\n",
      "          13       0.80      0.97      0.87      1499\n",
      "          14       0.60      0.88      0.72      1499\n",
      "          15       0.92      0.39      0.55      1499\n",
      "          16       0.85      0.69      0.76      1499\n",
      "          17       1.00      0.96      0.98      1499\n",
      "          18       0.90      0.80      0.85      1499\n",
      "          19       0.94      0.87      0.90      1499\n",
      "          20       1.00      0.99      0.99      1499\n",
      "          21       0.88      0.90      0.89      1499\n",
      "          22       0.75      0.87      0.80      1499\n",
      "          23       0.98      0.98      0.98      1499\n",
      "          24       0.98      0.95      0.97      1499\n",
      "\n",
      "    accuracy                           0.87     37475\n",
      "   macro avg       0.88      0.87      0.86     37475\n",
      "weighted avg       0.88      0.87      0.86     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model3.predict(xt)).numpy(),axis=1)\n",
    "print(classification_report(yt,y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "231da1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79      1499\n",
      "           1       0.91      0.96      0.93      1499\n",
      "           2       0.81      0.72      0.76      1499\n",
      "           3       0.98      0.93      0.95      1499\n",
      "           4       0.97      0.98      0.98      1499\n",
      "           5       0.98      0.98      0.98      1499\n",
      "           6       0.96      0.97      0.96      1499\n",
      "           7       0.92      0.87      0.90      1499\n",
      "           8       0.65      0.94      0.77      1499\n",
      "           9       0.98      0.82      0.89      1499\n",
      "          10       0.95      0.93      0.94      1499\n",
      "          11       0.95      0.96      0.96      1499\n",
      "          12       0.78      0.90      0.84      1499\n",
      "          13       0.94      0.93      0.93      1499\n",
      "          14       0.75      0.88      0.81      1499\n",
      "          15       0.93      0.73      0.81      1499\n",
      "          16       0.92      0.44      0.60      1499\n",
      "          17       0.94      0.98      0.96      1499\n",
      "          18       0.82      0.83      0.83      1499\n",
      "          19       0.93      0.89      0.91      1499\n",
      "          20       0.99      1.00      0.99      1499\n",
      "          21       0.87      0.93      0.90      1499\n",
      "          22       0.74      0.77      0.75      1499\n",
      "          23       0.98      0.99      0.99      1499\n",
      "          24       0.96      0.97      0.96      1499\n",
      "\n",
      "    accuracy                           0.89     37475\n",
      "   macro avg       0.89      0.89      0.88     37475\n",
      "weighted avg       0.89      0.89      0.88     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model4=XGBClassifier()\n",
    "model4.fit(x,y)\n",
    "y_pred=model4.predict(xt)\n",
    "print(classification_report(yt,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9e21c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.18258\n",
      "[1]\tvalidation_0-mlogloss:1.86592\n",
      "[2]\tvalidation_0-mlogloss:1.68784\n",
      "[3]\tvalidation_0-mlogloss:1.55050\n",
      "[4]\tvalidation_0-mlogloss:1.44391\n",
      "[5]\tvalidation_0-mlogloss:1.34707\n",
      "[6]\tvalidation_0-mlogloss:1.27419\n",
      "[7]\tvalidation_0-mlogloss:1.20788\n",
      "[8]\tvalidation_0-mlogloss:1.14848\n",
      "[9]\tvalidation_0-mlogloss:1.10192\n",
      "[10]\tvalidation_0-mlogloss:1.05679\n",
      "[11]\tvalidation_0-mlogloss:1.01284\n",
      "[12]\tvalidation_0-mlogloss:0.97881\n",
      "[13]\tvalidation_0-mlogloss:0.94522\n",
      "[14]\tvalidation_0-mlogloss:0.91180\n",
      "[15]\tvalidation_0-mlogloss:0.88008\n",
      "[16]\tvalidation_0-mlogloss:0.85301\n",
      "[17]\tvalidation_0-mlogloss:0.82647\n",
      "[18]\tvalidation_0-mlogloss:0.80048\n",
      "[19]\tvalidation_0-mlogloss:0.77987\n",
      "[20]\tvalidation_0-mlogloss:0.76109\n",
      "[21]\tvalidation_0-mlogloss:0.74467\n",
      "[22]\tvalidation_0-mlogloss:0.72866\n",
      "[23]\tvalidation_0-mlogloss:0.71225\n",
      "[24]\tvalidation_0-mlogloss:0.69797\n",
      "[25]\tvalidation_0-mlogloss:0.68085\n",
      "[26]\tvalidation_0-mlogloss:0.66956\n",
      "[27]\tvalidation_0-mlogloss:0.65700\n",
      "[28]\tvalidation_0-mlogloss:0.64518\n",
      "[29]\tvalidation_0-mlogloss:0.63288\n",
      "[30]\tvalidation_0-mlogloss:0.61993\n",
      "[31]\tvalidation_0-mlogloss:0.61129\n",
      "[32]\tvalidation_0-mlogloss:0.59841\n",
      "[33]\tvalidation_0-mlogloss:0.58771\n",
      "[34]\tvalidation_0-mlogloss:0.57701\n",
      "[35]\tvalidation_0-mlogloss:0.56621\n",
      "[36]\tvalidation_0-mlogloss:0.55994\n",
      "[37]\tvalidation_0-mlogloss:0.55084\n",
      "[38]\tvalidation_0-mlogloss:0.53973\n",
      "[39]\tvalidation_0-mlogloss:0.53317\n",
      "[40]\tvalidation_0-mlogloss:0.52503\n",
      "[41]\tvalidation_0-mlogloss:0.51828\n",
      "[42]\tvalidation_0-mlogloss:0.51290\n",
      "[43]\tvalidation_0-mlogloss:0.50688\n",
      "[44]\tvalidation_0-mlogloss:0.49891\n",
      "[45]\tvalidation_0-mlogloss:0.49558\n",
      "[46]\tvalidation_0-mlogloss:0.49036\n",
      "[47]\tvalidation_0-mlogloss:0.48660\n",
      "[48]\tvalidation_0-mlogloss:0.47857\n",
      "[49]\tvalidation_0-mlogloss:0.47147\n",
      "[50]\tvalidation_0-mlogloss:0.46640\n",
      "[51]\tvalidation_0-mlogloss:0.46258\n",
      "[52]\tvalidation_0-mlogloss:0.45819\n",
      "[53]\tvalidation_0-mlogloss:0.45537\n",
      "[54]\tvalidation_0-mlogloss:0.45151\n",
      "[55]\tvalidation_0-mlogloss:0.44595\n",
      "[56]\tvalidation_0-mlogloss:0.44194\n",
      "[57]\tvalidation_0-mlogloss:0.43668\n",
      "[58]\tvalidation_0-mlogloss:0.43316\n",
      "[59]\tvalidation_0-mlogloss:0.42864\n",
      "[60]\tvalidation_0-mlogloss:0.42667\n",
      "[61]\tvalidation_0-mlogloss:0.42449\n",
      "[62]\tvalidation_0-mlogloss:0.42098\n",
      "[63]\tvalidation_0-mlogloss:0.41772\n",
      "[64]\tvalidation_0-mlogloss:0.41452\n",
      "[65]\tvalidation_0-mlogloss:0.41233\n",
      "[66]\tvalidation_0-mlogloss:0.40868\n",
      "[67]\tvalidation_0-mlogloss:0.40524\n",
      "[68]\tvalidation_0-mlogloss:0.40296\n",
      "[69]\tvalidation_0-mlogloss:0.40068\n",
      "[70]\tvalidation_0-mlogloss:0.39828\n",
      "[71]\tvalidation_0-mlogloss:0.39614\n",
      "[72]\tvalidation_0-mlogloss:0.39349\n",
      "[73]\tvalidation_0-mlogloss:0.39169\n",
      "[74]\tvalidation_0-mlogloss:0.38955\n",
      "[75]\tvalidation_0-mlogloss:0.38751\n",
      "[76]\tvalidation_0-mlogloss:0.38533\n",
      "[77]\tvalidation_0-mlogloss:0.38258\n",
      "[78]\tvalidation_0-mlogloss:0.38100\n",
      "[79]\tvalidation_0-mlogloss:0.37925\n",
      "[80]\tvalidation_0-mlogloss:0.37655\n",
      "[81]\tvalidation_0-mlogloss:0.37412\n",
      "[82]\tvalidation_0-mlogloss:0.37250\n",
      "[83]\tvalidation_0-mlogloss:0.36931\n",
      "[84]\tvalidation_0-mlogloss:0.36721\n",
      "[85]\tvalidation_0-mlogloss:0.36590\n",
      "[86]\tvalidation_0-mlogloss:0.36398\n",
      "[87]\tvalidation_0-mlogloss:0.36314\n",
      "[88]\tvalidation_0-mlogloss:0.36171\n",
      "[89]\tvalidation_0-mlogloss:0.35988\n",
      "[90]\tvalidation_0-mlogloss:0.35847\n",
      "[91]\tvalidation_0-mlogloss:0.35758\n",
      "[92]\tvalidation_0-mlogloss:0.35623\n",
      "[93]\tvalidation_0-mlogloss:0.35514\n",
      "[94]\tvalidation_0-mlogloss:0.35386\n",
      "[95]\tvalidation_0-mlogloss:0.35211\n",
      "[96]\tvalidation_0-mlogloss:0.35081\n",
      "[97]\tvalidation_0-mlogloss:0.34936\n",
      "[98]\tvalidation_0-mlogloss:0.34743\n",
      "[99]\tvalidation_0-mlogloss:0.34651\n",
      "[100]\tvalidation_0-mlogloss:0.34341\n",
      "[101]\tvalidation_0-mlogloss:0.34174\n",
      "[102]\tvalidation_0-mlogloss:0.33975\n",
      "[103]\tvalidation_0-mlogloss:0.33818\n",
      "[104]\tvalidation_0-mlogloss:0.33722\n",
      "[105]\tvalidation_0-mlogloss:0.33575\n",
      "[106]\tvalidation_0-mlogloss:0.33509\n",
      "[107]\tvalidation_0-mlogloss:0.33459\n",
      "[108]\tvalidation_0-mlogloss:0.33276\n",
      "[109]\tvalidation_0-mlogloss:0.33159\n",
      "[110]\tvalidation_0-mlogloss:0.33099\n",
      "[111]\tvalidation_0-mlogloss:0.32966\n",
      "[112]\tvalidation_0-mlogloss:0.32866\n",
      "[113]\tvalidation_0-mlogloss:0.32752\n",
      "[114]\tvalidation_0-mlogloss:0.32734\n",
      "[115]\tvalidation_0-mlogloss:0.32695\n",
      "[116]\tvalidation_0-mlogloss:0.32528\n",
      "[117]\tvalidation_0-mlogloss:0.32369\n",
      "[118]\tvalidation_0-mlogloss:0.32275\n",
      "[119]\tvalidation_0-mlogloss:0.32241\n",
      "[120]\tvalidation_0-mlogloss:0.32139\n",
      "[121]\tvalidation_0-mlogloss:0.32033\n",
      "[122]\tvalidation_0-mlogloss:0.31865\n",
      "[123]\tvalidation_0-mlogloss:0.31874\n",
      "[124]\tvalidation_0-mlogloss:0.31780\n",
      "[125]\tvalidation_0-mlogloss:0.31706\n",
      "[126]\tvalidation_0-mlogloss:0.31625\n",
      "[127]\tvalidation_0-mlogloss:0.31593\n",
      "[128]\tvalidation_0-mlogloss:0.31545\n",
      "[129]\tvalidation_0-mlogloss:0.31510\n",
      "[130]\tvalidation_0-mlogloss:0.31475\n",
      "[131]\tvalidation_0-mlogloss:0.31393\n",
      "[132]\tvalidation_0-mlogloss:0.31304\n",
      "[133]\tvalidation_0-mlogloss:0.31201\n",
      "[134]\tvalidation_0-mlogloss:0.31118\n",
      "[135]\tvalidation_0-mlogloss:0.31072\n",
      "[136]\tvalidation_0-mlogloss:0.31023\n",
      "[137]\tvalidation_0-mlogloss:0.30959\n",
      "[138]\tvalidation_0-mlogloss:0.30946\n",
      "[139]\tvalidation_0-mlogloss:0.30865\n",
      "[140]\tvalidation_0-mlogloss:0.30777\n",
      "[141]\tvalidation_0-mlogloss:0.30765\n",
      "[142]\tvalidation_0-mlogloss:0.30674\n",
      "[143]\tvalidation_0-mlogloss:0.30689\n",
      "[144]\tvalidation_0-mlogloss:0.30636\n",
      "[145]\tvalidation_0-mlogloss:0.30606\n",
      "[146]\tvalidation_0-mlogloss:0.30530\n",
      "[147]\tvalidation_0-mlogloss:0.30482\n",
      "[148]\tvalidation_0-mlogloss:0.30396\n",
      "[149]\tvalidation_0-mlogloss:0.30323\n",
      "[150]\tvalidation_0-mlogloss:0.30218\n",
      "[151]\tvalidation_0-mlogloss:0.30172\n",
      "[152]\tvalidation_0-mlogloss:0.30106\n",
      "[153]\tvalidation_0-mlogloss:0.30060\n",
      "[154]\tvalidation_0-mlogloss:0.29991\n",
      "[155]\tvalidation_0-mlogloss:0.29958\n",
      "[156]\tvalidation_0-mlogloss:0.29923\n",
      "[157]\tvalidation_0-mlogloss:0.29891\n",
      "[158]\tvalidation_0-mlogloss:0.29798\n",
      "[159]\tvalidation_0-mlogloss:0.29712\n",
      "[160]\tvalidation_0-mlogloss:0.29670\n",
      "[161]\tvalidation_0-mlogloss:0.29663\n",
      "[162]\tvalidation_0-mlogloss:0.29581\n",
      "[163]\tvalidation_0-mlogloss:0.29514\n",
      "[164]\tvalidation_0-mlogloss:0.29451\n",
      "[165]\tvalidation_0-mlogloss:0.29372\n",
      "[166]\tvalidation_0-mlogloss:0.29337\n",
      "[167]\tvalidation_0-mlogloss:0.29348\n",
      "[168]\tvalidation_0-mlogloss:0.29276\n",
      "[169]\tvalidation_0-mlogloss:0.29247\n",
      "[170]\tvalidation_0-mlogloss:0.29170\n",
      "[171]\tvalidation_0-mlogloss:0.29067\n",
      "[172]\tvalidation_0-mlogloss:0.28968\n",
      "[173]\tvalidation_0-mlogloss:0.28951\n",
      "[174]\tvalidation_0-mlogloss:0.28915\n",
      "[175]\tvalidation_0-mlogloss:0.28912\n",
      "[176]\tvalidation_0-mlogloss:0.28916\n",
      "[177]\tvalidation_0-mlogloss:0.28919\n",
      "[178]\tvalidation_0-mlogloss:0.28873\n",
      "[179]\tvalidation_0-mlogloss:0.28760\n",
      "[180]\tvalidation_0-mlogloss:0.28780\n",
      "[181]\tvalidation_0-mlogloss:0.28747\n",
      "[182]\tvalidation_0-mlogloss:0.28696\n",
      "[183]\tvalidation_0-mlogloss:0.28656\n",
      "[184]\tvalidation_0-mlogloss:0.28634\n",
      "[185]\tvalidation_0-mlogloss:0.28667\n",
      "[186]\tvalidation_0-mlogloss:0.28637\n",
      "[187]\tvalidation_0-mlogloss:0.28626\n",
      "[188]\tvalidation_0-mlogloss:0.28646\n",
      "[189]\tvalidation_0-mlogloss:0.28621\n",
      "[190]\tvalidation_0-mlogloss:0.28598\n",
      "[191]\tvalidation_0-mlogloss:0.28569\n",
      "[192]\tvalidation_0-mlogloss:0.28532\n",
      "[193]\tvalidation_0-mlogloss:0.28493\n",
      "[194]\tvalidation_0-mlogloss:0.28458\n",
      "[195]\tvalidation_0-mlogloss:0.28402\n",
      "[196]\tvalidation_0-mlogloss:0.28444\n",
      "[197]\tvalidation_0-mlogloss:0.28442\n",
      "[198]\tvalidation_0-mlogloss:0.28427\n",
      "[199]\tvalidation_0-mlogloss:0.28410\n",
      "[200]\tvalidation_0-mlogloss:0.28366\n",
      "[201]\tvalidation_0-mlogloss:0.28365\n",
      "[202]\tvalidation_0-mlogloss:0.28353\n",
      "[203]\tvalidation_0-mlogloss:0.28359\n",
      "[204]\tvalidation_0-mlogloss:0.28404\n",
      "[205]\tvalidation_0-mlogloss:0.28387\n",
      "[206]\tvalidation_0-mlogloss:0.28356\n",
      "[207]\tvalidation_0-mlogloss:0.28352\n",
      "[208]\tvalidation_0-mlogloss:0.28349\n",
      "[209]\tvalidation_0-mlogloss:0.28294\n",
      "[210]\tvalidation_0-mlogloss:0.28316\n",
      "[211]\tvalidation_0-mlogloss:0.28256\n",
      "[212]\tvalidation_0-mlogloss:0.28210\n",
      "[213]\tvalidation_0-mlogloss:0.28166\n",
      "[214]\tvalidation_0-mlogloss:0.28135\n",
      "[215]\tvalidation_0-mlogloss:0.28164\n",
      "[216]\tvalidation_0-mlogloss:0.28159\n",
      "[217]\tvalidation_0-mlogloss:0.28115\n",
      "[218]\tvalidation_0-mlogloss:0.28097\n",
      "[219]\tvalidation_0-mlogloss:0.28065\n",
      "[220]\tvalidation_0-mlogloss:0.28051\n",
      "[221]\tvalidation_0-mlogloss:0.28034\n",
      "[222]\tvalidation_0-mlogloss:0.28028\n",
      "[223]\tvalidation_0-mlogloss:0.28015\n",
      "[224]\tvalidation_0-mlogloss:0.27998\n",
      "[225]\tvalidation_0-mlogloss:0.27987\n",
      "[226]\tvalidation_0-mlogloss:0.27945\n",
      "[227]\tvalidation_0-mlogloss:0.27915\n",
      "[228]\tvalidation_0-mlogloss:0.27911\n",
      "[229]\tvalidation_0-mlogloss:0.27900\n",
      "[230]\tvalidation_0-mlogloss:0.27877\n",
      "[231]\tvalidation_0-mlogloss:0.27843\n",
      "[232]\tvalidation_0-mlogloss:0.27843\n",
      "[233]\tvalidation_0-mlogloss:0.27833\n",
      "[234]\tvalidation_0-mlogloss:0.27835\n",
      "[235]\tvalidation_0-mlogloss:0.27839\n",
      "[236]\tvalidation_0-mlogloss:0.27854\n",
      "[237]\tvalidation_0-mlogloss:0.27835\n",
      "[238]\tvalidation_0-mlogloss:0.27856\n",
      "[239]\tvalidation_0-mlogloss:0.27829\n",
      "[240]\tvalidation_0-mlogloss:0.27817\n",
      "[241]\tvalidation_0-mlogloss:0.27802\n",
      "[242]\tvalidation_0-mlogloss:0.27776\n",
      "[243]\tvalidation_0-mlogloss:0.27790\n",
      "[244]\tvalidation_0-mlogloss:0.27803\n",
      "[245]\tvalidation_0-mlogloss:0.27740\n",
      "[246]\tvalidation_0-mlogloss:0.27740\n",
      "[247]\tvalidation_0-mlogloss:0.27717\n",
      "[248]\tvalidation_0-mlogloss:0.27702\n",
      "[249]\tvalidation_0-mlogloss:0.27689\n",
      "[250]\tvalidation_0-mlogloss:0.27682\n",
      "[251]\tvalidation_0-mlogloss:0.27650\n",
      "[252]\tvalidation_0-mlogloss:0.27634\n",
      "[253]\tvalidation_0-mlogloss:0.27623\n",
      "[254]\tvalidation_0-mlogloss:0.27608\n",
      "[255]\tvalidation_0-mlogloss:0.27563\n",
      "[256]\tvalidation_0-mlogloss:0.27543\n",
      "[257]\tvalidation_0-mlogloss:0.27553\n",
      "[258]\tvalidation_0-mlogloss:0.27574\n",
      "[259]\tvalidation_0-mlogloss:0.27546\n",
      "[260]\tvalidation_0-mlogloss:0.27506\n",
      "[261]\tvalidation_0-mlogloss:0.27505\n",
      "[262]\tvalidation_0-mlogloss:0.27470\n",
      "[263]\tvalidation_0-mlogloss:0.27484\n",
      "[264]\tvalidation_0-mlogloss:0.27450\n",
      "[265]\tvalidation_0-mlogloss:0.27457\n",
      "[266]\tvalidation_0-mlogloss:0.27436\n",
      "[267]\tvalidation_0-mlogloss:0.27438\n",
      "[268]\tvalidation_0-mlogloss:0.27431\n",
      "[269]\tvalidation_0-mlogloss:0.27418\n",
      "[270]\tvalidation_0-mlogloss:0.27433\n",
      "[271]\tvalidation_0-mlogloss:0.27406\n",
      "[272]\tvalidation_0-mlogloss:0.27388\n",
      "[273]\tvalidation_0-mlogloss:0.27393\n",
      "[274]\tvalidation_0-mlogloss:0.27393\n",
      "[275]\tvalidation_0-mlogloss:0.27357\n",
      "[276]\tvalidation_0-mlogloss:0.27356\n",
      "[277]\tvalidation_0-mlogloss:0.27345\n",
      "[278]\tvalidation_0-mlogloss:0.27318\n",
      "[279]\tvalidation_0-mlogloss:0.27304\n",
      "[280]\tvalidation_0-mlogloss:0.27278\n",
      "[281]\tvalidation_0-mlogloss:0.27270\n",
      "[282]\tvalidation_0-mlogloss:0.27248\n",
      "[283]\tvalidation_0-mlogloss:0.27261\n",
      "[284]\tvalidation_0-mlogloss:0.27248\n",
      "[285]\tvalidation_0-mlogloss:0.27225\n",
      "[286]\tvalidation_0-mlogloss:0.27217\n",
      "[287]\tvalidation_0-mlogloss:0.27223\n",
      "[288]\tvalidation_0-mlogloss:0.27237\n",
      "[289]\tvalidation_0-mlogloss:0.27209\n",
      "[290]\tvalidation_0-mlogloss:0.27190\n",
      "[291]\tvalidation_0-mlogloss:0.27201\n",
      "[292]\tvalidation_0-mlogloss:0.27195\n",
      "[293]\tvalidation_0-mlogloss:0.27176\n",
      "[294]\tvalidation_0-mlogloss:0.27159\n",
      "[295]\tvalidation_0-mlogloss:0.27181\n",
      "[296]\tvalidation_0-mlogloss:0.27189\n",
      "[297]\tvalidation_0-mlogloss:0.27200\n",
      "[298]\tvalidation_0-mlogloss:0.27207\n",
      "[299]\tvalidation_0-mlogloss:0.27205\n",
      "[300]\tvalidation_0-mlogloss:0.27185\n",
      "[301]\tvalidation_0-mlogloss:0.27179\n",
      "[302]\tvalidation_0-mlogloss:0.27211\n",
      "[303]\tvalidation_0-mlogloss:0.27188\n",
      "[304]\tvalidation_0-mlogloss:0.27171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      1499\n",
      "           1       0.95      0.98      0.97      1499\n",
      "           2       0.87      0.78      0.82      1499\n",
      "           3       0.98      0.96      0.97      1499\n",
      "           4       0.96      0.99      0.98      1499\n",
      "           5       0.99      1.00      0.99      1499\n",
      "           6       0.97      0.99      0.98      1499\n",
      "           7       0.93      0.92      0.92      1499\n",
      "           8       0.64      0.94      0.76      1499\n",
      "           9       0.96      0.84      0.90      1499\n",
      "          10       0.97      0.96      0.96      1499\n",
      "          11       0.99      0.99      0.99      1499\n",
      "          12       0.83      0.94      0.89      1499\n",
      "          13       0.98      0.96      0.97      1499\n",
      "          14       0.78      0.94      0.85      1499\n",
      "          15       0.97      0.69      0.80      1499\n",
      "          16       0.89      0.42      0.57      1499\n",
      "          17       0.95      1.00      0.97      1499\n",
      "          18       0.91      0.90      0.91      1499\n",
      "          19       0.97      0.90      0.93      1499\n",
      "          20       0.99      1.00      0.99      1499\n",
      "          21       0.89      0.94      0.92      1499\n",
      "          22       0.80      0.84      0.82      1499\n",
      "          23       0.98      1.00      0.99      1499\n",
      "          24       0.97      0.98      0.97      1499\n",
      "\n",
      "    accuracy                           0.91     37475\n",
      "   macro avg       0.92      0.91      0.91     37475\n",
      "weighted avg       0.92      0.91      0.91     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators = 500, learning_rate = 0.5,verbosity = 1, random_state = 55)\n",
    "xgb_model.fit(x,y, eval_set = [(xv,yv)], early_stopping_rounds = 10)\n",
    "y_pred=xgb_model.predict(xt)\n",
    "print(classification_report(yt,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6e4884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
