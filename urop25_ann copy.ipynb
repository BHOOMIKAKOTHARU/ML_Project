{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c862b2bf",
   "metadata": {},
   "source": [
    "# 25 persons\n",
    "## electrodes : 8, 16, 32, 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77ce0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "081a3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne in /usr/local/python/3.10.8/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/codespace/.local/lib/python3.10/site-packages (from mne) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.3 in /home/codespace/.local/lib/python3.10/site-packages (from mne) (1.11.3)\n",
      "Requirement already satisfied: matplotlib>=3.4.0 in /home/codespace/.local/lib/python3.10/site-packages (from mne) (3.8.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.8/lib/python3.10/site-packages (from mne) (4.66.1)\n",
      "Requirement already satisfied: pooch>=1.5 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from mne) (1.7.0)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.10/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from mne) (23.1)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.10/site-packages (from mne) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (0.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (4.43.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.10/site-packages (from matplotlib>=3.4.0->mne) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/codespace/.local/lib/python3.10/site-packages (from pooch>=1.5->mne) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/codespace/.local/lib/python3.10/site-packages (from pooch>=1.5->mne) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from jinja2->mne) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.4.0->mne) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42d4276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_patients=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9085fdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files2/S001R04.edf',\n",
       " 'files2/S002R04.edf',\n",
       " 'files2/S003R04.edf',\n",
       " 'files2/S004R04.edf',\n",
       " 'files2/S005R04.edf',\n",
       " 'files2/S006R04.edf',\n",
       " 'files2/S007R04.edf',\n",
       " 'files2/S008R04.edf',\n",
       " 'files2/S009R04.edf',\n",
       " 'files2/S010R04.edf',\n",
       " 'files2/S011R04.edf',\n",
       " 'files2/S012R04.edf',\n",
       " 'files2/S013R04.edf',\n",
       " 'files2/S014R04.edf',\n",
       " 'files2/S015R04.edf',\n",
       " 'files2/S016R04.edf',\n",
       " 'files2/S017R04.edf',\n",
       " 'files2/S018R04.edf',\n",
       " 'files2/S019R04.edf',\n",
       " 'files2/S020R04.edf',\n",
       " 'files2/S021R04.edf',\n",
       " 'files2/S022R04.edf',\n",
       " 'files2/S023R04.edf',\n",
       " 'files2/S024R04.edf',\n",
       " 'files2/S025R04.edf']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=sorted(glob('files2/*.edf'))\n",
    "train=train[:no_of_patients]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddb63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(i,train_split,valid_split):\n",
    "    raw = mne.io.read_raw_edf(i, preload=True)\n",
    "    eeg_data = raw.get_data()\n",
    "    eeg_channels = [f'Channel_{i}' for i in range(eeg_data.shape[0])]\n",
    "    eeg_df = pd.DataFrame(data=eeg_data.T, columns=eeg_channels)\n",
    "    \n",
    "    eeg_df = eeg_df.iloc[:15000]\n",
    "    eeg_df.sample(frac=1)\n",
    "    \n",
    "    idx1= int(train_split*(len(eeg_df)))\n",
    "    idx2= int(train_split*(len(eeg_df)))+1\n",
    "    eeg_df1=eeg_df.iloc[:idx1]\n",
    "    eeg_df2=eeg_df.iloc[idx2:]\n",
    "    idx3=int(valid_split*(len(eeg_df2)))\n",
    "    idx4=int(valid_split*(len(eeg_df2)))+1\n",
    "    eeg_df3=eeg_df2.iloc[:idx3]\n",
    "    eeg_df4=eeg_df2.iloc[idx4:]\n",
    "    return eeg_df1,eeg_df3,eeg_df4,len(eeg_df1),len(eeg_df3),len(eeg_df4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65857e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "xtemp1=[]\n",
    "xtemp2=[]\n",
    "xtemp3=[]\n",
    "ytemp1=[]\n",
    "ytemp2=[]\n",
    "ytemp3=[]\n",
    "for i in range(no_of_patients):\n",
    "    xtr,xte,xval,ytr,yte,yval=read_data(train[i],0.8,0.5) # xtr=xtrain, xte=xtest, ytr=ytrain, yte=ytest.\n",
    "    xtemp1.append(xtr)\n",
    "    xtemp2.append(xte)\n",
    "    xtemp3.append(xval)\n",
    "    ytemp1.append(ytr)\n",
    "    ytemp2.append(yte)\n",
    "    ytemp3.append(yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aeb31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.concat([xtemp1[i] for i in range(0, len(xtemp1))], ignore_index=True)\n",
    "xtest = pd.concat([xtemp2[i] for i in range(0, len(xtemp2))], ignore_index=True)\n",
    "xvalid=pd.concat([xtemp3[i] for i in range(0,len(xtemp3))],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a47802ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=[]\n",
    "for i in range(len(ytemp1)):\n",
    "    for j in range(ytemp1[i-1]):\n",
    "        ytrain.append(i)\n",
    "ytest=[]\n",
    "for i in range(len(ytemp2)):\n",
    "    for j in range(ytemp2[i-1]):\n",
    "        ytest.append(i)        \n",
    "yvalid=[]\n",
    "for i in range(len(ytemp3)):\n",
    "    for j in range(ytemp3[i-1]):\n",
    "        yvalid.append(i)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "705fd1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 37475, 300000, 37475)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain),len(xtest),len(ytrain),len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec6d73ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0e-05  1.5e-05  6.0e-06 ...  4.0e-06  1.0e-06  3.0e-06]\n"
     ]
    }
   ],
   "source": [
    "print(xtest.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8738bdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_0</th>\n",
       "      <th>Channel_1</th>\n",
       "      <th>Channel_2</th>\n",
       "      <th>Channel_3</th>\n",
       "      <th>Channel_4</th>\n",
       "      <th>Channel_5</th>\n",
       "      <th>Channel_6</th>\n",
       "      <th>Channel_7</th>\n",
       "      <th>Channel_8</th>\n",
       "      <th>Channel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Channel_54</th>\n",
       "      <th>Channel_55</th>\n",
       "      <th>Channel_56</th>\n",
       "      <th>Channel_57</th>\n",
       "      <th>Channel_58</th>\n",
       "      <th>Channel_59</th>\n",
       "      <th>Channel_60</th>\n",
       "      <th>Channel_61</th>\n",
       "      <th>Channel_62</th>\n",
       "      <th>Channel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Channel_0  Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  \\\n",
       "0       -0.000005   0.000002   0.000037   0.000039   0.000030   0.000026   \n",
       "1       -0.000012  -0.000024   0.000001  -0.000002  -0.000015  -0.000022   \n",
       "2       -0.000077  -0.000078  -0.000059  -0.000065  -0.000063  -0.000055   \n",
       "3       -0.000066  -0.000067  -0.000050  -0.000065  -0.000060  -0.000055   \n",
       "4       -0.000045  -0.000055  -0.000033  -0.000053  -0.000054  -0.000063   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "299995   0.000000   0.000008   0.000001   0.000003  -0.000005   0.000001   \n",
       "299996  -0.000006   0.000014   0.000009   0.000012   0.000005   0.000010   \n",
       "299997   0.000008   0.000017   0.000016   0.000021   0.000009   0.000010   \n",
       "299998  -0.000017  -0.000003  -0.000001   0.000004  -0.000005  -0.000004   \n",
       "299999  -0.000024  -0.000006  -0.000007  -0.000003  -0.000009  -0.000003   \n",
       "\n",
       "        Channel_6  Channel_7  Channel_8  Channel_9  ...  Channel_54  \\\n",
       "0       -0.000016  -0.000014   0.000004   0.000018  ...   -0.000021   \n",
       "1       -0.000055  -0.000036  -0.000027  -0.000025  ...   -0.000050   \n",
       "2       -0.000067  -0.000088  -0.000071  -0.000065  ...   -0.000017   \n",
       "3       -0.000068  -0.000062  -0.000053  -0.000054  ...   -0.000039   \n",
       "4       -0.000083  -0.000052  -0.000050  -0.000053  ...   -0.000044   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "299995  -0.000003  -0.000008  -0.000004   0.000007  ...   -0.000009   \n",
       "299996   0.000007  -0.000002  -0.000001   0.000012  ...   -0.000005   \n",
       "299997   0.000005  -0.000002  -0.000002   0.000014  ...   -0.000012   \n",
       "299998  -0.000006  -0.000018  -0.000015   0.000002  ...   -0.000010   \n",
       "299999  -0.000002  -0.000020  -0.000016   0.000002  ...   -0.000007   \n",
       "\n",
       "        Channel_55  Channel_56  Channel_57  Channel_58  Channel_59  \\\n",
       "0        -0.000008   -0.000035   -0.000045   -0.000066   -0.000039   \n",
       "1        -0.000040   -0.000068   -0.000065   -0.000084   -0.000052   \n",
       "2        -0.000022   -0.000050   -0.000035   -0.000048   -0.000018   \n",
       "3        -0.000060   -0.000078   -0.000064   -0.000068   -0.000041   \n",
       "4        -0.000055   -0.000070   -0.000054   -0.000063   -0.000037   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "299995    0.000000    0.000009    0.000017    0.000005    0.000002   \n",
       "299996    0.000006    0.000013    0.000018    0.000007    0.000012   \n",
       "299997   -0.000003    0.000002    0.000004   -0.000008   -0.000005   \n",
       "299998   -0.000004    0.000000    0.000004   -0.000007   -0.000002   \n",
       "299999   -0.000004    0.000000    0.000002   -0.000010   -0.000007   \n",
       "\n",
       "        Channel_60  Channel_61  Channel_62  Channel_63  \n",
       "0        -0.000033   -0.000048   -0.000039   -0.000039  \n",
       "1        -0.000021   -0.000042   -0.000031   -0.000034  \n",
       "2        -0.000020   -0.000042   -0.000029   -0.000027  \n",
       "3        -0.000044   -0.000062   -0.000034   -0.000043  \n",
       "4        -0.000060   -0.000070   -0.000034   -0.000045  \n",
       "...            ...         ...         ...         ...  \n",
       "299995    0.000015    0.000003    0.000004    0.000012  \n",
       "299996    0.000015    0.000009    0.000012    0.000017  \n",
       "299997    0.000005   -0.000011   -0.000010   -0.000004  \n",
       "299998    0.000004   -0.000011   -0.000009   -0.000003  \n",
       "299999    0.000001   -0.000008   -0.000008    0.000000  \n",
       "\n",
       "[300000 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "459d7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(dataframe):\n",
    "    x=dataframe.iloc[:,:-1].values\n",
    "    y=dataframe.iloc[:,-1].values\n",
    "    scaler =StandardScaler()\n",
    "    x=scaler.fit_transform(x)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabeaa2",
   "metadata": {},
   "source": [
    "## 0-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3172e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain8=xtrain.iloc[:,:8]\n",
    "xvalid8=xvalid.iloc[:,:8]\n",
    "xtest8=xtest.iloc[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "904c30f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10231/394288547.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtrain8['id']=ytrain\n",
      "/tmp/ipykernel_10231/394288547.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtest8['id']=ytest\n",
      "/tmp/ipykernel_10231/394288547.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xvalid8['id']=yvalid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_0</th>\n",
       "      <th>Channel_1</th>\n",
       "      <th>Channel_2</th>\n",
       "      <th>Channel_3</th>\n",
       "      <th>Channel_4</th>\n",
       "      <th>Channel_5</th>\n",
       "      <th>Channel_6</th>\n",
       "      <th>Channel_7</th>\n",
       "      <th>Channel_8</th>\n",
       "      <th>Channel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Channel_54</th>\n",
       "      <th>Channel_55</th>\n",
       "      <th>Channel_56</th>\n",
       "      <th>Channel_57</th>\n",
       "      <th>Channel_58</th>\n",
       "      <th>Channel_59</th>\n",
       "      <th>Channel_60</th>\n",
       "      <th>Channel_61</th>\n",
       "      <th>Channel_62</th>\n",
       "      <th>Channel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Channel_0  Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  \\\n",
       "0       -0.000005   0.000002   0.000037   0.000039   0.000030   0.000026   \n",
       "1       -0.000012  -0.000024   0.000001  -0.000002  -0.000015  -0.000022   \n",
       "2       -0.000077  -0.000078  -0.000059  -0.000065  -0.000063  -0.000055   \n",
       "3       -0.000066  -0.000067  -0.000050  -0.000065  -0.000060  -0.000055   \n",
       "4       -0.000045  -0.000055  -0.000033  -0.000053  -0.000054  -0.000063   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "299995   0.000000   0.000008   0.000001   0.000003  -0.000005   0.000001   \n",
       "299996  -0.000006   0.000014   0.000009   0.000012   0.000005   0.000010   \n",
       "299997   0.000008   0.000017   0.000016   0.000021   0.000009   0.000010   \n",
       "299998  -0.000017  -0.000003  -0.000001   0.000004  -0.000005  -0.000004   \n",
       "299999  -0.000024  -0.000006  -0.000007  -0.000003  -0.000009  -0.000003   \n",
       "\n",
       "        Channel_6  Channel_7  Channel_8  Channel_9  ...  Channel_54  \\\n",
       "0       -0.000016  -0.000014   0.000004   0.000018  ...   -0.000021   \n",
       "1       -0.000055  -0.000036  -0.000027  -0.000025  ...   -0.000050   \n",
       "2       -0.000067  -0.000088  -0.000071  -0.000065  ...   -0.000017   \n",
       "3       -0.000068  -0.000062  -0.000053  -0.000054  ...   -0.000039   \n",
       "4       -0.000083  -0.000052  -0.000050  -0.000053  ...   -0.000044   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "299995  -0.000003  -0.000008  -0.000004   0.000007  ...   -0.000009   \n",
       "299996   0.000007  -0.000002  -0.000001   0.000012  ...   -0.000005   \n",
       "299997   0.000005  -0.000002  -0.000002   0.000014  ...   -0.000012   \n",
       "299998  -0.000006  -0.000018  -0.000015   0.000002  ...   -0.000010   \n",
       "299999  -0.000002  -0.000020  -0.000016   0.000002  ...   -0.000007   \n",
       "\n",
       "        Channel_55  Channel_56  Channel_57  Channel_58  Channel_59  \\\n",
       "0        -0.000008   -0.000035   -0.000045   -0.000066   -0.000039   \n",
       "1        -0.000040   -0.000068   -0.000065   -0.000084   -0.000052   \n",
       "2        -0.000022   -0.000050   -0.000035   -0.000048   -0.000018   \n",
       "3        -0.000060   -0.000078   -0.000064   -0.000068   -0.000041   \n",
       "4        -0.000055   -0.000070   -0.000054   -0.000063   -0.000037   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "299995    0.000000    0.000009    0.000017    0.000005    0.000002   \n",
       "299996    0.000006    0.000013    0.000018    0.000007    0.000012   \n",
       "299997   -0.000003    0.000002    0.000004   -0.000008   -0.000005   \n",
       "299998   -0.000004    0.000000    0.000004   -0.000007   -0.000002   \n",
       "299999   -0.000004    0.000000    0.000002   -0.000010   -0.000007   \n",
       "\n",
       "        Channel_60  Channel_61  Channel_62  Channel_63  \n",
       "0        -0.000033   -0.000048   -0.000039   -0.000039  \n",
       "1        -0.000021   -0.000042   -0.000031   -0.000034  \n",
       "2        -0.000020   -0.000042   -0.000029   -0.000027  \n",
       "3        -0.000044   -0.000062   -0.000034   -0.000043  \n",
       "4        -0.000060   -0.000070   -0.000034   -0.000045  \n",
       "...            ...         ...         ...         ...  \n",
       "299995    0.000015    0.000003    0.000004    0.000012  \n",
       "299996    0.000015    0.000009    0.000012    0.000017  \n",
       "299997    0.000005   -0.000011   -0.000010   -0.000004  \n",
       "299998    0.000004   -0.000011   -0.000009   -0.000003  \n",
       "299999    0.000001   -0.000008   -0.000008    0.000000  \n",
       "\n",
       "[300000 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain8['id']=ytrain\n",
    "xtest8['id']=ytest\n",
    "xvalid8['id']=yvalid\n",
    "display(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b732f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x8,y8=scale_dataset(xtrain8)\n",
    "xt8,yt8=scale_dataset(xtest8)\n",
    "xv8,yv8=scale_dataset(xvalid8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.93145\n",
      "[1]\tvalidation_0-mlogloss:2.81771\n",
      "[2]\tvalidation_0-mlogloss:2.73923\n",
      "[3]\tvalidation_0-mlogloss:2.67700\n",
      "[4]\tvalidation_0-mlogloss:2.62570\n",
      "[5]\tvalidation_0-mlogloss:2.58917\n",
      "[6]\tvalidation_0-mlogloss:2.55329\n",
      "[7]\tvalidation_0-mlogloss:2.52323\n",
      "[8]\tvalidation_0-mlogloss:2.49181\n",
      "[9]\tvalidation_0-mlogloss:2.47261\n",
      "[10]\tvalidation_0-mlogloss:2.45166\n",
      "[11]\tvalidation_0-mlogloss:2.43362\n",
      "[12]\tvalidation_0-mlogloss:2.41513\n",
      "[13]\tvalidation_0-mlogloss:2.40333\n",
      "[14]\tvalidation_0-mlogloss:2.39216\n",
      "[15]\tvalidation_0-mlogloss:2.37805\n",
      "[16]\tvalidation_0-mlogloss:2.36761\n",
      "[17]\tvalidation_0-mlogloss:2.35508\n",
      "[18]\tvalidation_0-mlogloss:2.34854\n",
      "[19]\tvalidation_0-mlogloss:2.33602\n",
      "[20]\tvalidation_0-mlogloss:2.32327\n",
      "[21]\tvalidation_0-mlogloss:2.31347\n",
      "[22]\tvalidation_0-mlogloss:2.30482\n",
      "[23]\tvalidation_0-mlogloss:2.30002\n",
      "[24]\tvalidation_0-mlogloss:2.28978\n",
      "[25]\tvalidation_0-mlogloss:2.28668\n",
      "[26]\tvalidation_0-mlogloss:2.28195\n",
      "[27]\tvalidation_0-mlogloss:2.27670\n",
      "[28]\tvalidation_0-mlogloss:2.26881\n",
      "[29]\tvalidation_0-mlogloss:2.26466\n",
      "[30]\tvalidation_0-mlogloss:2.25900\n",
      "[31]\tvalidation_0-mlogloss:2.25137\n",
      "[32]\tvalidation_0-mlogloss:2.24711\n",
      "[33]\tvalidation_0-mlogloss:2.24086\n",
      "[34]\tvalidation_0-mlogloss:2.23779\n",
      "[35]\tvalidation_0-mlogloss:2.23162\n",
      "[36]\tvalidation_0-mlogloss:2.23076\n",
      "[37]\tvalidation_0-mlogloss:2.22428\n",
      "[38]\tvalidation_0-mlogloss:2.22200\n",
      "[39]\tvalidation_0-mlogloss:2.21606\n",
      "[40]\tvalidation_0-mlogloss:2.21524\n",
      "[41]\tvalidation_0-mlogloss:2.21113\n",
      "[42]\tvalidation_0-mlogloss:2.20539\n",
      "[43]\tvalidation_0-mlogloss:2.20099\n",
      "[44]\tvalidation_0-mlogloss:2.19772\n",
      "[45]\tvalidation_0-mlogloss:2.19368\n",
      "[46]\tvalidation_0-mlogloss:2.18907\n",
      "[47]\tvalidation_0-mlogloss:2.18636\n",
      "[48]\tvalidation_0-mlogloss:2.18474\n",
      "[49]\tvalidation_0-mlogloss:2.17879\n",
      "[50]\tvalidation_0-mlogloss:2.17791\n",
      "[51]\tvalidation_0-mlogloss:2.17082\n",
      "[52]\tvalidation_0-mlogloss:2.16579\n",
      "[53]\tvalidation_0-mlogloss:2.16396\n",
      "[54]\tvalidation_0-mlogloss:2.15743\n",
      "[55]\tvalidation_0-mlogloss:2.15364\n",
      "[56]\tvalidation_0-mlogloss:2.15103\n",
      "[57]\tvalidation_0-mlogloss:2.14620\n",
      "[58]\tvalidation_0-mlogloss:2.14488\n",
      "[59]\tvalidation_0-mlogloss:2.14048\n",
      "[60]\tvalidation_0-mlogloss:2.13655\n",
      "[61]\tvalidation_0-mlogloss:2.13372\n",
      "[62]\tvalidation_0-mlogloss:2.13060\n",
      "[63]\tvalidation_0-mlogloss:2.13157\n",
      "[64]\tvalidation_0-mlogloss:2.12914\n",
      "[65]\tvalidation_0-mlogloss:2.12701\n",
      "[66]\tvalidation_0-mlogloss:2.12443\n",
      "[67]\tvalidation_0-mlogloss:2.12285\n",
      "[68]\tvalidation_0-mlogloss:2.12151\n",
      "[69]\tvalidation_0-mlogloss:2.12040\n",
      "[70]\tvalidation_0-mlogloss:2.11738\n",
      "[71]\tvalidation_0-mlogloss:2.11335\n",
      "[72]\tvalidation_0-mlogloss:2.10955\n",
      "[73]\tvalidation_0-mlogloss:2.10988\n",
      "[74]\tvalidation_0-mlogloss:2.11159\n",
      "[75]\tvalidation_0-mlogloss:2.10930\n",
      "[76]\tvalidation_0-mlogloss:2.10950\n",
      "[77]\tvalidation_0-mlogloss:2.10589\n",
      "[78]\tvalidation_0-mlogloss:2.10438\n",
      "[79]\tvalidation_0-mlogloss:2.10300\n",
      "[80]\tvalidation_0-mlogloss:2.10162\n",
      "[81]\tvalidation_0-mlogloss:2.09870\n",
      "[82]\tvalidation_0-mlogloss:2.09413\n",
      "[83]\tvalidation_0-mlogloss:2.09592\n",
      "[84]\tvalidation_0-mlogloss:2.09305\n",
      "[85]\tvalidation_0-mlogloss:2.09064\n",
      "[86]\tvalidation_0-mlogloss:2.08768\n",
      "[87]\tvalidation_0-mlogloss:2.08568\n",
      "[88]\tvalidation_0-mlogloss:2.08269\n",
      "[89]\tvalidation_0-mlogloss:2.08086\n",
      "[90]\tvalidation_0-mlogloss:2.07732\n",
      "[91]\tvalidation_0-mlogloss:2.07456\n",
      "[92]\tvalidation_0-mlogloss:2.07221\n",
      "[93]\tvalidation_0-mlogloss:2.07103\n",
      "[94]\tvalidation_0-mlogloss:2.06902\n",
      "[95]\tvalidation_0-mlogloss:2.06645\n",
      "[96]\tvalidation_0-mlogloss:2.06477\n",
      "[97]\tvalidation_0-mlogloss:2.06307\n",
      "[98]\tvalidation_0-mlogloss:2.06028\n",
      "[99]\tvalidation_0-mlogloss:2.05775\n",
      "[100]\tvalidation_0-mlogloss:2.05727\n",
      "[101]\tvalidation_0-mlogloss:2.05573\n",
      "[102]\tvalidation_0-mlogloss:2.05454\n",
      "[103]\tvalidation_0-mlogloss:2.05293\n",
      "[104]\tvalidation_0-mlogloss:2.05177\n",
      "[105]\tvalidation_0-mlogloss:2.05146\n",
      "[106]\tvalidation_0-mlogloss:2.04946\n",
      "[107]\tvalidation_0-mlogloss:2.04805\n",
      "[108]\tvalidation_0-mlogloss:2.04840\n",
      "[109]\tvalidation_0-mlogloss:2.04695\n",
      "[110]\tvalidation_0-mlogloss:2.04477\n",
      "[111]\tvalidation_0-mlogloss:2.04494\n",
      "[112]\tvalidation_0-mlogloss:2.04291\n",
      "[113]\tvalidation_0-mlogloss:2.04079\n",
      "[114]\tvalidation_0-mlogloss:2.03936\n",
      "[115]\tvalidation_0-mlogloss:2.03803\n",
      "[116]\tvalidation_0-mlogloss:2.03655\n",
      "[117]\tvalidation_0-mlogloss:2.03465\n",
      "[118]\tvalidation_0-mlogloss:2.03246\n",
      "[119]\tvalidation_0-mlogloss:2.03239\n",
      "[120]\tvalidation_0-mlogloss:2.02927\n",
      "[121]\tvalidation_0-mlogloss:2.02800\n",
      "[122]\tvalidation_0-mlogloss:2.02589\n",
      "[123]\tvalidation_0-mlogloss:2.02461\n",
      "[124]\tvalidation_0-mlogloss:2.02385\n",
      "[125]\tvalidation_0-mlogloss:2.02331\n",
      "[126]\tvalidation_0-mlogloss:2.02475\n",
      "[127]\tvalidation_0-mlogloss:2.02223\n",
      "[128]\tvalidation_0-mlogloss:2.02138\n",
      "[129]\tvalidation_0-mlogloss:2.01979\n",
      "[130]\tvalidation_0-mlogloss:2.01923\n",
      "[131]\tvalidation_0-mlogloss:2.01676\n",
      "[132]\tvalidation_0-mlogloss:2.01419\n",
      "[133]\tvalidation_0-mlogloss:2.01614\n",
      "[134]\tvalidation_0-mlogloss:2.01400\n",
      "[135]\tvalidation_0-mlogloss:2.01265\n",
      "[136]\tvalidation_0-mlogloss:2.01199\n",
      "[137]\tvalidation_0-mlogloss:2.01076\n",
      "[138]\tvalidation_0-mlogloss:2.00929\n",
      "[139]\tvalidation_0-mlogloss:2.00706\n",
      "[140]\tvalidation_0-mlogloss:2.00508\n",
      "[141]\tvalidation_0-mlogloss:2.00401\n",
      "[142]\tvalidation_0-mlogloss:2.00321\n",
      "[143]\tvalidation_0-mlogloss:2.00214\n",
      "[144]\tvalidation_0-mlogloss:2.00325\n",
      "[145]\tvalidation_0-mlogloss:2.00269\n",
      "[146]\tvalidation_0-mlogloss:2.00061\n",
      "[147]\tvalidation_0-mlogloss:1.99933\n",
      "[148]\tvalidation_0-mlogloss:1.99849\n",
      "[149]\tvalidation_0-mlogloss:1.99728\n",
      "[150]\tvalidation_0-mlogloss:1.99982\n",
      "[151]\tvalidation_0-mlogloss:2.00119\n",
      "[152]\tvalidation_0-mlogloss:2.00098\n",
      "[153]\tvalidation_0-mlogloss:1.99948\n",
      "[154]\tvalidation_0-mlogloss:1.99834\n",
      "[155]\tvalidation_0-mlogloss:1.99910\n",
      "[156]\tvalidation_0-mlogloss:2.00122\n",
      "[157]\tvalidation_0-mlogloss:1.99953\n",
      "[158]\tvalidation_0-mlogloss:1.99919\n",
      "[159]\tvalidation_0-mlogloss:1.99875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.33      0.30      1499\n",
      "           1       0.29      0.46      0.35      1499\n",
      "           2       0.51      0.44      0.47      1499\n",
      "           3       0.52      0.46      0.49      1499\n",
      "           4       0.71      0.77      0.74      1499\n",
      "           5       0.38      0.55      0.45      1499\n",
      "           6       0.40      0.61      0.48      1499\n",
      "           7       0.41      0.35      0.38      1499\n",
      "           8       0.47      0.61      0.53      1499\n",
      "           9       0.72      0.63      0.67      1499\n",
      "          10       0.19      0.17      0.18      1499\n",
      "          11       0.20      0.10      0.13      1499\n",
      "          12       0.17      0.11      0.14      1499\n",
      "          13       0.21      0.19      0.20      1499\n",
      "          14       0.25      0.14      0.18      1499\n",
      "          15       0.31      0.33      0.32      1499\n",
      "          16       0.71      0.59      0.64      1499\n",
      "          17       0.59      0.68      0.63      1499\n",
      "          18       0.23      0.17      0.19      1499\n",
      "          19       0.23      0.30      0.26      1499\n",
      "          20       0.59      0.63      0.61      1499\n",
      "          21       0.58      0.49      0.53      1499\n",
      "          22       0.30      0.25      0.27      1499\n",
      "          23       0.61      0.71      0.66      1499\n",
      "          24       0.32      0.28      0.30      1499\n",
      "\n",
      "    accuracy                           0.41     37475\n",
      "   macro avg       0.41      0.41      0.40     37475\n",
      "weighted avg       0.41      0.41      0.40     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=XGBClassifier(n_estimators=500)\n",
    "model.fit(x8,y8,early_stopping_rounds=10, eval_set=[(xv8, yv8)])\n",
    "y_pred=model.predict(xt8)\n",
    "print(classification_report(yt8,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b271d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(8, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(25, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0aee87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 14s 1ms/step - loss: 1.9082 - val_loss: 2.0191\n",
      "Epoch 2/10\n",
      "9375/9375 [==============================] - 15s 2ms/step - loss: 1.3610 - val_loss: 2.1657\n",
      "Epoch 3/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 1.2310 - val_loss: 2.2872\n",
      "Epoch 4/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 1.1771 - val_loss: 2.2815\n",
      "Epoch 5/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 1.1443 - val_loss: 2.4766\n",
      "Epoch 6/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 1.1229 - val_loss: 2.4708\n",
      "Epoch 7/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 1.1049 - val_loss: 2.4606\n",
      "Epoch 8/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 1.0906 - val_loss: 2.4856\n",
      "Epoch 9/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 1.0790 - val_loss: 2.6716\n",
      "Epoch 10/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 1.0679 - val_loss: 2.6965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f185b3b3e20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x8,y8,epochs=10,validation_data=(xv8,yv8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "badca670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 114/1172 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 867us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.47      0.36      1499\n",
      "           1       0.33      0.62      0.43      1499\n",
      "           2       0.40      0.57      0.47      1499\n",
      "           3       0.49      0.39      0.44      1499\n",
      "           4       0.68      0.78      0.72      1499\n",
      "           5       0.51      0.71      0.60      1499\n",
      "           6       0.60      0.67      0.64      1499\n",
      "           7       0.59      0.45      0.51      1499\n",
      "           8       0.46      0.70      0.55      1499\n",
      "           9       0.66      0.71      0.69      1499\n",
      "          10       0.22      0.15      0.18      1499\n",
      "          11       0.23      0.17      0.20      1499\n",
      "          12       0.18      0.12      0.15      1499\n",
      "          13       0.20      0.25      0.22      1499\n",
      "          14       0.26      0.15      0.19      1499\n",
      "          15       0.31      0.35      0.33      1499\n",
      "          16       0.74      0.55      0.63      1499\n",
      "          17       0.83      0.51      0.63      1499\n",
      "          18       0.22      0.21      0.22      1499\n",
      "          19       0.34      0.24      0.28      1499\n",
      "          20       0.85      0.54      0.66      1499\n",
      "          21       0.58      0.47      0.52      1499\n",
      "          22       0.32      0.31      0.32      1499\n",
      "          23       0.62      0.73      0.67      1499\n",
      "          24       0.35      0.17      0.23      1499\n",
      "\n",
      "    accuracy                           0.44     37475\n",
      "   macro avg       0.45      0.44      0.43     37475\n",
      "weighted avg       0.45      0.44      0.43     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model.predict(xt8)).numpy(),axis=1)\n",
    "print(classification_report(yt8,y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'num_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/ML_Project/urop25_ann copy.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bverbose-guacamole-pqxwqw644rg26vw6/workspaces/ML_Project/urop25_ann%20copy.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m D_train \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mDMatrix(x8, label\u001b[39m=\u001b[39my8)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bverbose-guacamole-pqxwqw644rg26vw6/workspaces/ML_Project/urop25_ann%20copy.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m D_test \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mDMatrix(xt8, label\u001b[39m=\u001b[39myt8)\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bverbose-guacamole-pqxwqw644rg26vw6/workspaces/ML_Project/urop25_ann%20copy.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39;49mtrain(D_train,num_class\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bverbose-guacamole-pqxwqw644rg26vw6/workspaces/ML_Project/urop25_ann%20copy.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m ypred\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mpredict(xt8)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bverbose-guacamole-pqxwqw644rg26vw6/workspaces/ML_Project/urop25_ann%20copy.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(yt8,ypred))\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/xgboost/core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'num_class'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "D_train = xgb.DMatrix(x8, label=y8)\n",
    "D_test = xgb.DMatrix(xt8, label=yt8)\n",
    "model = xgb.train(D_train,num_class=25)\n",
    "ypred=model.predict(xt8)\n",
    "print(classification_report(yt8,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d7d010",
   "metadata": {},
   "source": [
    "## 0-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "268bff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain16=xtrain.iloc[:,:16]\n",
    "xtest16=xtest.iloc[:,:16]\n",
    "xvalid16=xvalid.iloc[:,:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "000e1a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10231/4039718790.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtrain16['id']=ytrain\n",
      "/tmp/ipykernel_10231/4039718790.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtest16['id']=ytest\n",
      "/tmp/ipykernel_10231/4039718790.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xvalid16['id']=yvalid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_0</th>\n",
       "      <th>Channel_1</th>\n",
       "      <th>Channel_2</th>\n",
       "      <th>Channel_3</th>\n",
       "      <th>Channel_4</th>\n",
       "      <th>Channel_5</th>\n",
       "      <th>Channel_6</th>\n",
       "      <th>Channel_7</th>\n",
       "      <th>Channel_8</th>\n",
       "      <th>Channel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Channel_54</th>\n",
       "      <th>Channel_55</th>\n",
       "      <th>Channel_56</th>\n",
       "      <th>Channel_57</th>\n",
       "      <th>Channel_58</th>\n",
       "      <th>Channel_59</th>\n",
       "      <th>Channel_60</th>\n",
       "      <th>Channel_61</th>\n",
       "      <th>Channel_62</th>\n",
       "      <th>Channel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Channel_0  Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  \\\n",
       "0       -0.000005   0.000002   0.000037   0.000039   0.000030   0.000026   \n",
       "1       -0.000012  -0.000024   0.000001  -0.000002  -0.000015  -0.000022   \n",
       "2       -0.000077  -0.000078  -0.000059  -0.000065  -0.000063  -0.000055   \n",
       "3       -0.000066  -0.000067  -0.000050  -0.000065  -0.000060  -0.000055   \n",
       "4       -0.000045  -0.000055  -0.000033  -0.000053  -0.000054  -0.000063   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "299995   0.000000   0.000008   0.000001   0.000003  -0.000005   0.000001   \n",
       "299996  -0.000006   0.000014   0.000009   0.000012   0.000005   0.000010   \n",
       "299997   0.000008   0.000017   0.000016   0.000021   0.000009   0.000010   \n",
       "299998  -0.000017  -0.000003  -0.000001   0.000004  -0.000005  -0.000004   \n",
       "299999  -0.000024  -0.000006  -0.000007  -0.000003  -0.000009  -0.000003   \n",
       "\n",
       "        Channel_6  Channel_7  Channel_8  Channel_9  ...  Channel_54  \\\n",
       "0       -0.000016  -0.000014   0.000004   0.000018  ...   -0.000021   \n",
       "1       -0.000055  -0.000036  -0.000027  -0.000025  ...   -0.000050   \n",
       "2       -0.000067  -0.000088  -0.000071  -0.000065  ...   -0.000017   \n",
       "3       -0.000068  -0.000062  -0.000053  -0.000054  ...   -0.000039   \n",
       "4       -0.000083  -0.000052  -0.000050  -0.000053  ...   -0.000044   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "299995  -0.000003  -0.000008  -0.000004   0.000007  ...   -0.000009   \n",
       "299996   0.000007  -0.000002  -0.000001   0.000012  ...   -0.000005   \n",
       "299997   0.000005  -0.000002  -0.000002   0.000014  ...   -0.000012   \n",
       "299998  -0.000006  -0.000018  -0.000015   0.000002  ...   -0.000010   \n",
       "299999  -0.000002  -0.000020  -0.000016   0.000002  ...   -0.000007   \n",
       "\n",
       "        Channel_55  Channel_56  Channel_57  Channel_58  Channel_59  \\\n",
       "0        -0.000008   -0.000035   -0.000045   -0.000066   -0.000039   \n",
       "1        -0.000040   -0.000068   -0.000065   -0.000084   -0.000052   \n",
       "2        -0.000022   -0.000050   -0.000035   -0.000048   -0.000018   \n",
       "3        -0.000060   -0.000078   -0.000064   -0.000068   -0.000041   \n",
       "4        -0.000055   -0.000070   -0.000054   -0.000063   -0.000037   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "299995    0.000000    0.000009    0.000017    0.000005    0.000002   \n",
       "299996    0.000006    0.000013    0.000018    0.000007    0.000012   \n",
       "299997   -0.000003    0.000002    0.000004   -0.000008   -0.000005   \n",
       "299998   -0.000004    0.000000    0.000004   -0.000007   -0.000002   \n",
       "299999   -0.000004    0.000000    0.000002   -0.000010   -0.000007   \n",
       "\n",
       "        Channel_60  Channel_61  Channel_62  Channel_63  \n",
       "0        -0.000033   -0.000048   -0.000039   -0.000039  \n",
       "1        -0.000021   -0.000042   -0.000031   -0.000034  \n",
       "2        -0.000020   -0.000042   -0.000029   -0.000027  \n",
       "3        -0.000044   -0.000062   -0.000034   -0.000043  \n",
       "4        -0.000060   -0.000070   -0.000034   -0.000045  \n",
       "...            ...         ...         ...         ...  \n",
       "299995    0.000015    0.000003    0.000004    0.000012  \n",
       "299996    0.000015    0.000009    0.000012    0.000017  \n",
       "299997    0.000005   -0.000011   -0.000010   -0.000004  \n",
       "299998    0.000004   -0.000011   -0.000009   -0.000003  \n",
       "299999    0.000001   -0.000008   -0.000008    0.000000  \n",
       "\n",
       "[300000 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain16['id']=ytrain\n",
    "xtest16['id']=ytest\n",
    "xvalid16['id']=yvalid\n",
    "display(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03b98fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x16,y16=scale_dataset(xtrain16)\n",
    "xt16,yt16=scale_dataset(xtest16)\n",
    "xv16,yv16=scale_dataset(xvalid16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.86806\n",
      "[1]\tvalidation_0-mlogloss:2.73679\n",
      "[2]\tvalidation_0-mlogloss:2.64125\n",
      "[3]\tvalidation_0-mlogloss:2.55989\n",
      "[4]\tvalidation_0-mlogloss:2.49798\n",
      "[5]\tvalidation_0-mlogloss:2.44695\n",
      "[6]\tvalidation_0-mlogloss:2.40216\n",
      "[7]\tvalidation_0-mlogloss:2.35693\n",
      "[8]\tvalidation_0-mlogloss:2.32183\n",
      "[9]\tvalidation_0-mlogloss:2.28848\n",
      "[10]\tvalidation_0-mlogloss:2.25645\n",
      "[11]\tvalidation_0-mlogloss:2.23106\n",
      "[12]\tvalidation_0-mlogloss:2.20833\n",
      "[13]\tvalidation_0-mlogloss:2.18272\n",
      "[14]\tvalidation_0-mlogloss:2.16264\n",
      "[15]\tvalidation_0-mlogloss:2.14244\n",
      "[16]\tvalidation_0-mlogloss:2.12256\n",
      "[17]\tvalidation_0-mlogloss:2.10579\n",
      "[18]\tvalidation_0-mlogloss:2.08784\n",
      "[19]\tvalidation_0-mlogloss:2.07081\n",
      "[20]\tvalidation_0-mlogloss:2.05692\n",
      "[21]\tvalidation_0-mlogloss:2.04071\n",
      "[22]\tvalidation_0-mlogloss:2.02457\n",
      "[23]\tvalidation_0-mlogloss:2.01073\n",
      "[24]\tvalidation_0-mlogloss:1.99799\n",
      "[25]\tvalidation_0-mlogloss:1.98731\n",
      "[26]\tvalidation_0-mlogloss:1.97624\n",
      "[27]\tvalidation_0-mlogloss:1.96748\n",
      "[28]\tvalidation_0-mlogloss:1.95482\n",
      "[29]\tvalidation_0-mlogloss:1.94323\n",
      "[30]\tvalidation_0-mlogloss:1.93299\n",
      "[31]\tvalidation_0-mlogloss:1.92300\n",
      "[32]\tvalidation_0-mlogloss:1.91533\n",
      "[33]\tvalidation_0-mlogloss:1.90735\n",
      "[34]\tvalidation_0-mlogloss:1.89741\n",
      "[35]\tvalidation_0-mlogloss:1.88795\n",
      "[36]\tvalidation_0-mlogloss:1.88165\n",
      "[37]\tvalidation_0-mlogloss:1.87360\n",
      "[38]\tvalidation_0-mlogloss:1.86246\n",
      "[39]\tvalidation_0-mlogloss:1.85334\n",
      "[40]\tvalidation_0-mlogloss:1.84569\n",
      "[41]\tvalidation_0-mlogloss:1.83968\n",
      "[42]\tvalidation_0-mlogloss:1.83186\n",
      "[43]\tvalidation_0-mlogloss:1.82917\n",
      "[44]\tvalidation_0-mlogloss:1.82041\n",
      "[45]\tvalidation_0-mlogloss:1.81138\n",
      "[46]\tvalidation_0-mlogloss:1.80483\n",
      "[47]\tvalidation_0-mlogloss:1.79664\n",
      "[48]\tvalidation_0-mlogloss:1.78825\n",
      "[49]\tvalidation_0-mlogloss:1.77877\n",
      "[50]\tvalidation_0-mlogloss:1.77576\n",
      "[51]\tvalidation_0-mlogloss:1.76910\n",
      "[52]\tvalidation_0-mlogloss:1.76369\n",
      "[53]\tvalidation_0-mlogloss:1.75652\n",
      "[54]\tvalidation_0-mlogloss:1.74966\n",
      "[55]\tvalidation_0-mlogloss:1.74341\n",
      "[56]\tvalidation_0-mlogloss:1.73716\n",
      "[57]\tvalidation_0-mlogloss:1.73159\n",
      "[58]\tvalidation_0-mlogloss:1.72684\n",
      "[59]\tvalidation_0-mlogloss:1.72314\n",
      "[60]\tvalidation_0-mlogloss:1.71886\n",
      "[61]\tvalidation_0-mlogloss:1.71445\n",
      "[62]\tvalidation_0-mlogloss:1.70927\n",
      "[63]\tvalidation_0-mlogloss:1.70327\n",
      "[64]\tvalidation_0-mlogloss:1.69795\n",
      "[65]\tvalidation_0-mlogloss:1.69330\n",
      "[66]\tvalidation_0-mlogloss:1.68742\n",
      "[67]\tvalidation_0-mlogloss:1.68285\n",
      "[68]\tvalidation_0-mlogloss:1.67690\n",
      "[69]\tvalidation_0-mlogloss:1.67052\n",
      "[70]\tvalidation_0-mlogloss:1.66619\n",
      "[71]\tvalidation_0-mlogloss:1.66003\n",
      "[72]\tvalidation_0-mlogloss:1.66042\n",
      "[73]\tvalidation_0-mlogloss:1.65788\n",
      "[74]\tvalidation_0-mlogloss:1.65567\n",
      "[75]\tvalidation_0-mlogloss:1.65143\n",
      "[76]\tvalidation_0-mlogloss:1.64983\n",
      "[77]\tvalidation_0-mlogloss:1.64641\n",
      "[78]\tvalidation_0-mlogloss:1.64295\n",
      "[79]\tvalidation_0-mlogloss:1.63883\n",
      "[80]\tvalidation_0-mlogloss:1.63575\n",
      "[81]\tvalidation_0-mlogloss:1.63280\n",
      "[82]\tvalidation_0-mlogloss:1.62939\n",
      "[83]\tvalidation_0-mlogloss:1.62675\n",
      "[84]\tvalidation_0-mlogloss:1.62325\n",
      "[85]\tvalidation_0-mlogloss:1.62027\n",
      "[86]\tvalidation_0-mlogloss:1.61712\n",
      "[87]\tvalidation_0-mlogloss:1.61421\n",
      "[88]\tvalidation_0-mlogloss:1.61451\n",
      "[89]\tvalidation_0-mlogloss:1.61256\n",
      "[90]\tvalidation_0-mlogloss:1.60906\n",
      "[91]\tvalidation_0-mlogloss:1.60640\n",
      "[92]\tvalidation_0-mlogloss:1.60513\n",
      "[93]\tvalidation_0-mlogloss:1.60260\n",
      "[94]\tvalidation_0-mlogloss:1.59973\n",
      "[95]\tvalidation_0-mlogloss:1.59855\n",
      "[96]\tvalidation_0-mlogloss:1.59462\n",
      "[97]\tvalidation_0-mlogloss:1.59211\n",
      "[98]\tvalidation_0-mlogloss:1.58976\n",
      "[99]\tvalidation_0-mlogloss:1.58716\n",
      "[100]\tvalidation_0-mlogloss:1.58400\n",
      "[101]\tvalidation_0-mlogloss:1.58196\n",
      "[102]\tvalidation_0-mlogloss:1.57832\n",
      "[103]\tvalidation_0-mlogloss:1.57650\n",
      "[104]\tvalidation_0-mlogloss:1.57459\n",
      "[105]\tvalidation_0-mlogloss:1.57227\n",
      "[106]\tvalidation_0-mlogloss:1.57048\n",
      "[107]\tvalidation_0-mlogloss:1.56927\n",
      "[108]\tvalidation_0-mlogloss:1.56666\n",
      "[109]\tvalidation_0-mlogloss:1.56391\n",
      "[110]\tvalidation_0-mlogloss:1.56171\n",
      "[111]\tvalidation_0-mlogloss:1.55927\n",
      "[112]\tvalidation_0-mlogloss:1.55755\n",
      "[113]\tvalidation_0-mlogloss:1.55504\n",
      "[114]\tvalidation_0-mlogloss:1.55329\n",
      "[115]\tvalidation_0-mlogloss:1.55126\n",
      "[116]\tvalidation_0-mlogloss:1.54917\n",
      "[117]\tvalidation_0-mlogloss:1.54733\n",
      "[118]\tvalidation_0-mlogloss:1.54666\n",
      "[119]\tvalidation_0-mlogloss:1.54512\n",
      "[120]\tvalidation_0-mlogloss:1.54467\n",
      "[121]\tvalidation_0-mlogloss:1.54199\n",
      "[122]\tvalidation_0-mlogloss:1.54038\n",
      "[123]\tvalidation_0-mlogloss:1.53880\n",
      "[124]\tvalidation_0-mlogloss:1.53672\n",
      "[125]\tvalidation_0-mlogloss:1.53361\n",
      "[126]\tvalidation_0-mlogloss:1.52951\n",
      "[127]\tvalidation_0-mlogloss:1.52713\n",
      "[128]\tvalidation_0-mlogloss:1.52541\n",
      "[129]\tvalidation_0-mlogloss:1.52243\n",
      "[130]\tvalidation_0-mlogloss:1.52061\n",
      "[131]\tvalidation_0-mlogloss:1.51827\n",
      "[132]\tvalidation_0-mlogloss:1.51619\n",
      "[133]\tvalidation_0-mlogloss:1.51322\n",
      "[134]\tvalidation_0-mlogloss:1.51104\n",
      "[135]\tvalidation_0-mlogloss:1.50945\n",
      "[136]\tvalidation_0-mlogloss:1.50780\n",
      "[137]\tvalidation_0-mlogloss:1.50502\n",
      "[138]\tvalidation_0-mlogloss:1.50432\n",
      "[139]\tvalidation_0-mlogloss:1.50362\n",
      "[140]\tvalidation_0-mlogloss:1.50088\n",
      "[141]\tvalidation_0-mlogloss:1.49979\n",
      "[142]\tvalidation_0-mlogloss:1.49905\n",
      "[143]\tvalidation_0-mlogloss:1.49784\n",
      "[144]\tvalidation_0-mlogloss:1.49656\n",
      "[145]\tvalidation_0-mlogloss:1.49697\n",
      "[146]\tvalidation_0-mlogloss:1.49476\n",
      "[147]\tvalidation_0-mlogloss:1.49404\n",
      "[148]\tvalidation_0-mlogloss:1.49183\n",
      "[149]\tvalidation_0-mlogloss:1.48935\n",
      "[150]\tvalidation_0-mlogloss:1.48840\n",
      "[151]\tvalidation_0-mlogloss:1.48634\n",
      "[152]\tvalidation_0-mlogloss:1.48613\n",
      "[153]\tvalidation_0-mlogloss:1.48538\n",
      "[154]\tvalidation_0-mlogloss:1.48463\n",
      "[155]\tvalidation_0-mlogloss:1.48398\n",
      "[156]\tvalidation_0-mlogloss:1.48190\n",
      "[157]\tvalidation_0-mlogloss:1.48113\n",
      "[158]\tvalidation_0-mlogloss:1.47899\n",
      "[159]\tvalidation_0-mlogloss:1.47793\n",
      "[160]\tvalidation_0-mlogloss:1.47811\n",
      "[161]\tvalidation_0-mlogloss:1.47569\n",
      "[162]\tvalidation_0-mlogloss:1.47517\n",
      "[163]\tvalidation_0-mlogloss:1.47396\n",
      "[164]\tvalidation_0-mlogloss:1.47323\n",
      "[165]\tvalidation_0-mlogloss:1.47155\n",
      "[166]\tvalidation_0-mlogloss:1.47068\n",
      "[167]\tvalidation_0-mlogloss:1.46866\n",
      "[168]\tvalidation_0-mlogloss:1.46773\n",
      "[169]\tvalidation_0-mlogloss:1.46630\n",
      "[170]\tvalidation_0-mlogloss:1.46470\n",
      "[171]\tvalidation_0-mlogloss:1.46399\n",
      "[172]\tvalidation_0-mlogloss:1.46319\n",
      "[173]\tvalidation_0-mlogloss:1.46273\n",
      "[174]\tvalidation_0-mlogloss:1.46163\n",
      "[175]\tvalidation_0-mlogloss:1.46078\n",
      "[176]\tvalidation_0-mlogloss:1.45962\n",
      "[177]\tvalidation_0-mlogloss:1.45938\n",
      "[178]\tvalidation_0-mlogloss:1.45799\n",
      "[179]\tvalidation_0-mlogloss:1.45696\n",
      "[180]\tvalidation_0-mlogloss:1.45636\n",
      "[181]\tvalidation_0-mlogloss:1.45648\n",
      "[182]\tvalidation_0-mlogloss:1.45531\n",
      "[183]\tvalidation_0-mlogloss:1.45405\n",
      "[184]\tvalidation_0-mlogloss:1.45406\n",
      "[185]\tvalidation_0-mlogloss:1.45264\n",
      "[186]\tvalidation_0-mlogloss:1.45191\n",
      "[187]\tvalidation_0-mlogloss:1.45123\n",
      "[188]\tvalidation_0-mlogloss:1.45119\n",
      "[189]\tvalidation_0-mlogloss:1.45098\n",
      "[190]\tvalidation_0-mlogloss:1.44983\n",
      "[191]\tvalidation_0-mlogloss:1.44917\n",
      "[192]\tvalidation_0-mlogloss:1.44841\n",
      "[193]\tvalidation_0-mlogloss:1.44847\n",
      "[194]\tvalidation_0-mlogloss:1.44724\n",
      "[195]\tvalidation_0-mlogloss:1.44579\n",
      "[196]\tvalidation_0-mlogloss:1.44469\n",
      "[197]\tvalidation_0-mlogloss:1.44424\n",
      "[198]\tvalidation_0-mlogloss:1.44418\n",
      "[199]\tvalidation_0-mlogloss:1.44259\n",
      "[200]\tvalidation_0-mlogloss:1.44196\n",
      "[201]\tvalidation_0-mlogloss:1.44129\n",
      "[202]\tvalidation_0-mlogloss:1.44259\n",
      "[203]\tvalidation_0-mlogloss:1.44260\n",
      "[204]\tvalidation_0-mlogloss:1.44179\n",
      "[205]\tvalidation_0-mlogloss:1.44124\n",
      "[206]\tvalidation_0-mlogloss:1.44099\n",
      "[207]\tvalidation_0-mlogloss:1.44060\n",
      "[208]\tvalidation_0-mlogloss:1.43962\n",
      "[209]\tvalidation_0-mlogloss:1.43906\n",
      "[210]\tvalidation_0-mlogloss:1.43827\n",
      "[211]\tvalidation_0-mlogloss:1.43718\n",
      "[212]\tvalidation_0-mlogloss:1.43728\n",
      "[213]\tvalidation_0-mlogloss:1.43670\n",
      "[214]\tvalidation_0-mlogloss:1.43621\n",
      "[215]\tvalidation_0-mlogloss:1.43781\n",
      "[216]\tvalidation_0-mlogloss:1.43747\n",
      "[217]\tvalidation_0-mlogloss:1.43693\n",
      "[218]\tvalidation_0-mlogloss:1.43707\n",
      "[219]\tvalidation_0-mlogloss:1.43721\n",
      "[220]\tvalidation_0-mlogloss:1.43732\n",
      "[221]\tvalidation_0-mlogloss:1.43658\n",
      "[222]\tvalidation_0-mlogloss:1.43613\n",
      "[223]\tvalidation_0-mlogloss:1.43527\n",
      "[224]\tvalidation_0-mlogloss:1.43455\n",
      "[225]\tvalidation_0-mlogloss:1.43397\n",
      "[226]\tvalidation_0-mlogloss:1.43247\n",
      "[227]\tvalidation_0-mlogloss:1.43232\n",
      "[228]\tvalidation_0-mlogloss:1.43328\n",
      "[229]\tvalidation_0-mlogloss:1.43275\n",
      "[230]\tvalidation_0-mlogloss:1.43199\n",
      "[231]\tvalidation_0-mlogloss:1.43227\n",
      "[232]\tvalidation_0-mlogloss:1.43206\n",
      "[233]\tvalidation_0-mlogloss:1.43127\n",
      "[234]\tvalidation_0-mlogloss:1.43049\n",
      "[235]\tvalidation_0-mlogloss:1.43011\n",
      "[236]\tvalidation_0-mlogloss:1.43049\n",
      "[237]\tvalidation_0-mlogloss:1.43108\n",
      "[238]\tvalidation_0-mlogloss:1.43126\n",
      "[239]\tvalidation_0-mlogloss:1.43112\n",
      "[240]\tvalidation_0-mlogloss:1.43168\n",
      "[241]\tvalidation_0-mlogloss:1.43185\n",
      "[242]\tvalidation_0-mlogloss:1.43146\n",
      "[243]\tvalidation_0-mlogloss:1.43084\n",
      "[244]\tvalidation_0-mlogloss:1.43142\n",
      "[245]\tvalidation_0-mlogloss:1.43172\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.54      0.43      1499\n",
      "           1       0.46      0.56      0.50      1499\n",
      "           2       0.57      0.62      0.59      1499\n",
      "           3       0.77      0.49      0.60      1499\n",
      "           4       0.92      0.89      0.90      1499\n",
      "           5       0.58      0.61      0.59      1499\n",
      "           6       0.67      0.82      0.74      1499\n",
      "           7       0.76      0.59      0.66      1499\n",
      "           8       0.53      0.70      0.61      1499\n",
      "           9       0.81      0.75      0.78      1499\n",
      "          10       0.46      0.22      0.29      1499\n",
      "          11       0.52      0.60      0.56      1499\n",
      "          12       0.45      0.48      0.46      1499\n",
      "          13       0.28      0.40      0.33      1499\n",
      "          14       0.36      0.35      0.36      1499\n",
      "          15       0.64      0.49      0.56      1499\n",
      "          16       0.83      0.54      0.65      1499\n",
      "          17       0.83      0.91      0.87      1499\n",
      "          18       0.52      0.55      0.54      1499\n",
      "          19       0.42      0.39      0.41      1499\n",
      "          20       0.87      0.74      0.80      1499\n",
      "          21       0.61      0.67      0.64      1499\n",
      "          22       0.45      0.42      0.44      1499\n",
      "          23       0.77      0.83      0.80      1499\n",
      "          24       0.64      0.50      0.56      1499\n",
      "\n",
      "    accuracy                           0.59     37475\n",
      "   macro avg       0.60      0.59      0.59     37475\n",
      "weighted avg       0.60      0.59      0.59     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2=XGBClassifier(n_estimators=500)\n",
    "model2.fit(x16,y16,early_stopping_rounds=10, eval_set=[(xv16, yv16)])\n",
    "y_pred=model2.predict(xt16)\n",
    "print(classification_report(yt16,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7844baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model1 = Sequential(\n",
    "    [\n",
    "        Dense(16, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(25, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7980b449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 15s 1ms/step - loss: 1.3050 - val_loss: 1.8960\n",
      "Epoch 2/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.6797 - val_loss: 1.9321\n",
      "Epoch 3/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.5478 - val_loss: 2.1032\n",
      "Epoch 4/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.4926 - val_loss: 2.2106\n",
      "Epoch 5/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.4596 - val_loss: 2.4400\n",
      "Epoch 6/10\n",
      "9375/9375 [==============================] - 13s 1ms/step - loss: 0.4374 - val_loss: 2.3829\n",
      "Epoch 7/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.4194 - val_loss: 2.7439\n",
      "Epoch 8/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.4070 - val_loss: 2.6990\n",
      "Epoch 9/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.3950 - val_loss: 2.5336\n",
      "Epoch 10/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.3850 - val_loss: 3.0248\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f18400e7c70>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model1.fit(\n",
    "    x16,y16,epochs=10,validation_data=(xv16,yv16)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d07cf8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 177/1172 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 866us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.55      0.39      1499\n",
      "           1       0.48      0.67      0.56      1499\n",
      "           2       0.50      0.71      0.59      1499\n",
      "           3       0.60      0.49      0.54      1499\n",
      "           4       0.86      0.92      0.89      1499\n",
      "           5       0.61      0.80      0.69      1499\n",
      "           6       0.94      0.57      0.71      1499\n",
      "           7       0.80      0.58      0.67      1499\n",
      "           8       0.48      0.60      0.53      1499\n",
      "           9       0.59      0.83      0.69      1499\n",
      "          10       0.40      0.08      0.13      1499\n",
      "          11       0.84      0.61      0.71      1499\n",
      "          12       0.53      0.42      0.47      1499\n",
      "          13       0.21      0.48      0.29      1499\n",
      "          14       0.34      0.52      0.41      1499\n",
      "          15       0.72      0.36      0.48      1499\n",
      "          16       0.83      0.34      0.48      1499\n",
      "          17       0.99      0.83      0.90      1499\n",
      "          18       0.54      0.60      0.57      1499\n",
      "          19       0.46      0.19      0.26      1499\n",
      "          20       0.98      0.62      0.76      1499\n",
      "          21       0.55      0.71      0.62      1499\n",
      "          22       0.42      0.54      0.47      1499\n",
      "          23       0.84      0.84      0.84      1499\n",
      "          24       0.71      0.13      0.23      1499\n",
      "\n",
      "    accuracy                           0.56     37475\n",
      "   macro avg       0.62      0.56      0.56     37475\n",
      "weighted avg       0.62      0.56      0.56     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model1.predict(xt16)).numpy(),axis=1)\n",
    "print(classification_report(yt16,y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e57e7",
   "metadata": {},
   "source": [
    "## 0-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a408e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain32=xtrain.iloc[:,:32]\n",
    "xtest32=xtest.iloc[:,:32]\n",
    "xvalid32=xvalid.iloc[:,:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26f15468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10231/1675347936.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtrain32['id']=ytrain\n",
      "/tmp/ipykernel_10231/1675347936.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtest32['id']=ytest\n",
      "/tmp/ipykernel_10231/1675347936.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xvalid32['id']=yvalid\n"
     ]
    }
   ],
   "source": [
    "xtrain32['id']=ytrain\n",
    "xtest32['id']=ytest\n",
    "xvalid32['id']=yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3ddddf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x32,y32=scale_dataset(xtrain32)\n",
    "xt32,yt32=scale_dataset(xtest32)\n",
    "xv32,yv32=scale_dataset(xvalid32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.70971\n",
      "[1]\tvalidation_0-mlogloss:2.51738\n",
      "[2]\tvalidation_0-mlogloss:2.38308\n",
      "[3]\tvalidation_0-mlogloss:2.27969\n",
      "[4]\tvalidation_0-mlogloss:2.19041\n",
      "[5]\tvalidation_0-mlogloss:2.11033\n",
      "[6]\tvalidation_0-mlogloss:2.04798\n",
      "[7]\tvalidation_0-mlogloss:1.99195\n",
      "[8]\tvalidation_0-mlogloss:1.94001\n",
      "[9]\tvalidation_0-mlogloss:1.88984\n",
      "[10]\tvalidation_0-mlogloss:1.84523\n",
      "[11]\tvalidation_0-mlogloss:1.80420\n",
      "[12]\tvalidation_0-mlogloss:1.76769\n",
      "[13]\tvalidation_0-mlogloss:1.73532\n",
      "[14]\tvalidation_0-mlogloss:1.70033\n",
      "[15]\tvalidation_0-mlogloss:1.67288\n",
      "[16]\tvalidation_0-mlogloss:1.65079\n",
      "[17]\tvalidation_0-mlogloss:1.62779\n",
      "[18]\tvalidation_0-mlogloss:1.60033\n",
      "[19]\tvalidation_0-mlogloss:1.57218\n",
      "[20]\tvalidation_0-mlogloss:1.55227\n",
      "[21]\tvalidation_0-mlogloss:1.53162\n",
      "[22]\tvalidation_0-mlogloss:1.51232\n",
      "[23]\tvalidation_0-mlogloss:1.49478\n",
      "[24]\tvalidation_0-mlogloss:1.48041\n",
      "[25]\tvalidation_0-mlogloss:1.46415\n",
      "[26]\tvalidation_0-mlogloss:1.44284\n",
      "[27]\tvalidation_0-mlogloss:1.42518\n",
      "[28]\tvalidation_0-mlogloss:1.41158\n",
      "[29]\tvalidation_0-mlogloss:1.39577\n",
      "[30]\tvalidation_0-mlogloss:1.38270\n",
      "[31]\tvalidation_0-mlogloss:1.37116\n",
      "[32]\tvalidation_0-mlogloss:1.35513\n",
      "[33]\tvalidation_0-mlogloss:1.34296\n",
      "[34]\tvalidation_0-mlogloss:1.33032\n",
      "[35]\tvalidation_0-mlogloss:1.32013\n",
      "[36]\tvalidation_0-mlogloss:1.30733\n",
      "[37]\tvalidation_0-mlogloss:1.29545\n",
      "[38]\tvalidation_0-mlogloss:1.28123\n",
      "[39]\tvalidation_0-mlogloss:1.27346\n",
      "[40]\tvalidation_0-mlogloss:1.26288\n",
      "[41]\tvalidation_0-mlogloss:1.25098\n",
      "[42]\tvalidation_0-mlogloss:1.23851\n",
      "[43]\tvalidation_0-mlogloss:1.22645\n",
      "[44]\tvalidation_0-mlogloss:1.21868\n",
      "[45]\tvalidation_0-mlogloss:1.20881\n",
      "[46]\tvalidation_0-mlogloss:1.19765\n",
      "[47]\tvalidation_0-mlogloss:1.19235\n",
      "[48]\tvalidation_0-mlogloss:1.18428\n",
      "[49]\tvalidation_0-mlogloss:1.17600\n",
      "[50]\tvalidation_0-mlogloss:1.17083\n",
      "[51]\tvalidation_0-mlogloss:1.16365\n",
      "[52]\tvalidation_0-mlogloss:1.15665\n",
      "[53]\tvalidation_0-mlogloss:1.14853\n",
      "[54]\tvalidation_0-mlogloss:1.14149\n",
      "[55]\tvalidation_0-mlogloss:1.13551\n",
      "[56]\tvalidation_0-mlogloss:1.12921\n",
      "[57]\tvalidation_0-mlogloss:1.12130\n",
      "[58]\tvalidation_0-mlogloss:1.11536\n",
      "[59]\tvalidation_0-mlogloss:1.10848\n",
      "[60]\tvalidation_0-mlogloss:1.10300\n",
      "[61]\tvalidation_0-mlogloss:1.09771\n",
      "[62]\tvalidation_0-mlogloss:1.09196\n",
      "[63]\tvalidation_0-mlogloss:1.08656\n",
      "[64]\tvalidation_0-mlogloss:1.08263\n",
      "[65]\tvalidation_0-mlogloss:1.07552\n",
      "[66]\tvalidation_0-mlogloss:1.07073\n",
      "[67]\tvalidation_0-mlogloss:1.06480\n",
      "[68]\tvalidation_0-mlogloss:1.05822\n",
      "[69]\tvalidation_0-mlogloss:1.05288\n",
      "[70]\tvalidation_0-mlogloss:1.04768\n",
      "[71]\tvalidation_0-mlogloss:1.04415\n",
      "[72]\tvalidation_0-mlogloss:1.04012\n",
      "[73]\tvalidation_0-mlogloss:1.03565\n",
      "[74]\tvalidation_0-mlogloss:1.03171\n",
      "[75]\tvalidation_0-mlogloss:1.02801\n",
      "[76]\tvalidation_0-mlogloss:1.02175\n",
      "[77]\tvalidation_0-mlogloss:1.01718\n",
      "[78]\tvalidation_0-mlogloss:1.01261\n",
      "[79]\tvalidation_0-mlogloss:1.00827\n",
      "[80]\tvalidation_0-mlogloss:1.00371\n",
      "[81]\tvalidation_0-mlogloss:1.00013\n",
      "[82]\tvalidation_0-mlogloss:0.99707\n",
      "[83]\tvalidation_0-mlogloss:0.99291\n",
      "[84]\tvalidation_0-mlogloss:0.98777\n",
      "[85]\tvalidation_0-mlogloss:0.98288\n",
      "[86]\tvalidation_0-mlogloss:0.97865\n",
      "[87]\tvalidation_0-mlogloss:0.97557\n",
      "[88]\tvalidation_0-mlogloss:0.97250\n",
      "[89]\tvalidation_0-mlogloss:0.96914\n",
      "[90]\tvalidation_0-mlogloss:0.96535\n",
      "[91]\tvalidation_0-mlogloss:0.96097\n",
      "[92]\tvalidation_0-mlogloss:0.95559\n",
      "[93]\tvalidation_0-mlogloss:0.95260\n",
      "[94]\tvalidation_0-mlogloss:0.94907\n",
      "[95]\tvalidation_0-mlogloss:0.94637\n",
      "[96]\tvalidation_0-mlogloss:0.94319\n",
      "[97]\tvalidation_0-mlogloss:0.94021\n",
      "[98]\tvalidation_0-mlogloss:0.93659\n",
      "[99]\tvalidation_0-mlogloss:0.93273\n",
      "[100]\tvalidation_0-mlogloss:0.93103\n",
      "[101]\tvalidation_0-mlogloss:0.92572\n",
      "[102]\tvalidation_0-mlogloss:0.92339\n",
      "[103]\tvalidation_0-mlogloss:0.92004\n",
      "[104]\tvalidation_0-mlogloss:0.91745\n",
      "[105]\tvalidation_0-mlogloss:0.91463\n",
      "[106]\tvalidation_0-mlogloss:0.91145\n",
      "[107]\tvalidation_0-mlogloss:0.90781\n",
      "[108]\tvalidation_0-mlogloss:0.90357\n",
      "[109]\tvalidation_0-mlogloss:0.90101\n",
      "[110]\tvalidation_0-mlogloss:0.89800\n",
      "[111]\tvalidation_0-mlogloss:0.89404\n",
      "[112]\tvalidation_0-mlogloss:0.89067\n",
      "[113]\tvalidation_0-mlogloss:0.88805\n",
      "[114]\tvalidation_0-mlogloss:0.88706\n",
      "[115]\tvalidation_0-mlogloss:0.88417\n",
      "[116]\tvalidation_0-mlogloss:0.88227\n",
      "[117]\tvalidation_0-mlogloss:0.88078\n",
      "[118]\tvalidation_0-mlogloss:0.87911\n",
      "[119]\tvalidation_0-mlogloss:0.87757\n",
      "[120]\tvalidation_0-mlogloss:0.87478\n",
      "[121]\tvalidation_0-mlogloss:0.87208\n",
      "[122]\tvalidation_0-mlogloss:0.87050\n",
      "[123]\tvalidation_0-mlogloss:0.86982\n",
      "[124]\tvalidation_0-mlogloss:0.86739\n",
      "[125]\tvalidation_0-mlogloss:0.86481\n",
      "[126]\tvalidation_0-mlogloss:0.86429\n",
      "[127]\tvalidation_0-mlogloss:0.86312\n",
      "[128]\tvalidation_0-mlogloss:0.86130\n",
      "[129]\tvalidation_0-mlogloss:0.85922\n",
      "[130]\tvalidation_0-mlogloss:0.85683\n",
      "[131]\tvalidation_0-mlogloss:0.85506\n",
      "[132]\tvalidation_0-mlogloss:0.85512\n",
      "[133]\tvalidation_0-mlogloss:0.85362\n",
      "[134]\tvalidation_0-mlogloss:0.84985\n",
      "[135]\tvalidation_0-mlogloss:0.84792\n",
      "[136]\tvalidation_0-mlogloss:0.84588\n",
      "[137]\tvalidation_0-mlogloss:0.84393\n",
      "[138]\tvalidation_0-mlogloss:0.84176\n",
      "[139]\tvalidation_0-mlogloss:0.84003\n",
      "[140]\tvalidation_0-mlogloss:0.83791\n",
      "[141]\tvalidation_0-mlogloss:0.83490\n",
      "[142]\tvalidation_0-mlogloss:0.83316\n",
      "[143]\tvalidation_0-mlogloss:0.83188\n",
      "[144]\tvalidation_0-mlogloss:0.83093\n",
      "[145]\tvalidation_0-mlogloss:0.82883\n",
      "[146]\tvalidation_0-mlogloss:0.82761\n",
      "[147]\tvalidation_0-mlogloss:0.82571\n",
      "[148]\tvalidation_0-mlogloss:0.82355\n",
      "[149]\tvalidation_0-mlogloss:0.82148\n",
      "[150]\tvalidation_0-mlogloss:0.81880\n",
      "[151]\tvalidation_0-mlogloss:0.81771\n",
      "[152]\tvalidation_0-mlogloss:0.81644\n",
      "[153]\tvalidation_0-mlogloss:0.81389\n",
      "[154]\tvalidation_0-mlogloss:0.81205\n",
      "[155]\tvalidation_0-mlogloss:0.81130\n",
      "[156]\tvalidation_0-mlogloss:0.81045\n",
      "[157]\tvalidation_0-mlogloss:0.80878\n",
      "[158]\tvalidation_0-mlogloss:0.80718\n",
      "[159]\tvalidation_0-mlogloss:0.80457\n",
      "[160]\tvalidation_0-mlogloss:0.80269\n",
      "[161]\tvalidation_0-mlogloss:0.80060\n",
      "[162]\tvalidation_0-mlogloss:0.79906\n",
      "[163]\tvalidation_0-mlogloss:0.79727\n",
      "[164]\tvalidation_0-mlogloss:0.79538\n",
      "[165]\tvalidation_0-mlogloss:0.79415\n",
      "[166]\tvalidation_0-mlogloss:0.79265\n",
      "[167]\tvalidation_0-mlogloss:0.79030\n",
      "[168]\tvalidation_0-mlogloss:0.78946\n",
      "[169]\tvalidation_0-mlogloss:0.78809\n",
      "[170]\tvalidation_0-mlogloss:0.78633\n",
      "[171]\tvalidation_0-mlogloss:0.78453\n",
      "[172]\tvalidation_0-mlogloss:0.78406\n",
      "[173]\tvalidation_0-mlogloss:0.78283\n",
      "[174]\tvalidation_0-mlogloss:0.78121\n",
      "[175]\tvalidation_0-mlogloss:0.78076\n",
      "[176]\tvalidation_0-mlogloss:0.77995\n",
      "[177]\tvalidation_0-mlogloss:0.77879\n",
      "[178]\tvalidation_0-mlogloss:0.77773\n",
      "[179]\tvalidation_0-mlogloss:0.77646\n",
      "[180]\tvalidation_0-mlogloss:0.77593\n",
      "[181]\tvalidation_0-mlogloss:0.77460\n",
      "[182]\tvalidation_0-mlogloss:0.77330\n",
      "[183]\tvalidation_0-mlogloss:0.77163\n",
      "[184]\tvalidation_0-mlogloss:0.77081\n",
      "[185]\tvalidation_0-mlogloss:0.76891\n",
      "[186]\tvalidation_0-mlogloss:0.76733\n",
      "[187]\tvalidation_0-mlogloss:0.76612\n",
      "[188]\tvalidation_0-mlogloss:0.76427\n",
      "[189]\tvalidation_0-mlogloss:0.76289\n",
      "[190]\tvalidation_0-mlogloss:0.76207\n",
      "[191]\tvalidation_0-mlogloss:0.76022\n",
      "[192]\tvalidation_0-mlogloss:0.75959\n",
      "[193]\tvalidation_0-mlogloss:0.75895\n",
      "[194]\tvalidation_0-mlogloss:0.75732\n",
      "[195]\tvalidation_0-mlogloss:0.75561\n",
      "[196]\tvalidation_0-mlogloss:0.75462\n",
      "[197]\tvalidation_0-mlogloss:0.75245\n",
      "[198]\tvalidation_0-mlogloss:0.75160\n",
      "[199]\tvalidation_0-mlogloss:0.75044\n",
      "[200]\tvalidation_0-mlogloss:0.74937\n",
      "[201]\tvalidation_0-mlogloss:0.74956\n",
      "[202]\tvalidation_0-mlogloss:0.74875\n",
      "[203]\tvalidation_0-mlogloss:0.74830\n",
      "[204]\tvalidation_0-mlogloss:0.74749\n",
      "[205]\tvalidation_0-mlogloss:0.74745\n",
      "[206]\tvalidation_0-mlogloss:0.74644\n",
      "[207]\tvalidation_0-mlogloss:0.74622\n",
      "[208]\tvalidation_0-mlogloss:0.74538\n",
      "[209]\tvalidation_0-mlogloss:0.74415\n",
      "[210]\tvalidation_0-mlogloss:0.74346\n",
      "[211]\tvalidation_0-mlogloss:0.74244\n",
      "[212]\tvalidation_0-mlogloss:0.74152\n",
      "[213]\tvalidation_0-mlogloss:0.74044\n",
      "[214]\tvalidation_0-mlogloss:0.74063\n",
      "[215]\tvalidation_0-mlogloss:0.73975\n",
      "[216]\tvalidation_0-mlogloss:0.73893\n",
      "[217]\tvalidation_0-mlogloss:0.73798\n",
      "[218]\tvalidation_0-mlogloss:0.73722\n",
      "[219]\tvalidation_0-mlogloss:0.73690\n",
      "[220]\tvalidation_0-mlogloss:0.73611\n",
      "[221]\tvalidation_0-mlogloss:0.73498\n",
      "[222]\tvalidation_0-mlogloss:0.73367\n",
      "[223]\tvalidation_0-mlogloss:0.73343\n",
      "[224]\tvalidation_0-mlogloss:0.73266\n",
      "[225]\tvalidation_0-mlogloss:0.73219\n",
      "[226]\tvalidation_0-mlogloss:0.73166\n",
      "[227]\tvalidation_0-mlogloss:0.73021\n",
      "[228]\tvalidation_0-mlogloss:0.72893\n",
      "[229]\tvalidation_0-mlogloss:0.72761\n",
      "[230]\tvalidation_0-mlogloss:0.72627\n",
      "[231]\tvalidation_0-mlogloss:0.72528\n",
      "[232]\tvalidation_0-mlogloss:0.72496\n",
      "[233]\tvalidation_0-mlogloss:0.72425\n",
      "[234]\tvalidation_0-mlogloss:0.72382\n",
      "[235]\tvalidation_0-mlogloss:0.72315\n",
      "[236]\tvalidation_0-mlogloss:0.72288\n",
      "[237]\tvalidation_0-mlogloss:0.72224\n",
      "[238]\tvalidation_0-mlogloss:0.72075\n",
      "[239]\tvalidation_0-mlogloss:0.71979\n",
      "[240]\tvalidation_0-mlogloss:0.71951\n",
      "[241]\tvalidation_0-mlogloss:0.71855\n",
      "[242]\tvalidation_0-mlogloss:0.71868\n",
      "[243]\tvalidation_0-mlogloss:0.71801\n",
      "[244]\tvalidation_0-mlogloss:0.71690\n",
      "[245]\tvalidation_0-mlogloss:0.71682\n",
      "[246]\tvalidation_0-mlogloss:0.71618\n",
      "[247]\tvalidation_0-mlogloss:0.71564\n",
      "[248]\tvalidation_0-mlogloss:0.71510\n",
      "[249]\tvalidation_0-mlogloss:0.71442\n",
      "[250]\tvalidation_0-mlogloss:0.71344\n",
      "[251]\tvalidation_0-mlogloss:0.71353\n",
      "[252]\tvalidation_0-mlogloss:0.71230\n",
      "[253]\tvalidation_0-mlogloss:0.71167\n",
      "[254]\tvalidation_0-mlogloss:0.71067\n",
      "[255]\tvalidation_0-mlogloss:0.71049\n",
      "[256]\tvalidation_0-mlogloss:0.71024\n",
      "[257]\tvalidation_0-mlogloss:0.70947\n",
      "[258]\tvalidation_0-mlogloss:0.70899\n",
      "[259]\tvalidation_0-mlogloss:0.70847\n",
      "[260]\tvalidation_0-mlogloss:0.70793\n",
      "[261]\tvalidation_0-mlogloss:0.70769\n",
      "[262]\tvalidation_0-mlogloss:0.70771\n",
      "[263]\tvalidation_0-mlogloss:0.70758\n",
      "[264]\tvalidation_0-mlogloss:0.70714\n",
      "[265]\tvalidation_0-mlogloss:0.70718\n",
      "[266]\tvalidation_0-mlogloss:0.70677\n",
      "[267]\tvalidation_0-mlogloss:0.70659\n",
      "[268]\tvalidation_0-mlogloss:0.70600\n",
      "[269]\tvalidation_0-mlogloss:0.70636\n",
      "[270]\tvalidation_0-mlogloss:0.70577\n",
      "[271]\tvalidation_0-mlogloss:0.70509\n",
      "[272]\tvalidation_0-mlogloss:0.70422\n",
      "[273]\tvalidation_0-mlogloss:0.70380\n",
      "[274]\tvalidation_0-mlogloss:0.70315\n",
      "[275]\tvalidation_0-mlogloss:0.70245\n",
      "[276]\tvalidation_0-mlogloss:0.70220\n",
      "[277]\tvalidation_0-mlogloss:0.70181\n",
      "[278]\tvalidation_0-mlogloss:0.70171\n",
      "[279]\tvalidation_0-mlogloss:0.70168\n",
      "[280]\tvalidation_0-mlogloss:0.70163\n",
      "[281]\tvalidation_0-mlogloss:0.70075\n",
      "[282]\tvalidation_0-mlogloss:0.70038\n",
      "[283]\tvalidation_0-mlogloss:0.70016\n",
      "[284]\tvalidation_0-mlogloss:0.69974\n",
      "[285]\tvalidation_0-mlogloss:0.69904\n",
      "[286]\tvalidation_0-mlogloss:0.69783\n",
      "[287]\tvalidation_0-mlogloss:0.69729\n",
      "[288]\tvalidation_0-mlogloss:0.69642\n",
      "[289]\tvalidation_0-mlogloss:0.69635\n",
      "[290]\tvalidation_0-mlogloss:0.69591\n",
      "[291]\tvalidation_0-mlogloss:0.69550\n",
      "[292]\tvalidation_0-mlogloss:0.69537\n",
      "[293]\tvalidation_0-mlogloss:0.69436\n",
      "[294]\tvalidation_0-mlogloss:0.69432\n",
      "[295]\tvalidation_0-mlogloss:0.69378\n",
      "[296]\tvalidation_0-mlogloss:0.69338\n",
      "[297]\tvalidation_0-mlogloss:0.69312\n",
      "[298]\tvalidation_0-mlogloss:0.69307\n",
      "[299]\tvalidation_0-mlogloss:0.69355\n",
      "[300]\tvalidation_0-mlogloss:0.69310\n",
      "[301]\tvalidation_0-mlogloss:0.69283\n",
      "[302]\tvalidation_0-mlogloss:0.69313\n",
      "[303]\tvalidation_0-mlogloss:0.69255\n",
      "[304]\tvalidation_0-mlogloss:0.69186\n",
      "[305]\tvalidation_0-mlogloss:0.69259\n",
      "[306]\tvalidation_0-mlogloss:0.69311\n",
      "[307]\tvalidation_0-mlogloss:0.69336\n",
      "[308]\tvalidation_0-mlogloss:0.69272\n",
      "[309]\tvalidation_0-mlogloss:0.69272\n",
      "[310]\tvalidation_0-mlogloss:0.69214\n",
      "[311]\tvalidation_0-mlogloss:0.69193\n",
      "[312]\tvalidation_0-mlogloss:0.69088\n",
      "[313]\tvalidation_0-mlogloss:0.69092\n",
      "[314]\tvalidation_0-mlogloss:0.69073\n",
      "[315]\tvalidation_0-mlogloss:0.68985\n",
      "[316]\tvalidation_0-mlogloss:0.69002\n",
      "[317]\tvalidation_0-mlogloss:0.69031\n",
      "[318]\tvalidation_0-mlogloss:0.68897\n",
      "[319]\tvalidation_0-mlogloss:0.68831\n",
      "[320]\tvalidation_0-mlogloss:0.68784\n",
      "[321]\tvalidation_0-mlogloss:0.68768\n",
      "[322]\tvalidation_0-mlogloss:0.68715\n",
      "[323]\tvalidation_0-mlogloss:0.68664\n",
      "[324]\tvalidation_0-mlogloss:0.68671\n",
      "[325]\tvalidation_0-mlogloss:0.68644\n",
      "[326]\tvalidation_0-mlogloss:0.68606\n",
      "[327]\tvalidation_0-mlogloss:0.68570\n",
      "[328]\tvalidation_0-mlogloss:0.68613\n",
      "[329]\tvalidation_0-mlogloss:0.68649\n",
      "[330]\tvalidation_0-mlogloss:0.68552\n",
      "[331]\tvalidation_0-mlogloss:0.68481\n",
      "[332]\tvalidation_0-mlogloss:0.68453\n",
      "[333]\tvalidation_0-mlogloss:0.68377\n",
      "[334]\tvalidation_0-mlogloss:0.68363\n",
      "[335]\tvalidation_0-mlogloss:0.68296\n",
      "[336]\tvalidation_0-mlogloss:0.68319\n",
      "[337]\tvalidation_0-mlogloss:0.68300\n",
      "[338]\tvalidation_0-mlogloss:0.68238\n",
      "[339]\tvalidation_0-mlogloss:0.68218\n",
      "[340]\tvalidation_0-mlogloss:0.68216\n",
      "[341]\tvalidation_0-mlogloss:0.68183\n",
      "[342]\tvalidation_0-mlogloss:0.68148\n",
      "[343]\tvalidation_0-mlogloss:0.68118\n",
      "[344]\tvalidation_0-mlogloss:0.68088\n",
      "[345]\tvalidation_0-mlogloss:0.68072\n",
      "[346]\tvalidation_0-mlogloss:0.68039\n",
      "[347]\tvalidation_0-mlogloss:0.68089\n",
      "[348]\tvalidation_0-mlogloss:0.68031\n",
      "[349]\tvalidation_0-mlogloss:0.67960\n",
      "[350]\tvalidation_0-mlogloss:0.67971\n",
      "[351]\tvalidation_0-mlogloss:0.68021\n",
      "[352]\tvalidation_0-mlogloss:0.67982\n",
      "[353]\tvalidation_0-mlogloss:0.67928\n",
      "[354]\tvalidation_0-mlogloss:0.67938\n",
      "[355]\tvalidation_0-mlogloss:0.67944\n",
      "[356]\tvalidation_0-mlogloss:0.67918\n",
      "[357]\tvalidation_0-mlogloss:0.67900\n",
      "[358]\tvalidation_0-mlogloss:0.67930\n",
      "[359]\tvalidation_0-mlogloss:0.67977\n",
      "[360]\tvalidation_0-mlogloss:0.67934\n",
      "[361]\tvalidation_0-mlogloss:0.67877\n",
      "[362]\tvalidation_0-mlogloss:0.67854\n",
      "[363]\tvalidation_0-mlogloss:0.67857\n",
      "[364]\tvalidation_0-mlogloss:0.67861\n",
      "[365]\tvalidation_0-mlogloss:0.67873\n",
      "[366]\tvalidation_0-mlogloss:0.67855\n",
      "[367]\tvalidation_0-mlogloss:0.67812\n",
      "[368]\tvalidation_0-mlogloss:0.67844\n",
      "[369]\tvalidation_0-mlogloss:0.67858\n",
      "[370]\tvalidation_0-mlogloss:0.67853\n",
      "[371]\tvalidation_0-mlogloss:0.67840\n",
      "[372]\tvalidation_0-mlogloss:0.67837\n",
      "[373]\tvalidation_0-mlogloss:0.67807\n",
      "[374]\tvalidation_0-mlogloss:0.67819\n",
      "[375]\tvalidation_0-mlogloss:0.67826\n",
      "[376]\tvalidation_0-mlogloss:0.67795\n",
      "[377]\tvalidation_0-mlogloss:0.67785\n",
      "[378]\tvalidation_0-mlogloss:0.67793\n",
      "[379]\tvalidation_0-mlogloss:0.67810\n",
      "[380]\tvalidation_0-mlogloss:0.67738\n",
      "[381]\tvalidation_0-mlogloss:0.67715\n",
      "[382]\tvalidation_0-mlogloss:0.67673\n",
      "[383]\tvalidation_0-mlogloss:0.67660\n",
      "[384]\tvalidation_0-mlogloss:0.67655\n",
      "[385]\tvalidation_0-mlogloss:0.67611\n",
      "[386]\tvalidation_0-mlogloss:0.67558\n",
      "[387]\tvalidation_0-mlogloss:0.67564\n",
      "[388]\tvalidation_0-mlogloss:0.67583\n",
      "[389]\tvalidation_0-mlogloss:0.67574\n",
      "[390]\tvalidation_0-mlogloss:0.67547\n",
      "[391]\tvalidation_0-mlogloss:0.67596\n",
      "[392]\tvalidation_0-mlogloss:0.67547\n",
      "[393]\tvalidation_0-mlogloss:0.67555\n",
      "[394]\tvalidation_0-mlogloss:0.67553\n",
      "[395]\tvalidation_0-mlogloss:0.67493\n",
      "[396]\tvalidation_0-mlogloss:0.67466\n",
      "[397]\tvalidation_0-mlogloss:0.67451\n",
      "[398]\tvalidation_0-mlogloss:0.67440\n",
      "[399]\tvalidation_0-mlogloss:0.67456\n",
      "[400]\tvalidation_0-mlogloss:0.67408\n",
      "[401]\tvalidation_0-mlogloss:0.67394\n",
      "[402]\tvalidation_0-mlogloss:0.67374\n",
      "[403]\tvalidation_0-mlogloss:0.67383\n",
      "[404]\tvalidation_0-mlogloss:0.67395\n",
      "[405]\tvalidation_0-mlogloss:0.67386\n",
      "[406]\tvalidation_0-mlogloss:0.67367\n",
      "[407]\tvalidation_0-mlogloss:0.67417\n",
      "[408]\tvalidation_0-mlogloss:0.67396\n",
      "[409]\tvalidation_0-mlogloss:0.67322\n",
      "[410]\tvalidation_0-mlogloss:0.67369\n",
      "[411]\tvalidation_0-mlogloss:0.67327\n",
      "[412]\tvalidation_0-mlogloss:0.67380\n",
      "[413]\tvalidation_0-mlogloss:0.67375\n",
      "[414]\tvalidation_0-mlogloss:0.67324\n",
      "[415]\tvalidation_0-mlogloss:0.67314\n",
      "[416]\tvalidation_0-mlogloss:0.67300\n",
      "[417]\tvalidation_0-mlogloss:0.67282\n",
      "[418]\tvalidation_0-mlogloss:0.67356\n",
      "[419]\tvalidation_0-mlogloss:0.67303\n",
      "[420]\tvalidation_0-mlogloss:0.67340\n",
      "[421]\tvalidation_0-mlogloss:0.67354\n",
      "[422]\tvalidation_0-mlogloss:0.67297\n",
      "[423]\tvalidation_0-mlogloss:0.67330\n",
      "[424]\tvalidation_0-mlogloss:0.67361\n",
      "[425]\tvalidation_0-mlogloss:0.67330\n",
      "[426]\tvalidation_0-mlogloss:0.67409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75      1499\n",
      "           1       0.84      0.93      0.88      1499\n",
      "           2       0.73      0.87      0.80      1499\n",
      "           3       0.91      0.69      0.78      1499\n",
      "           4       0.95      0.98      0.96      1499\n",
      "           5       0.92      0.86      0.89      1499\n",
      "           6       0.92      0.98      0.95      1499\n",
      "           7       0.92      0.79      0.85      1499\n",
      "           8       0.63      0.91      0.75      1499\n",
      "           9       0.95      0.85      0.90      1499\n",
      "          10       0.94      0.75      0.84      1499\n",
      "          11       0.94      0.90      0.92      1499\n",
      "          12       0.75      0.83      0.79      1499\n",
      "          13       0.71      0.81      0.75      1499\n",
      "          14       0.65      0.81      0.72      1499\n",
      "          15       0.88      0.72      0.79      1499\n",
      "          16       0.95      0.56      0.71      1499\n",
      "          17       0.94      0.94      0.94      1499\n",
      "          18       0.82      0.86      0.84      1499\n",
      "          19       0.75      0.77      0.76      1499\n",
      "          20       0.96      0.93      0.94      1499\n",
      "          21       0.83      0.86      0.84      1499\n",
      "          22       0.73      0.86      0.79      1499\n",
      "          23       0.96      0.97      0.96      1499\n",
      "          24       0.87      0.53      0.66      1499\n",
      "\n",
      "    accuracy                           0.83     37475\n",
      "   macro avg       0.85      0.83      0.83     37475\n",
      "weighted avg       0.85      0.83      0.83     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3=XGBClassifier(n_estimators=500)\n",
    "model3.fit(x32,y32,early_stopping_rounds=10, eval_set=[(xv32, yv32)])\n",
    "y_pred=model3.predict(xt32)\n",
    "print(classification_report(yt32,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8f654ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model2 = Sequential(\n",
    "    [\n",
    "        Dense(32, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(25, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "300aa492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 11:33:03.291033: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 38400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 15s 2ms/step - loss: 0.8175 - val_loss: 2.0148\n",
      "Epoch 2/10\n",
      "9375/9375 [==============================] - 14s 2ms/step - loss: 0.2687 - val_loss: 1.8710\n",
      "Epoch 3/10\n",
      "9375/9375 [==============================] - 14s 2ms/step - loss: 0.1857 - val_loss: 1.7827\n",
      "Epoch 4/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.1519 - val_loss: 1.8325\n",
      "Epoch 5/10\n",
      "9375/9375 [==============================] - 14s 1ms/step - loss: 0.1314 - val_loss: 1.6044\n",
      "Epoch 6/10\n",
      "9375/9375 [==============================] - 14s 2ms/step - loss: 0.1172 - val_loss: 1.8141\n",
      "Epoch 7/10\n",
      "9375/9375 [==============================] - 15s 2ms/step - loss: 0.1065 - val_loss: 1.7100\n",
      "Epoch 8/10\n",
      "9375/9375 [==============================] - 14s 2ms/step - loss: 0.0997 - val_loss: 2.0032\n",
      "Epoch 9/10\n",
      "9375/9375 [==============================] - 15s 2ms/step - loss: 0.0931 - val_loss: 1.5126\n",
      "Epoch 10/10\n",
      "9375/9375 [==============================] - 14s 2ms/step - loss: 0.0864 - val_loss: 1.9673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1840e21210>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model2.fit(\n",
    "    x32,y32,epochs=10,validation_data=(xv32,yv32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eedffd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 228/1172 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 880us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.59      0.68      1499\n",
      "           1       0.75      0.88      0.81      1499\n",
      "           2       0.67      0.81      0.74      1499\n",
      "           3       0.57      0.56      0.56      1499\n",
      "           4       0.94      0.97      0.96      1499\n",
      "           5       0.90      0.74      0.81      1499\n",
      "           6       0.91      0.77      0.84      1499\n",
      "           7       0.85      0.63      0.72      1499\n",
      "           8       0.53      0.94      0.68      1499\n",
      "           9       0.85      0.88      0.87      1499\n",
      "          10       0.65      0.61      0.63      1499\n",
      "          11       0.98      0.72      0.83      1499\n",
      "          12       0.64      0.86      0.74      1499\n",
      "          13       0.38      0.82      0.52      1499\n",
      "          14       0.54      0.74      0.62      1499\n",
      "          15       0.69      0.45      0.55      1499\n",
      "          16       0.92      0.48      0.63      1499\n",
      "          17       1.00      0.85      0.92      1499\n",
      "          18       0.90      0.83      0.86      1499\n",
      "          19       0.66      0.39      0.49      1499\n",
      "          20       0.95      0.77      0.85      1499\n",
      "          21       0.59      0.81      0.68      1499\n",
      "          22       0.66      0.76      0.71      1499\n",
      "          23       0.92      0.95      0.94      1499\n",
      "          24       0.88      0.20      0.33      1499\n",
      "\n",
      "    accuracy                           0.72     37475\n",
      "   macro avg       0.77      0.72      0.72     37475\n",
      "weighted avg       0.77      0.72      0.72     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model2.predict(xt32)).numpy(),axis=1)\n",
    "print(classification_report(yt32,y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead93bfd",
   "metadata": {},
   "source": [
    "## 0-64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85c5c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain['id']=ytrain\n",
    "xtest['id']=ytest\n",
    "xvalid['id']=yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21e76096",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=scale_dataset(xtrain)\n",
    "xt,yt=scale_dataset(xtest)\n",
    "xv,yv=scale_dataset(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/xgboost/sklearn.py:885: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.44111\n",
      "[1]\tvalidation_0-mlogloss:2.20961\n",
      "[2]\tvalidation_0-mlogloss:2.03998\n",
      "[3]\tvalidation_0-mlogloss:1.91108\n",
      "[4]\tvalidation_0-mlogloss:1.80742\n",
      "[5]\tvalidation_0-mlogloss:1.71138\n",
      "[6]\tvalidation_0-mlogloss:1.63310\n",
      "[7]\tvalidation_0-mlogloss:1.56635\n",
      "[8]\tvalidation_0-mlogloss:1.50783\n",
      "[9]\tvalidation_0-mlogloss:1.45546\n",
      "[10]\tvalidation_0-mlogloss:1.40198\n",
      "[11]\tvalidation_0-mlogloss:1.35729\n",
      "[12]\tvalidation_0-mlogloss:1.32107\n",
      "[13]\tvalidation_0-mlogloss:1.28236\n",
      "[14]\tvalidation_0-mlogloss:1.24948\n",
      "[15]\tvalidation_0-mlogloss:1.21666\n",
      "[16]\tvalidation_0-mlogloss:1.18832\n",
      "[17]\tvalidation_0-mlogloss:1.15846\n",
      "[18]\tvalidation_0-mlogloss:1.13277\n",
      "[19]\tvalidation_0-mlogloss:1.10898\n",
      "[20]\tvalidation_0-mlogloss:1.08729\n",
      "[21]\tvalidation_0-mlogloss:1.06274\n",
      "[22]\tvalidation_0-mlogloss:1.04293\n",
      "[23]\tvalidation_0-mlogloss:1.02324\n",
      "[24]\tvalidation_0-mlogloss:1.00372\n",
      "[25]\tvalidation_0-mlogloss:0.98551\n",
      "[26]\tvalidation_0-mlogloss:0.97020\n",
      "[27]\tvalidation_0-mlogloss:0.95367\n",
      "[28]\tvalidation_0-mlogloss:0.93514\n",
      "[29]\tvalidation_0-mlogloss:0.92170\n",
      "[30]\tvalidation_0-mlogloss:0.90686\n",
      "[31]\tvalidation_0-mlogloss:0.89247\n",
      "[32]\tvalidation_0-mlogloss:0.87858\n",
      "[33]\tvalidation_0-mlogloss:0.86628\n",
      "[34]\tvalidation_0-mlogloss:0.85341\n",
      "[35]\tvalidation_0-mlogloss:0.84060\n",
      "[36]\tvalidation_0-mlogloss:0.83095\n",
      "[37]\tvalidation_0-mlogloss:0.82133\n",
      "[38]\tvalidation_0-mlogloss:0.81120\n",
      "[39]\tvalidation_0-mlogloss:0.80185\n",
      "[40]\tvalidation_0-mlogloss:0.79060\n",
      "[41]\tvalidation_0-mlogloss:0.78000\n",
      "[42]\tvalidation_0-mlogloss:0.76999\n",
      "[43]\tvalidation_0-mlogloss:0.76210\n",
      "[44]\tvalidation_0-mlogloss:0.75126\n",
      "[45]\tvalidation_0-mlogloss:0.74342\n",
      "[46]\tvalidation_0-mlogloss:0.73266\n",
      "[47]\tvalidation_0-mlogloss:0.72560\n",
      "[48]\tvalidation_0-mlogloss:0.71949\n",
      "[49]\tvalidation_0-mlogloss:0.71278\n",
      "[50]\tvalidation_0-mlogloss:0.70566\n",
      "[51]\tvalidation_0-mlogloss:0.69727\n",
      "[52]\tvalidation_0-mlogloss:0.69021\n",
      "[53]\tvalidation_0-mlogloss:0.68258\n",
      "[54]\tvalidation_0-mlogloss:0.67518\n",
      "[55]\tvalidation_0-mlogloss:0.66972\n",
      "[56]\tvalidation_0-mlogloss:0.66365\n",
      "[57]\tvalidation_0-mlogloss:0.65846\n",
      "[58]\tvalidation_0-mlogloss:0.65349\n",
      "[59]\tvalidation_0-mlogloss:0.64775\n",
      "[60]\tvalidation_0-mlogloss:0.64178\n",
      "[61]\tvalidation_0-mlogloss:0.63566\n",
      "[62]\tvalidation_0-mlogloss:0.63109\n",
      "[63]\tvalidation_0-mlogloss:0.62565\n",
      "[64]\tvalidation_0-mlogloss:0.61901\n",
      "[65]\tvalidation_0-mlogloss:0.61290\n",
      "[66]\tvalidation_0-mlogloss:0.60683\n",
      "[67]\tvalidation_0-mlogloss:0.60173\n",
      "[68]\tvalidation_0-mlogloss:0.59657\n",
      "[69]\tvalidation_0-mlogloss:0.59286\n",
      "[70]\tvalidation_0-mlogloss:0.58828\n",
      "[71]\tvalidation_0-mlogloss:0.58494\n",
      "[72]\tvalidation_0-mlogloss:0.58017\n",
      "[73]\tvalidation_0-mlogloss:0.57649\n",
      "[74]\tvalidation_0-mlogloss:0.57034\n",
      "[75]\tvalidation_0-mlogloss:0.56543\n",
      "[76]\tvalidation_0-mlogloss:0.56084\n",
      "[77]\tvalidation_0-mlogloss:0.55669\n",
      "[78]\tvalidation_0-mlogloss:0.55239\n",
      "[79]\tvalidation_0-mlogloss:0.54740\n",
      "[80]\tvalidation_0-mlogloss:0.54372\n",
      "[81]\tvalidation_0-mlogloss:0.54050\n",
      "[82]\tvalidation_0-mlogloss:0.53865\n",
      "[83]\tvalidation_0-mlogloss:0.53421\n",
      "[84]\tvalidation_0-mlogloss:0.52897\n",
      "[85]\tvalidation_0-mlogloss:0.52600\n",
      "[86]\tvalidation_0-mlogloss:0.52289\n",
      "[87]\tvalidation_0-mlogloss:0.52053\n",
      "[88]\tvalidation_0-mlogloss:0.51752\n",
      "[89]\tvalidation_0-mlogloss:0.51493\n",
      "[90]\tvalidation_0-mlogloss:0.51078\n",
      "[91]\tvalidation_0-mlogloss:0.50743\n",
      "[92]\tvalidation_0-mlogloss:0.50528\n",
      "[93]\tvalidation_0-mlogloss:0.50194\n",
      "[94]\tvalidation_0-mlogloss:0.49899\n",
      "[95]\tvalidation_0-mlogloss:0.49635\n",
      "[96]\tvalidation_0-mlogloss:0.49255\n",
      "[97]\tvalidation_0-mlogloss:0.48981\n",
      "[98]\tvalidation_0-mlogloss:0.48804\n",
      "[99]\tvalidation_0-mlogloss:0.48663\n",
      "[100]\tvalidation_0-mlogloss:0.48448\n",
      "[101]\tvalidation_0-mlogloss:0.48278\n",
      "[102]\tvalidation_0-mlogloss:0.47932\n",
      "[103]\tvalidation_0-mlogloss:0.47684\n",
      "[104]\tvalidation_0-mlogloss:0.47532\n",
      "[105]\tvalidation_0-mlogloss:0.47427\n",
      "[106]\tvalidation_0-mlogloss:0.47240\n",
      "[107]\tvalidation_0-mlogloss:0.47008\n",
      "[108]\tvalidation_0-mlogloss:0.46815\n",
      "[109]\tvalidation_0-mlogloss:0.46584\n",
      "[110]\tvalidation_0-mlogloss:0.46386\n",
      "[111]\tvalidation_0-mlogloss:0.46234\n",
      "[112]\tvalidation_0-mlogloss:0.46078\n",
      "[113]\tvalidation_0-mlogloss:0.45908\n",
      "[114]\tvalidation_0-mlogloss:0.45682\n",
      "[115]\tvalidation_0-mlogloss:0.45539\n",
      "[116]\tvalidation_0-mlogloss:0.45279\n",
      "[117]\tvalidation_0-mlogloss:0.45092\n",
      "[118]\tvalidation_0-mlogloss:0.44846\n",
      "[119]\tvalidation_0-mlogloss:0.44668\n",
      "[120]\tvalidation_0-mlogloss:0.44544\n",
      "[121]\tvalidation_0-mlogloss:0.44421\n",
      "[122]\tvalidation_0-mlogloss:0.44298\n",
      "[123]\tvalidation_0-mlogloss:0.44065\n",
      "[124]\tvalidation_0-mlogloss:0.43905\n",
      "[125]\tvalidation_0-mlogloss:0.43814\n",
      "[126]\tvalidation_0-mlogloss:0.43634\n",
      "[127]\tvalidation_0-mlogloss:0.43471\n",
      "[128]\tvalidation_0-mlogloss:0.43249\n",
      "[129]\tvalidation_0-mlogloss:0.43030\n",
      "[130]\tvalidation_0-mlogloss:0.42900\n",
      "[131]\tvalidation_0-mlogloss:0.42720\n",
      "[132]\tvalidation_0-mlogloss:0.42602\n",
      "[133]\tvalidation_0-mlogloss:0.42440\n",
      "[134]\tvalidation_0-mlogloss:0.42301\n",
      "[135]\tvalidation_0-mlogloss:0.42115\n",
      "[136]\tvalidation_0-mlogloss:0.41865\n",
      "[137]\tvalidation_0-mlogloss:0.41758\n",
      "[138]\tvalidation_0-mlogloss:0.41560\n",
      "[139]\tvalidation_0-mlogloss:0.41438\n",
      "[140]\tvalidation_0-mlogloss:0.41341\n",
      "[141]\tvalidation_0-mlogloss:0.41234\n",
      "[142]\tvalidation_0-mlogloss:0.41145\n",
      "[143]\tvalidation_0-mlogloss:0.41057\n",
      "[144]\tvalidation_0-mlogloss:0.40971\n",
      "[145]\tvalidation_0-mlogloss:0.40796\n",
      "[146]\tvalidation_0-mlogloss:0.40729\n",
      "[147]\tvalidation_0-mlogloss:0.40548\n",
      "[148]\tvalidation_0-mlogloss:0.40348\n",
      "[149]\tvalidation_0-mlogloss:0.40208\n",
      "[150]\tvalidation_0-mlogloss:0.40080\n",
      "[151]\tvalidation_0-mlogloss:0.39986\n",
      "[152]\tvalidation_0-mlogloss:0.39897\n",
      "[153]\tvalidation_0-mlogloss:0.39719\n",
      "[154]\tvalidation_0-mlogloss:0.39649\n",
      "[155]\tvalidation_0-mlogloss:0.39559\n",
      "[156]\tvalidation_0-mlogloss:0.39468\n",
      "[157]\tvalidation_0-mlogloss:0.39272\n",
      "[158]\tvalidation_0-mlogloss:0.39136\n",
      "[159]\tvalidation_0-mlogloss:0.38972\n",
      "[160]\tvalidation_0-mlogloss:0.38901\n",
      "[161]\tvalidation_0-mlogloss:0.38780\n",
      "[162]\tvalidation_0-mlogloss:0.38686\n",
      "[163]\tvalidation_0-mlogloss:0.38556\n",
      "[164]\tvalidation_0-mlogloss:0.38505\n",
      "[165]\tvalidation_0-mlogloss:0.38445\n",
      "[166]\tvalidation_0-mlogloss:0.38393\n",
      "[167]\tvalidation_0-mlogloss:0.38269\n",
      "[168]\tvalidation_0-mlogloss:0.38214\n",
      "[169]\tvalidation_0-mlogloss:0.38132\n",
      "[170]\tvalidation_0-mlogloss:0.38076\n",
      "[171]\tvalidation_0-mlogloss:0.38036\n",
      "[172]\tvalidation_0-mlogloss:0.37923\n",
      "[173]\tvalidation_0-mlogloss:0.37889\n",
      "[174]\tvalidation_0-mlogloss:0.37817\n",
      "[175]\tvalidation_0-mlogloss:0.37745\n",
      "[176]\tvalidation_0-mlogloss:0.37623\n",
      "[177]\tvalidation_0-mlogloss:0.37530\n",
      "[178]\tvalidation_0-mlogloss:0.37505\n",
      "[179]\tvalidation_0-mlogloss:0.37455\n",
      "[180]\tvalidation_0-mlogloss:0.37349\n",
      "[181]\tvalidation_0-mlogloss:0.37264\n",
      "[182]\tvalidation_0-mlogloss:0.37269\n",
      "[183]\tvalidation_0-mlogloss:0.37160\n",
      "[184]\tvalidation_0-mlogloss:0.37026\n",
      "[185]\tvalidation_0-mlogloss:0.36936\n",
      "[186]\tvalidation_0-mlogloss:0.36850\n",
      "[187]\tvalidation_0-mlogloss:0.36794\n",
      "[188]\tvalidation_0-mlogloss:0.36726\n",
      "[189]\tvalidation_0-mlogloss:0.36662\n",
      "[190]\tvalidation_0-mlogloss:0.36606\n",
      "[191]\tvalidation_0-mlogloss:0.36505\n",
      "[192]\tvalidation_0-mlogloss:0.36427\n",
      "[193]\tvalidation_0-mlogloss:0.36374\n",
      "[194]\tvalidation_0-mlogloss:0.36280\n",
      "[195]\tvalidation_0-mlogloss:0.36204\n",
      "[196]\tvalidation_0-mlogloss:0.36140\n",
      "[197]\tvalidation_0-mlogloss:0.36136\n",
      "[198]\tvalidation_0-mlogloss:0.36041\n",
      "[199]\tvalidation_0-mlogloss:0.36005\n",
      "[200]\tvalidation_0-mlogloss:0.35882\n",
      "[201]\tvalidation_0-mlogloss:0.35821\n",
      "[202]\tvalidation_0-mlogloss:0.35716\n",
      "[203]\tvalidation_0-mlogloss:0.35630\n",
      "[204]\tvalidation_0-mlogloss:0.35562\n",
      "[205]\tvalidation_0-mlogloss:0.35506\n",
      "[206]\tvalidation_0-mlogloss:0.35461\n",
      "[207]\tvalidation_0-mlogloss:0.35395\n",
      "[208]\tvalidation_0-mlogloss:0.35346\n",
      "[209]\tvalidation_0-mlogloss:0.35317\n",
      "[210]\tvalidation_0-mlogloss:0.35258\n",
      "[211]\tvalidation_0-mlogloss:0.35239\n",
      "[212]\tvalidation_0-mlogloss:0.35238\n",
      "[213]\tvalidation_0-mlogloss:0.35169\n",
      "[214]\tvalidation_0-mlogloss:0.35120\n",
      "[215]\tvalidation_0-mlogloss:0.35051\n",
      "[216]\tvalidation_0-mlogloss:0.34979\n",
      "[217]\tvalidation_0-mlogloss:0.34916\n",
      "[218]\tvalidation_0-mlogloss:0.34838\n",
      "[219]\tvalidation_0-mlogloss:0.34779\n",
      "[220]\tvalidation_0-mlogloss:0.34703\n",
      "[221]\tvalidation_0-mlogloss:0.34652\n",
      "[222]\tvalidation_0-mlogloss:0.34571\n",
      "[223]\tvalidation_0-mlogloss:0.34527\n",
      "[224]\tvalidation_0-mlogloss:0.34460\n",
      "[225]\tvalidation_0-mlogloss:0.34424\n",
      "[226]\tvalidation_0-mlogloss:0.34375\n",
      "[227]\tvalidation_0-mlogloss:0.34353\n",
      "[228]\tvalidation_0-mlogloss:0.34289\n",
      "[229]\tvalidation_0-mlogloss:0.34241\n",
      "[230]\tvalidation_0-mlogloss:0.34161\n",
      "[231]\tvalidation_0-mlogloss:0.34094\n",
      "[232]\tvalidation_0-mlogloss:0.34036\n",
      "[233]\tvalidation_0-mlogloss:0.33995\n",
      "[234]\tvalidation_0-mlogloss:0.33906\n",
      "[235]\tvalidation_0-mlogloss:0.33865\n",
      "[236]\tvalidation_0-mlogloss:0.33805\n",
      "[237]\tvalidation_0-mlogloss:0.33771\n",
      "[238]\tvalidation_0-mlogloss:0.33747\n",
      "[239]\tvalidation_0-mlogloss:0.33701\n",
      "[240]\tvalidation_0-mlogloss:0.33643\n",
      "[241]\tvalidation_0-mlogloss:0.33565\n",
      "[242]\tvalidation_0-mlogloss:0.33514\n",
      "[243]\tvalidation_0-mlogloss:0.33462\n",
      "[244]\tvalidation_0-mlogloss:0.33394\n",
      "[245]\tvalidation_0-mlogloss:0.33335\n",
      "[246]\tvalidation_0-mlogloss:0.33270\n",
      "[247]\tvalidation_0-mlogloss:0.33251\n",
      "[248]\tvalidation_0-mlogloss:0.33189\n",
      "[249]\tvalidation_0-mlogloss:0.33170\n",
      "[250]\tvalidation_0-mlogloss:0.33142\n",
      "[251]\tvalidation_0-mlogloss:0.33104\n",
      "[252]\tvalidation_0-mlogloss:0.33033\n",
      "[253]\tvalidation_0-mlogloss:0.32942\n",
      "[254]\tvalidation_0-mlogloss:0.32927\n",
      "[255]\tvalidation_0-mlogloss:0.32900\n",
      "[256]\tvalidation_0-mlogloss:0.32836\n",
      "[257]\tvalidation_0-mlogloss:0.32800\n",
      "[258]\tvalidation_0-mlogloss:0.32726\n",
      "[259]\tvalidation_0-mlogloss:0.32708\n",
      "[260]\tvalidation_0-mlogloss:0.32700\n",
      "[261]\tvalidation_0-mlogloss:0.32683\n",
      "[262]\tvalidation_0-mlogloss:0.32655\n",
      "[263]\tvalidation_0-mlogloss:0.32583\n",
      "[264]\tvalidation_0-mlogloss:0.32531\n",
      "[265]\tvalidation_0-mlogloss:0.32502\n",
      "[266]\tvalidation_0-mlogloss:0.32474\n",
      "[267]\tvalidation_0-mlogloss:0.32433\n",
      "[268]\tvalidation_0-mlogloss:0.32392\n",
      "[269]\tvalidation_0-mlogloss:0.32346\n",
      "[270]\tvalidation_0-mlogloss:0.32320\n",
      "[271]\tvalidation_0-mlogloss:0.32256\n",
      "[272]\tvalidation_0-mlogloss:0.32222\n",
      "[273]\tvalidation_0-mlogloss:0.32192\n",
      "[274]\tvalidation_0-mlogloss:0.32175\n",
      "[275]\tvalidation_0-mlogloss:0.32132\n",
      "[276]\tvalidation_0-mlogloss:0.32178\n",
      "[277]\tvalidation_0-mlogloss:0.32174\n",
      "[278]\tvalidation_0-mlogloss:0.32128\n",
      "[279]\tvalidation_0-mlogloss:0.32088\n",
      "[280]\tvalidation_0-mlogloss:0.32032\n",
      "[281]\tvalidation_0-mlogloss:0.31972\n",
      "[282]\tvalidation_0-mlogloss:0.31979\n",
      "[283]\tvalidation_0-mlogloss:0.31951\n",
      "[284]\tvalidation_0-mlogloss:0.31928\n",
      "[285]\tvalidation_0-mlogloss:0.31862\n",
      "[286]\tvalidation_0-mlogloss:0.31833\n",
      "[287]\tvalidation_0-mlogloss:0.31802\n",
      "[288]\tvalidation_0-mlogloss:0.31774\n",
      "[289]\tvalidation_0-mlogloss:0.31721\n",
      "[290]\tvalidation_0-mlogloss:0.31684\n",
      "[291]\tvalidation_0-mlogloss:0.31642\n",
      "[292]\tvalidation_0-mlogloss:0.31620\n",
      "[293]\tvalidation_0-mlogloss:0.31611\n",
      "[294]\tvalidation_0-mlogloss:0.31551\n",
      "[295]\tvalidation_0-mlogloss:0.31514\n",
      "[296]\tvalidation_0-mlogloss:0.31429\n",
      "[297]\tvalidation_0-mlogloss:0.31430\n",
      "[298]\tvalidation_0-mlogloss:0.31428\n",
      "[299]\tvalidation_0-mlogloss:0.31390\n",
      "[300]\tvalidation_0-mlogloss:0.31397\n",
      "[301]\tvalidation_0-mlogloss:0.31398\n",
      "[302]\tvalidation_0-mlogloss:0.31384\n",
      "[303]\tvalidation_0-mlogloss:0.31341\n",
      "[304]\tvalidation_0-mlogloss:0.31344\n",
      "[305]\tvalidation_0-mlogloss:0.31346\n",
      "[306]\tvalidation_0-mlogloss:0.31310\n",
      "[307]\tvalidation_0-mlogloss:0.31295\n",
      "[308]\tvalidation_0-mlogloss:0.31249\n",
      "[309]\tvalidation_0-mlogloss:0.31218\n",
      "[310]\tvalidation_0-mlogloss:0.31212\n",
      "[311]\tvalidation_0-mlogloss:0.31170\n",
      "[312]\tvalidation_0-mlogloss:0.31142\n",
      "[313]\tvalidation_0-mlogloss:0.31132\n",
      "[314]\tvalidation_0-mlogloss:0.31088\n",
      "[315]\tvalidation_0-mlogloss:0.31110\n",
      "[316]\tvalidation_0-mlogloss:0.31063\n",
      "[317]\tvalidation_0-mlogloss:0.31032\n",
      "[318]\tvalidation_0-mlogloss:0.31002\n",
      "[319]\tvalidation_0-mlogloss:0.31004\n",
      "[320]\tvalidation_0-mlogloss:0.30971\n",
      "[321]\tvalidation_0-mlogloss:0.30976\n",
      "[322]\tvalidation_0-mlogloss:0.30957\n",
      "[323]\tvalidation_0-mlogloss:0.30895\n",
      "[324]\tvalidation_0-mlogloss:0.30884\n",
      "[325]\tvalidation_0-mlogloss:0.30884\n",
      "[326]\tvalidation_0-mlogloss:0.30870\n",
      "[327]\tvalidation_0-mlogloss:0.30856\n",
      "[328]\tvalidation_0-mlogloss:0.30815\n",
      "[329]\tvalidation_0-mlogloss:0.30824\n",
      "[330]\tvalidation_0-mlogloss:0.30804\n",
      "[331]\tvalidation_0-mlogloss:0.30767\n",
      "[332]\tvalidation_0-mlogloss:0.30712\n",
      "[333]\tvalidation_0-mlogloss:0.30697\n",
      "[334]\tvalidation_0-mlogloss:0.30702\n",
      "[335]\tvalidation_0-mlogloss:0.30685\n",
      "[336]\tvalidation_0-mlogloss:0.30656\n",
      "[337]\tvalidation_0-mlogloss:0.30625\n",
      "[338]\tvalidation_0-mlogloss:0.30612\n",
      "[339]\tvalidation_0-mlogloss:0.30620\n",
      "[340]\tvalidation_0-mlogloss:0.30585\n",
      "[341]\tvalidation_0-mlogloss:0.30571\n",
      "[342]\tvalidation_0-mlogloss:0.30521\n",
      "[343]\tvalidation_0-mlogloss:0.30485\n",
      "[344]\tvalidation_0-mlogloss:0.30487\n",
      "[345]\tvalidation_0-mlogloss:0.30465\n",
      "[346]\tvalidation_0-mlogloss:0.30438\n",
      "[347]\tvalidation_0-mlogloss:0.30430\n",
      "[348]\tvalidation_0-mlogloss:0.30389\n",
      "[349]\tvalidation_0-mlogloss:0.30388\n",
      "[350]\tvalidation_0-mlogloss:0.30382\n",
      "[351]\tvalidation_0-mlogloss:0.30356\n",
      "[352]\tvalidation_0-mlogloss:0.30368\n",
      "[353]\tvalidation_0-mlogloss:0.30370\n",
      "[354]\tvalidation_0-mlogloss:0.30352\n",
      "[355]\tvalidation_0-mlogloss:0.30322\n",
      "[356]\tvalidation_0-mlogloss:0.30312\n",
      "[357]\tvalidation_0-mlogloss:0.30265\n",
      "[358]\tvalidation_0-mlogloss:0.30259\n",
      "[359]\tvalidation_0-mlogloss:0.30263\n",
      "[360]\tvalidation_0-mlogloss:0.30227\n",
      "[361]\tvalidation_0-mlogloss:0.30191\n",
      "[362]\tvalidation_0-mlogloss:0.30161\n",
      "[363]\tvalidation_0-mlogloss:0.30116\n",
      "[364]\tvalidation_0-mlogloss:0.30106\n",
      "[365]\tvalidation_0-mlogloss:0.30072\n",
      "[366]\tvalidation_0-mlogloss:0.30079\n",
      "[367]\tvalidation_0-mlogloss:0.30038\n",
      "[368]\tvalidation_0-mlogloss:0.30026\n",
      "[369]\tvalidation_0-mlogloss:0.30006\n",
      "[370]\tvalidation_0-mlogloss:0.30013\n",
      "[371]\tvalidation_0-mlogloss:0.30007\n",
      "[372]\tvalidation_0-mlogloss:0.29985\n",
      "[373]\tvalidation_0-mlogloss:0.29947\n",
      "[374]\tvalidation_0-mlogloss:0.29941\n",
      "[375]\tvalidation_0-mlogloss:0.29960\n",
      "[376]\tvalidation_0-mlogloss:0.29933\n",
      "[377]\tvalidation_0-mlogloss:0.29934\n",
      "[378]\tvalidation_0-mlogloss:0.29903\n",
      "[379]\tvalidation_0-mlogloss:0.29880\n",
      "[380]\tvalidation_0-mlogloss:0.29886\n",
      "[381]\tvalidation_0-mlogloss:0.29885\n",
      "[382]\tvalidation_0-mlogloss:0.29867\n",
      "[383]\tvalidation_0-mlogloss:0.29878\n",
      "[384]\tvalidation_0-mlogloss:0.29870\n",
      "[385]\tvalidation_0-mlogloss:0.29859\n",
      "[386]\tvalidation_0-mlogloss:0.29878\n",
      "[387]\tvalidation_0-mlogloss:0.29877\n",
      "[388]\tvalidation_0-mlogloss:0.29839\n",
      "[389]\tvalidation_0-mlogloss:0.29838\n",
      "[390]\tvalidation_0-mlogloss:0.29823\n",
      "[391]\tvalidation_0-mlogloss:0.29827\n",
      "[392]\tvalidation_0-mlogloss:0.29804\n",
      "[393]\tvalidation_0-mlogloss:0.29768\n",
      "[394]\tvalidation_0-mlogloss:0.29739\n",
      "[395]\tvalidation_0-mlogloss:0.29713\n",
      "[396]\tvalidation_0-mlogloss:0.29709\n",
      "[397]\tvalidation_0-mlogloss:0.29717\n",
      "[398]\tvalidation_0-mlogloss:0.29711\n",
      "[399]\tvalidation_0-mlogloss:0.29692\n",
      "[400]\tvalidation_0-mlogloss:0.29693\n",
      "[401]\tvalidation_0-mlogloss:0.29687\n",
      "[402]\tvalidation_0-mlogloss:0.29672\n",
      "[403]\tvalidation_0-mlogloss:0.29646\n",
      "[404]\tvalidation_0-mlogloss:0.29667\n",
      "[405]\tvalidation_0-mlogloss:0.29687\n",
      "[406]\tvalidation_0-mlogloss:0.29671\n",
      "[407]\tvalidation_0-mlogloss:0.29655\n",
      "[408]\tvalidation_0-mlogloss:0.29657\n",
      "[409]\tvalidation_0-mlogloss:0.29646\n",
      "[410]\tvalidation_0-mlogloss:0.29643\n",
      "[411]\tvalidation_0-mlogloss:0.29641\n",
      "[412]\tvalidation_0-mlogloss:0.29604\n",
      "[413]\tvalidation_0-mlogloss:0.29586\n",
      "[414]\tvalidation_0-mlogloss:0.29583\n",
      "[415]\tvalidation_0-mlogloss:0.29558\n",
      "[416]\tvalidation_0-mlogloss:0.29530\n",
      "[417]\tvalidation_0-mlogloss:0.29528\n",
      "[418]\tvalidation_0-mlogloss:0.29519\n",
      "[419]\tvalidation_0-mlogloss:0.29502\n",
      "[420]\tvalidation_0-mlogloss:0.29483\n",
      "[421]\tvalidation_0-mlogloss:0.29485\n",
      "[422]\tvalidation_0-mlogloss:0.29517\n",
      "[423]\tvalidation_0-mlogloss:0.29513\n",
      "[424]\tvalidation_0-mlogloss:0.29481\n",
      "[425]\tvalidation_0-mlogloss:0.29474\n",
      "[426]\tvalidation_0-mlogloss:0.29458\n",
      "[427]\tvalidation_0-mlogloss:0.29456\n",
      "[428]\tvalidation_0-mlogloss:0.29436\n",
      "[429]\tvalidation_0-mlogloss:0.29418\n",
      "[430]\tvalidation_0-mlogloss:0.29410\n",
      "[431]\tvalidation_0-mlogloss:0.29416\n",
      "[432]\tvalidation_0-mlogloss:0.29416\n",
      "[433]\tvalidation_0-mlogloss:0.29417\n",
      "[434]\tvalidation_0-mlogloss:0.29408\n",
      "[435]\tvalidation_0-mlogloss:0.29395\n",
      "[436]\tvalidation_0-mlogloss:0.29386\n",
      "[437]\tvalidation_0-mlogloss:0.29414\n",
      "[438]\tvalidation_0-mlogloss:0.29419\n",
      "[439]\tvalidation_0-mlogloss:0.29436\n",
      "[440]\tvalidation_0-mlogloss:0.29428\n",
      "[441]\tvalidation_0-mlogloss:0.29409\n",
      "[442]\tvalidation_0-mlogloss:0.29409\n",
      "[443]\tvalidation_0-mlogloss:0.29392\n",
      "[444]\tvalidation_0-mlogloss:0.29392\n",
      "[445]\tvalidation_0-mlogloss:0.29401\n",
      "[446]\tvalidation_0-mlogloss:0.29384\n",
      "[447]\tvalidation_0-mlogloss:0.29380\n",
      "[448]\tvalidation_0-mlogloss:0.29360\n",
      "[449]\tvalidation_0-mlogloss:0.29358\n",
      "[450]\tvalidation_0-mlogloss:0.29364\n",
      "[451]\tvalidation_0-mlogloss:0.29339\n",
      "[452]\tvalidation_0-mlogloss:0.29344\n",
      "[453]\tvalidation_0-mlogloss:0.29354\n",
      "[454]\tvalidation_0-mlogloss:0.29367\n",
      "[455]\tvalidation_0-mlogloss:0.29361\n",
      "[456]\tvalidation_0-mlogloss:0.29356\n",
      "[457]\tvalidation_0-mlogloss:0.29365\n",
      "[458]\tvalidation_0-mlogloss:0.29355\n",
      "[459]\tvalidation_0-mlogloss:0.29354\n",
      "[460]\tvalidation_0-mlogloss:0.29333\n",
      "[461]\tvalidation_0-mlogloss:0.29360\n",
      "[462]\tvalidation_0-mlogloss:0.29359\n",
      "[463]\tvalidation_0-mlogloss:0.29343\n",
      "[464]\tvalidation_0-mlogloss:0.29358\n",
      "[465]\tvalidation_0-mlogloss:0.29325\n",
      "[466]\tvalidation_0-mlogloss:0.29346\n",
      "[467]\tvalidation_0-mlogloss:0.29326\n",
      "[468]\tvalidation_0-mlogloss:0.29319\n",
      "[469]\tvalidation_0-mlogloss:0.29305\n",
      "[470]\tvalidation_0-mlogloss:0.29280\n",
      "[471]\tvalidation_0-mlogloss:0.29296\n",
      "[472]\tvalidation_0-mlogloss:0.29289\n",
      "[473]\tvalidation_0-mlogloss:0.29281\n",
      "[474]\tvalidation_0-mlogloss:0.29253\n",
      "[475]\tvalidation_0-mlogloss:0.29250\n",
      "[476]\tvalidation_0-mlogloss:0.29254\n",
      "[477]\tvalidation_0-mlogloss:0.29266\n",
      "[478]\tvalidation_0-mlogloss:0.29258\n",
      "[479]\tvalidation_0-mlogloss:0.29255\n",
      "[480]\tvalidation_0-mlogloss:0.29227\n",
      "[481]\tvalidation_0-mlogloss:0.29230\n",
      "[482]\tvalidation_0-mlogloss:0.29218\n",
      "[483]\tvalidation_0-mlogloss:0.29210\n",
      "[484]\tvalidation_0-mlogloss:0.29211\n",
      "[485]\tvalidation_0-mlogloss:0.29204\n",
      "[486]\tvalidation_0-mlogloss:0.29211\n",
      "[487]\tvalidation_0-mlogloss:0.29210\n",
      "[488]\tvalidation_0-mlogloss:0.29210\n",
      "[489]\tvalidation_0-mlogloss:0.29208\n",
      "[490]\tvalidation_0-mlogloss:0.29198\n",
      "[491]\tvalidation_0-mlogloss:0.29188\n",
      "[492]\tvalidation_0-mlogloss:0.29168\n",
      "[493]\tvalidation_0-mlogloss:0.29164\n",
      "[494]\tvalidation_0-mlogloss:0.29133\n",
      "[495]\tvalidation_0-mlogloss:0.29124\n",
      "[496]\tvalidation_0-mlogloss:0.29107\n",
      "[497]\tvalidation_0-mlogloss:0.29099\n",
      "[498]\tvalidation_0-mlogloss:0.29102\n",
      "[499]\tvalidation_0-mlogloss:0.29099\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1499\n",
      "           1       0.87      0.98      0.92      1499\n",
      "           2       0.91      0.90      0.91      1499\n",
      "           3       0.91      0.95      0.93      1499\n",
      "           4       0.98      1.00      0.99      1499\n",
      "           5       0.87      0.97      0.92      1499\n",
      "           6       0.98      0.99      0.99      1499\n",
      "           7       0.96      0.87      0.91      1499\n",
      "           8       0.85      0.92      0.89      1499\n",
      "           9       0.99      0.96      0.98      1499\n",
      "          10       0.99      0.78      0.87      1499\n",
      "          11       0.95      0.99      0.97      1499\n",
      "          12       0.88      0.94      0.91      1499\n",
      "          13       0.84      0.92      0.88      1499\n",
      "          14       0.89      0.91      0.90      1499\n",
      "          15       0.96      0.88      0.92      1499\n",
      "          16       0.99      0.84      0.91      1499\n",
      "          17       0.97      0.98      0.97      1499\n",
      "          18       0.91      0.94      0.93      1499\n",
      "          19       0.86      0.78      0.82      1499\n",
      "          20       0.96      0.82      0.88      1499\n",
      "          21       0.93      0.93      0.93      1499\n",
      "          22       0.80      0.95      0.87      1499\n",
      "          23       0.98      0.99      0.99      1499\n",
      "          24       0.91      0.87      0.89      1499\n",
      "\n",
      "    accuracy                           0.92     37475\n",
      "   macro avg       0.92      0.92      0.92     37475\n",
      "weighted avg       0.92      0.92      0.92     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model4=XGBClassifier(n_estimators=500)\n",
    "model4.fit(x,y,early_stopping_rounds=10, eval_set=[(xv, yv)])\n",
    "y_pred=model4.predict(xt)\n",
    "print(classification_report(yt,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1dad4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model3 = Sequential(\n",
    "    [\n",
    "        Dense(64, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(25, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3361defb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-04 11:35:29.030629: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 76800000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 [==============================] - 15s 2ms/step - loss: 0.5260 - val_loss: 1.2493\n",
      "Epoch 2/10\n",
      "9375/9375 [==============================] - 14s 2ms/step - loss: 0.1637 - val_loss: 1.1901\n",
      "Epoch 3/10\n",
      "9375/9375 [==============================] - 14s 2ms/step - loss: 0.1160 - val_loss: 1.1938\n",
      "Epoch 4/10\n",
      "9375/9375 [==============================] - 14s 2ms/step - loss: 0.0946 - val_loss: 1.1484\n",
      "Epoch 5/10\n",
      "9375/9375 [==============================] - 14s 2ms/step - loss: 0.0795 - val_loss: 1.0209\n",
      "Epoch 6/10\n",
      "9375/9375 [==============================] - 14s 2ms/step - loss: 0.0712 - val_loss: 0.8775\n",
      "Epoch 7/10\n",
      "9375/9375 [==============================] - 15s 2ms/step - loss: 0.0634 - val_loss: 0.9754\n",
      "Epoch 8/10\n",
      "9375/9375 [==============================] - 15s 2ms/step - loss: 0.0588 - val_loss: 1.0735\n",
      "Epoch 9/10\n",
      "9375/9375 [==============================] - 15s 2ms/step - loss: 0.0556 - val_loss: 1.0181\n",
      "Epoch 10/10\n",
      "9375/9375 [==============================] - 15s 2ms/step - loss: 0.0509 - val_loss: 1.1411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f1841572b90>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model3.fit(\n",
    "    x,y,epochs=10,validation_data=(xv,yv)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43017064",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 117/1172 [=>............................] - ETA: 0s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172/1172 [==============================] - 1s 880us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      1499\n",
      "           1       0.92      0.94      0.93      1499\n",
      "           2       0.71      0.66      0.68      1499\n",
      "           3       0.85      0.83      0.84      1499\n",
      "           4       0.98      1.00      0.99      1499\n",
      "           5       0.86      0.91      0.89      1499\n",
      "           6       0.96      0.97      0.97      1499\n",
      "           7       0.75      0.79      0.77      1499\n",
      "           8       0.82      0.91      0.87      1499\n",
      "           9       0.89      0.99      0.94      1499\n",
      "          10       0.88      0.33      0.48      1499\n",
      "          11       0.87      0.92      0.89      1499\n",
      "          12       0.67      0.95      0.79      1499\n",
      "          13       0.41      0.86      0.56      1499\n",
      "          14       0.73      0.83      0.77      1499\n",
      "          15       0.94      0.41      0.57      1499\n",
      "          16       0.98      0.71      0.82      1499\n",
      "          17       0.99      0.92      0.95      1499\n",
      "          18       0.87      0.90      0.89      1499\n",
      "          19       0.68      0.65      0.66      1499\n",
      "          20       0.99      0.97      0.98      1499\n",
      "          21       0.78      0.78      0.78      1499\n",
      "          22       0.86      0.88      0.87      1499\n",
      "          23       0.96      0.97      0.97      1499\n",
      "          24       0.99      0.57      0.72      1499\n",
      "\n",
      "    accuracy                           0.82     37475\n",
      "   macro avg       0.85      0.82      0.82     37475\n",
      "weighted avg       0.85      0.82      0.82     37475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model3.predict(xt)).numpy(),axis=1)\n",
    "print(classification_report(yt,y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
