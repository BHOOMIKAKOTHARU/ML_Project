{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77ce0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d4276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_patients=109"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9085fdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/aditya/Research_Intership/eeg_files/files/S001\\\\S001R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S002\\\\S002R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S003\\\\S003R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S004\\\\S004R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S005\\\\S005R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S006\\\\S006R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S007\\\\S007R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S008\\\\S008R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S009\\\\S009R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S010\\\\S010R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S011\\\\S011R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S012\\\\S012R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S013\\\\S013R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S014\\\\S014R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S015\\\\S015R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S016\\\\S016R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S017\\\\S017R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S018\\\\S018R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S019\\\\S019R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S020\\\\S020R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S021\\\\S021R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S022\\\\S022R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S023\\\\S023R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S024\\\\S024R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S025\\\\S025R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S026\\\\S026R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S027\\\\S027R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S028\\\\S028R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S029\\\\S029R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S030\\\\S030R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S031\\\\S031R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S032\\\\S032R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S033\\\\S033R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S034\\\\S034R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S035\\\\S035R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S036\\\\S036R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S037\\\\S037R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S038\\\\S038R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S039\\\\S039R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S040\\\\S040R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S041\\\\S041R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S042\\\\S042R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S043\\\\S043R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S044\\\\S044R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S045\\\\S045R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S046\\\\S046R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S047\\\\S047R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S048\\\\S048R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S049\\\\S049R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S050\\\\S050R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S051\\\\S051R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S052\\\\S052R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S053\\\\S053R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S054\\\\S054R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S055\\\\S055R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S056\\\\S056R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S057\\\\S057R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S058\\\\S058R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S059\\\\S059R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S060\\\\S060R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S061\\\\S061R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S062\\\\S062R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S063\\\\S063R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S064\\\\S064R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S065\\\\S065R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S066\\\\S066R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S067\\\\S067R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S068\\\\S068R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S069\\\\S069R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S070\\\\S070R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S071\\\\S071R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S072\\\\S072R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S073\\\\S073R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S074\\\\S074R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S075\\\\S075R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S076\\\\S076R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S077\\\\S077R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S078\\\\S078R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S079\\\\S079R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S080\\\\S080R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S081\\\\S081R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S082\\\\S082R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S083\\\\S083R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S084\\\\S084R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S085\\\\S085R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S086\\\\S086R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S087\\\\S087R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S088\\\\S088R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S089\\\\S089R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S090\\\\S090R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S091\\\\S091R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S092\\\\S092R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S093\\\\S093R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S094\\\\S094R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S095\\\\S095R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S096\\\\S096R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S097\\\\S097R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S098\\\\S098R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S099\\\\S099R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S100\\\\S100R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S101\\\\S101R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S102\\\\S102R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S103\\\\S103R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S104\\\\S104R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S105\\\\S105R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S106\\\\S106R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S107\\\\S107R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S108\\\\S108R03.edf',\n",
       " 'C:/aditya/Research_Intership/eeg_files/files/S109\\\\S109R03.edf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=[]\n",
    "test=[]\n",
    "for i in range(1,no_of_patients+1):\n",
    "    files=glob('C:/aditya/Research_Intership/eeg_files/files/S'+str(str(i).zfill(3))+'/*.edf')\n",
    "    files=files[2:3]\n",
    "    train+=files\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddb63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(i,train_split):\n",
    "    raw = mne.io.read_raw_edf(i, preload=True)\n",
    "    eeg_data = raw.get_data()\n",
    "    eeg_channels = [f'Channel_{i}' for i in range(eeg_data.shape[0])]\n",
    "    eeg_df = pd.DataFrame(data=eeg_data.T, columns=eeg_channels)\n",
    "#     display(eeg_df)\n",
    "    eeg_df = eeg_df.iloc[:15000]\n",
    "    eeg_df.sample()\n",
    "    \n",
    "    idx1= int(train_split*(len(eeg_df)))\n",
    "    idx2= int(train_split*(len(eeg_df)))+1\n",
    "        \n",
    "    eeg_df1=eeg_df.iloc[:idx1]\n",
    "    eeg_df2=eeg_df.iloc[idx2:]\n",
    "    \n",
    "    return eeg_df1,eeg_df2, len(eeg_df1),len(eeg_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459d7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(dataframe):\n",
    "    x=dataframe[dataframe.columns[:-1]].values\n",
    "    y=dataframe[dataframe.columns[-1]].values\n",
    "    scaler =StandardScaler()\n",
    "    x=scaler.fit_transform(x)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c746b37e",
   "metadata": {},
   "source": [
    "## 80-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43017064",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "xtemp1=[]\n",
    "xtemp2=[]\n",
    "ytemp1=[]\n",
    "ytemp2=[]\n",
    "for i in range(no_of_patients):\n",
    "    xtr,xte,ytr,yte=read_data(train[i],0.8) # xtr=xtrain, xte=xtest, ytr=ytrain, yte=ytest.\n",
    "    xtemp1.append(xtr)\n",
    "    xtemp2.append(xte)\n",
    "    ytemp1.append(ytr)\n",
    "    ytemp2.append(yte)\n",
    "\n",
    "xtrain = pd.concat([xtemp1[i] for i in range(0, len(xtemp1))], ignore_index=True)\n",
    "xtest = pd.concat([xtemp2[i] for i in range(0, len(xtemp2))], ignore_index=True)\n",
    "\n",
    "ytrain=[]\n",
    "for i in range(len(ytemp1)):\n",
    "    for j in range(ytemp1[i-1]):\n",
    "        ytrain.append(i)\n",
    "ytest=[]\n",
    "for i in range(len(ytemp2)):\n",
    "    for j in range(ytemp2[i-1]):\n",
    "        ytest.append(i)        \n",
    "\n",
    "xtrain['id']=ytrain\n",
    "xtest['id']=ytest\n",
    "display(xtrain)\n",
    "x,y=scale_dataset(xtrain)\n",
    "xt,yt=scale_dataset(xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba317622",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(64, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(109, activation = 'softmax', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e6a4e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0 ... 108 108 108]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "becf4160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "40875/40875 [==============================] - 120s 3ms/step - loss: 1.9698\n",
      "Epoch 2/10\n",
      "40875/40875 [==============================] - 117s 3ms/step - loss: 1.4222\n",
      "Epoch 3/10\n",
      "40875/40875 [==============================] - 118s 3ms/step - loss: 1.2595\n",
      "Epoch 4/10\n",
      "40875/40875 [==============================] - 119s 3ms/step - loss: 1.1687\n",
      "Epoch 5/10\n",
      "40875/40875 [==============================] - 121s 3ms/step - loss: 1.1057\n",
      "Epoch 6/10\n",
      "40875/40875 [==============================] - 127s 3ms/step - loss: 1.0598\n",
      "Epoch 7/10\n",
      "40875/40875 [==============================] - 126s 3ms/step - loss: 1.0221\n",
      "Epoch 8/10\n",
      "40875/40875 [==============================] - 178s 4ms/step - loss: 0.9902\n",
      "Epoch 9/10\n",
      "40875/40875 [==============================] - 165s 4ms/step - loss: 0.9608\n",
      "Epoch 10/10\n",
      "40875/40875 [==============================] - 157s 4ms/step - loss: 0.9351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b781293988>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x,y,epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ee76d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " L1 (Dense)                  (32, 64)                  4160      \n",
      "                                                                 \n",
      " L2 (Dense)                  (32, 256)                 16640     \n",
      "                                                                 \n",
      " dropout (Dropout)           (32, 256)                 0         \n",
      "                                                                 \n",
      " L3 (Dense)                  (32, 128)                 32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (32, 128)                 0         \n",
      "                                                                 \n",
      " L4 (Dense)                  (32, 64)                  8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (32, 64)                  0         \n",
      "                                                                 \n",
      " L5 (Dense)                  (32, 32)                  2080      \n",
      "                                                                 \n",
      " L6 (Dense)                  (32, 109)                 3597      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67,629\n",
      "Trainable params: 67,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22ae01cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10216/10216 [==============================] - 20s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65      2999\n",
      "           1       0.58      0.80      0.67      2999\n",
      "           2       0.51      0.55      0.53      2999\n",
      "           3       0.96      0.92      0.94      2999\n",
      "           4       0.96      0.98      0.97      2999\n",
      "           5       0.85      0.83      0.84      2999\n",
      "           6       0.95      0.89      0.92      2999\n",
      "           7       0.81      0.78      0.79      2999\n",
      "           8       0.73      0.71      0.72      2999\n",
      "           9       0.47      0.80      0.59      2999\n",
      "          10       0.72      0.80      0.76      2999\n",
      "          11       0.89      0.72      0.79      2999\n",
      "          12       0.65      0.59      0.62      2999\n",
      "          13       0.57      0.60      0.59      2999\n",
      "          14       0.48      0.44      0.46      2999\n",
      "          15       0.90      0.31      0.46      2999\n",
      "          16       0.71      0.67      0.69      2999\n",
      "          17       0.88      0.65      0.75      2999\n",
      "          18       0.68      0.61      0.65      2999\n",
      "          19       0.46      0.56      0.50      2999\n",
      "          20       0.96      0.99      0.98      2999\n",
      "          21       0.62      0.75      0.68      2999\n",
      "          22       0.63      0.63      0.63      2999\n",
      "          23       0.94      0.93      0.94      2999\n",
      "          24       0.93      0.78      0.85      2999\n",
      "          25       0.58      0.24      0.34      2999\n",
      "          26       0.55      0.23      0.32      2999\n",
      "          27       0.78      0.58      0.66      2999\n",
      "          28       0.71      0.72      0.71      2999\n",
      "          29       0.67      0.87      0.76      2999\n",
      "          30       0.78      0.82      0.80      2999\n",
      "          31       0.74      0.79      0.76      2999\n",
      "          32       0.82      0.89      0.85      2999\n",
      "          33       0.62      0.40      0.49      2999\n",
      "          34       0.90      0.98      0.94      2999\n",
      "          35       0.66      0.55      0.60      2999\n",
      "          36       0.44      0.58      0.51      2999\n",
      "          37       0.58      0.44      0.50      2999\n",
      "          38       0.47      0.15      0.22      2999\n",
      "          39       0.39      0.60      0.48      2999\n",
      "          40       0.73      0.80      0.76      2999\n",
      "          41       0.51      0.26      0.34      2999\n",
      "          42       0.38      0.77      0.51      2999\n",
      "          43       0.69      0.54      0.61      2999\n",
      "          44       0.73      0.76      0.74      2999\n",
      "          45       0.68      0.58      0.63      2999\n",
      "          46       0.46      0.40      0.43      2999\n",
      "          47       0.93      0.43      0.59      2999\n",
      "          48       0.50      0.63      0.56      2999\n",
      "          49       0.49      0.73      0.59      2999\n",
      "          50       0.72      0.61      0.66      2999\n",
      "          51       0.53      0.54      0.53      2999\n",
      "          52       0.73      0.71      0.72      2999\n",
      "          53       0.65      0.71      0.68      2999\n",
      "          54       0.69      0.69      0.69      2999\n",
      "          55       0.41      0.46      0.43      2999\n",
      "          56       0.69      0.80      0.74      2999\n",
      "          57       0.74      0.73      0.74      2999\n",
      "          58       0.95      0.56      0.71      2999\n",
      "          59       0.32      0.60      0.42      2999\n",
      "          60       0.70      0.69      0.70      2999\n",
      "          61       0.45      0.16      0.24      2999\n",
      "          62       0.94      0.90      0.92      2999\n",
      "          63       0.52      0.60      0.56      2999\n",
      "          64       0.52      0.74      0.61      2999\n",
      "          65       0.83      0.83      0.83      2999\n",
      "          66       0.92      0.86      0.89      2999\n",
      "          67       0.40      0.29      0.34      2999\n",
      "          68       0.85      0.87      0.86      2999\n",
      "          69       0.34      0.56      0.43      2999\n",
      "          70       0.70      0.49      0.57      2999\n",
      "          71       0.34      0.37      0.35      2999\n",
      "          72       0.81      0.65      0.72      2999\n",
      "          73       0.60      0.44      0.51      2999\n",
      "          74       0.41      0.63      0.50      2999\n",
      "          75       0.75      0.73      0.74      2999\n",
      "          76       0.47      0.66      0.55      2999\n",
      "          77       0.80      0.58      0.68      2999\n",
      "          78       0.55      0.52      0.54      2999\n",
      "          79       0.65      0.81      0.72      2999\n",
      "          80       0.76      0.86      0.81      2999\n",
      "          81       0.76      0.68      0.72      2999\n",
      "          82       0.83      0.76      0.79      2999\n",
      "          83       0.64      0.75      0.69      2999\n",
      "          84       0.72      0.78      0.75      2999\n",
      "          85       0.68      0.65      0.66      2999\n",
      "          86       0.37      0.43      0.40      2999\n",
      "          87       0.44      0.40      0.42      2999\n",
      "          88       0.89      0.96      0.92      2999\n",
      "          89       0.71      0.71      0.71      2999\n",
      "          90       0.84      0.91      0.87      2999\n",
      "          91       0.61      0.75      0.67      2999\n",
      "          92       0.45      0.58      0.51      2999\n",
      "          93       1.00      0.96      0.98      2999\n",
      "          94       0.73      0.73      0.73      2999\n",
      "          95       0.80      0.69      0.74      2999\n",
      "          96       0.72      0.78      0.75      2999\n",
      "          97       0.45      0.69      0.54      2999\n",
      "          98       0.79      0.58      0.67      2999\n",
      "          99       0.61      0.70      0.65      2999\n",
      "         100       0.54      0.68      0.60      2999\n",
      "         101       0.49      0.53      0.51      2999\n",
      "         102       0.59      0.61      0.60      2999\n",
      "         103       0.90      0.37      0.53      2999\n",
      "         104       0.87      0.44      0.59      2999\n",
      "         105       0.63      0.44      0.52      2999\n",
      "         106       0.53      0.55      0.54      2999\n",
      "         107       0.70      0.67      0.68      2999\n",
      "         108       0.90      0.77      0.83      2999\n",
      "\n",
      "    accuracy                           0.65    326891\n",
      "   macro avg       0.67      0.65      0.65    326891\n",
      "weighted avg       0.67      0.65      0.65    326891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(xt)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(yt,y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6925ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model1 = Sequential(\n",
    "    [\n",
    "        Dense(64, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(109, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77e72630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "40875/40875 [==============================] - 119s 3ms/step - loss: 1.1961\n",
      "Epoch 2/20\n",
      "40875/40875 [==============================] - 120s 3ms/step - loss: 0.5216\n",
      "Epoch 3/20\n",
      "40875/40875 [==============================] - 118s 3ms/step - loss: 0.3732\n",
      "Epoch 4/20\n",
      "40875/40875 [==============================] - 118s 3ms/step - loss: 0.2981\n",
      "Epoch 5/20\n",
      "40875/40875 [==============================] - 120s 3ms/step - loss: 0.2544\n",
      "Epoch 6/20\n",
      "40875/40875 [==============================] - 128s 3ms/step - loss: 0.2237\n",
      "Epoch 7/20\n",
      "40875/40875 [==============================] - 124s 3ms/step - loss: 0.2029\n",
      "Epoch 8/20\n",
      "40875/40875 [==============================] - 127s 3ms/step - loss: 0.1862\n",
      "Epoch 9/20\n",
      "40875/40875 [==============================] - 131s 3ms/step - loss: 0.1728\n",
      "Epoch 10/20\n",
      "40875/40875 [==============================] - 137s 3ms/step - loss: 0.1627\n",
      "Epoch 11/20\n",
      "40875/40875 [==============================] - 139s 3ms/step - loss: 0.1538\n",
      "Epoch 12/20\n",
      "40875/40875 [==============================] - 142s 3ms/step - loss: 0.1479\n",
      "Epoch 13/20\n",
      "40875/40875 [==============================] - 142s 3ms/step - loss: 0.1419\n",
      "Epoch 14/20\n",
      "40875/40875 [==============================] - 152s 4ms/step - loss: 0.1382\n",
      "Epoch 15/20\n",
      "40875/40875 [==============================] - 146s 4ms/step - loss: 0.1346\n",
      "Epoch 16/20\n",
      "40875/40875 [==============================] - 157s 4ms/step - loss: 0.1335\n",
      "Epoch 17/20\n",
      "40875/40875 [==============================] - 148s 4ms/step - loss: 0.1308\n",
      "Epoch 18/20\n",
      "40875/40875 [==============================] - 147s 4ms/step - loss: 0.1302\n",
      "Epoch 19/20\n",
      "40875/40875 [==============================] - 151s 4ms/step - loss: 0.1294\n",
      "Epoch 20/20\n",
      "40875/40875 [==============================] - 159s 4ms/step - loss: 0.1292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b7a06a6048>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model1.fit(\n",
    "    x,y,epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1710d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10216/10216 [==============================] - 79s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      2999\n",
      "           1       0.88      0.88      0.88      2999\n",
      "           2       0.75      0.62      0.68      2999\n",
      "           3       0.84      0.97      0.90      2999\n",
      "           4       0.97      0.99      0.98      2999\n",
      "           5       0.99      0.95      0.97      2999\n",
      "           6       0.95      0.95      0.95      2999\n",
      "           7       0.93      0.74      0.82      2999\n",
      "           8       0.41      0.88      0.56      2999\n",
      "           9       0.67      0.81      0.73      2999\n",
      "          10       0.92      0.77      0.84      2999\n",
      "          11       0.91      0.91      0.91      2999\n",
      "          12       0.67      0.92      0.78      2999\n",
      "          13       0.83      0.87      0.85      2999\n",
      "          14       0.70      0.89      0.78      2999\n",
      "          15       0.85      0.63      0.72      2999\n",
      "          16       0.58      0.42      0.48      2999\n",
      "          17       0.88      0.79      0.83      2999\n",
      "          18       0.91      0.85      0.88      2999\n",
      "          19       0.68      0.61      0.64      2999\n",
      "          20       0.99      0.97      0.98      2999\n",
      "          21       0.75      0.90      0.82      2999\n",
      "          22       0.85      0.85      0.85      2999\n",
      "          23       0.95      0.98      0.96      2999\n",
      "          24       0.94      0.89      0.91      2999\n",
      "          25       0.76      0.44      0.56      2999\n",
      "          26       0.65      0.37      0.47      2999\n",
      "          27       0.79      0.49      0.61      2999\n",
      "          28       0.71      0.81      0.76      2999\n",
      "          29       0.88      0.87      0.87      2999\n",
      "          30       0.84      0.93      0.88      2999\n",
      "          31       0.58      0.93      0.71      2999\n",
      "          32       0.90      0.95      0.93      2999\n",
      "          33       0.84      0.55      0.66      2999\n",
      "          34       0.90      0.99      0.94      2999\n",
      "          35       0.91      0.83      0.87      2999\n",
      "          36       0.76      0.65      0.70      2999\n",
      "          37       0.76      0.84      0.80      2999\n",
      "          38       0.32      0.32      0.32      2999\n",
      "          39       0.59      0.69      0.64      2999\n",
      "          40       0.85      0.88      0.86      2999\n",
      "          41       0.84      0.46      0.60      2999\n",
      "          42       0.61      0.80      0.69      2999\n",
      "          43       0.74      0.78      0.76      2999\n",
      "          44       0.89      0.93      0.91      2999\n",
      "          45       0.83      0.59      0.69      2999\n",
      "          46       0.54      0.74      0.62      2999\n",
      "          47       0.94      0.59      0.72      2999\n",
      "          48       0.92      0.88      0.90      2999\n",
      "          49       0.74      0.81      0.77      2999\n",
      "          50       0.81      0.88      0.84      2999\n",
      "          51       0.43      0.72      0.53      2999\n",
      "          52       0.88      0.90      0.89      2999\n",
      "          53       0.79      0.91      0.85      2999\n",
      "          54       0.78      0.86      0.82      2999\n",
      "          55       0.88      0.89      0.89      2999\n",
      "          56       0.68      0.84      0.75      2999\n",
      "          57       0.89      0.95      0.92      2999\n",
      "          58       0.91      0.32      0.47      2999\n",
      "          59       0.39      0.41      0.40      2999\n",
      "          60       0.82      0.81      0.82      2999\n",
      "          61       0.81      0.24      0.37      2999\n",
      "          62       0.96      0.89      0.92      2999\n",
      "          63       0.53      0.82      0.64      2999\n",
      "          64       0.58      0.81      0.68      2999\n",
      "          65       0.85      0.94      0.89      2999\n",
      "          66       0.94      0.94      0.94      2999\n",
      "          67       0.45      0.55      0.49      2999\n",
      "          68       0.87      0.90      0.89      2999\n",
      "          69       0.50      0.79      0.62      2999\n",
      "          70       0.75      0.61      0.67      2999\n",
      "          71       0.53      0.57      0.55      2999\n",
      "          72       0.85      0.76      0.80      2999\n",
      "          73       0.84      0.75      0.79      2999\n",
      "          74       0.40      0.86      0.55      2999\n",
      "          75       0.94      0.78      0.85      2999\n",
      "          76       0.73      0.68      0.70      2999\n",
      "          77       0.90      0.82      0.86      2999\n",
      "          78       0.87      0.48      0.62      2999\n",
      "          79       0.91      0.87      0.89      2999\n",
      "          80       0.74      0.86      0.80      2999\n",
      "          81       0.85      0.65      0.74      2999\n",
      "          82       0.95      0.82      0.88      2999\n",
      "          83       0.62      0.77      0.68      2999\n",
      "          84       0.80      0.95      0.87      2999\n",
      "          85       0.78      0.66      0.72      2999\n",
      "          86       0.81      0.55      0.65      2999\n",
      "          87       0.74      0.62      0.67      2999\n",
      "          88       0.86      0.93      0.90      2999\n",
      "          89       0.86      0.90      0.88      2999\n",
      "          90       0.96      0.95      0.96      2999\n",
      "          91       0.88      0.91      0.90      2999\n",
      "          92       0.75      0.78      0.76      2999\n",
      "          93       1.00      0.97      0.98      2999\n",
      "          94       0.65      0.84      0.74      2999\n",
      "          95       0.84      0.82      0.83      2999\n",
      "          96       0.84      0.91      0.88      2999\n",
      "          97       0.84      0.63      0.72      2999\n",
      "          98       0.88      0.86      0.87      2999\n",
      "          99       0.85      0.80      0.83      2999\n",
      "         100       0.61      0.78      0.68      2999\n",
      "         101       0.66      0.45      0.54      2999\n",
      "         102       0.86      0.68      0.76      2999\n",
      "         103       0.93      0.48      0.63      2999\n",
      "         104       0.94      0.40      0.56      2999\n",
      "         105       0.61      0.56      0.59      2999\n",
      "         106       0.58      0.43      0.50      2999\n",
      "         107       0.82      0.83      0.82      2999\n",
      "         108       0.88      0.82      0.85      2999\n",
      "\n",
      "    accuracy                           0.76    326891\n",
      "   macro avg       0.79      0.76      0.76    326891\n",
      "weighted avg       0.79      0.76      0.76    326891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model1.predict(xt)).numpy(),axis=1)\n",
    "print(classification_report(yt,y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
