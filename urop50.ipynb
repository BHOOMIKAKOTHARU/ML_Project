{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c862b2bf",
   "metadata": {},
   "source": [
    "# 50 persons\n",
    "## electrodes : 8, 16, 32, 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77ce0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42d4276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_patients=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9085fdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['files/S001R03.edf',\n",
       " 'files/S002R03.edf',\n",
       " 'files/S003R03.edf',\n",
       " 'files/S004R03.edf',\n",
       " 'files/S005R03.edf',\n",
       " 'files/S006R03.edf',\n",
       " 'files/S007R03.edf',\n",
       " 'files/S008R03.edf',\n",
       " 'files/S009R03.edf',\n",
       " 'files/S010R03.edf',\n",
       " 'files/S011R03.edf',\n",
       " 'files/S012R03.edf',\n",
       " 'files/S013R03.edf',\n",
       " 'files/S014R03.edf',\n",
       " 'files/S015R03.edf',\n",
       " 'files/S016R03.edf',\n",
       " 'files/S017R03.edf',\n",
       " 'files/S018R03.edf',\n",
       " 'files/S019R03.edf',\n",
       " 'files/S020R03.edf',\n",
       " 'files/S021R03.edf',\n",
       " 'files/S022R03.edf',\n",
       " 'files/S023R03.edf',\n",
       " 'files/S024R03.edf',\n",
       " 'files/S025R03.edf',\n",
       " 'files/S026R03.edf',\n",
       " 'files/S027R03.edf',\n",
       " 'files/S028R03.edf',\n",
       " 'files/S029R03.edf',\n",
       " 'files/S030R03.edf',\n",
       " 'files/S031R03.edf',\n",
       " 'files/S032R03.edf',\n",
       " 'files/S033R03.edf',\n",
       " 'files/S034R03.edf',\n",
       " 'files/S035R03.edf',\n",
       " 'files/S036R03.edf',\n",
       " 'files/S037R03.edf',\n",
       " 'files/S038R03.edf',\n",
       " 'files/S039R03.edf',\n",
       " 'files/S040R03.edf',\n",
       " 'files/S041R03.edf',\n",
       " 'files/S042R03.edf',\n",
       " 'files/S043R03.edf',\n",
       " 'files/S044R03.edf',\n",
       " 'files/S045R03.edf',\n",
       " 'files/S046R03.edf',\n",
       " 'files/S047R03.edf',\n",
       " 'files/S048R03.edf',\n",
       " 'files/S049R03.edf',\n",
       " 'files/S050R03.edf']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=sorted(glob('files/*.edf'))\n",
    "train=train[:no_of_patients]\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddb63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(i,train_split,valid_split):\n",
    "    raw = mne.io.read_raw_edf(i, preload=True)\n",
    "    eeg_data = raw.get_data()\n",
    "    eeg_channels = [f'Channel_{i}' for i in range(eeg_data.shape[0])]\n",
    "    eeg_df = pd.DataFrame(data=eeg_data.T, columns=eeg_channels)\n",
    "    \n",
    "    eeg_df = eeg_df.iloc[:15000]\n",
    "    eeg_df.sample()\n",
    "    \n",
    "    idx1= int(train_split*(len(eeg_df)))\n",
    "    idx2= int(train_split*(len(eeg_df)))+1\n",
    "    eeg_df1=eeg_df.iloc[:idx1]\n",
    "    eeg_df2=eeg_df.iloc[idx2:]\n",
    "    idx3=int(valid_split*(len(eeg_df2)))\n",
    "    idx4=int(valid_split*(len(eeg_df2)))+1\n",
    "    eeg_df3=eeg_df2.iloc[:idx3]\n",
    "    eeg_df4=eeg_df2.iloc[idx4:]\n",
    "    return eeg_df1,eeg_df3,eeg_df4,len(eeg_df1),len(eeg_df3),len(eeg_df4)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65857e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "xtemp1=[]\n",
    "xtemp2=[]\n",
    "xtemp3=[]\n",
    "ytemp1=[]\n",
    "ytemp2=[]\n",
    "ytemp3=[]\n",
    "for i in range(no_of_patients):\n",
    "    xtr,xte,xval,ytr,yte,yval=read_data(train[i],0.8,0.5) # xtr=xtrain, xte=xtest, ytr=ytrain, yte=ytest.\n",
    "    xtemp1.append(xtr)\n",
    "    xtemp2.append(xte)\n",
    "    xtemp3.append(xval)\n",
    "    ytemp1.append(ytr)\n",
    "    ytemp2.append(yte)\n",
    "    ytemp3.append(yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0aeb31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pd.concat([xtemp1[i] for i in range(0, len(xtemp1))], ignore_index=True)\n",
    "xtest = pd.concat([xtemp2[i] for i in range(0, len(xtemp2))], ignore_index=True)\n",
    "xvalid=pd.concat([xtemp3[i] for i in range(0,len(xtemp3))],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a47802ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=[]\n",
    "for i in range(len(ytemp1)):\n",
    "    for j in range(ytemp1[i-1]):\n",
    "        ytrain.append(i)\n",
    "ytest=[]\n",
    "for i in range(len(ytemp2)):\n",
    "    for j in range(ytemp2[i-1]):\n",
    "        ytest.append(i)        \n",
    "yvalid=[]\n",
    "for i in range(len(ytemp3)):\n",
    "    for j in range(ytemp3[i-1]):\n",
    "        yvalid.append(i)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "705fd1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 74950, 600000, 74950)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain),len(xtest),len(ytrain),len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec6d73ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.7e-05 -4.5e-05 -2.9e-05 ...  9.0e-06  4.0e-06  1.6e-05]\n"
     ]
    }
   ],
   "source": [
    "print(xtest.iloc[:,-1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8738bdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_0</th>\n",
       "      <th>Channel_1</th>\n",
       "      <th>Channel_2</th>\n",
       "      <th>Channel_3</th>\n",
       "      <th>Channel_4</th>\n",
       "      <th>Channel_5</th>\n",
       "      <th>Channel_6</th>\n",
       "      <th>Channel_7</th>\n",
       "      <th>Channel_8</th>\n",
       "      <th>Channel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Channel_54</th>\n",
       "      <th>Channel_55</th>\n",
       "      <th>Channel_56</th>\n",
       "      <th>Channel_57</th>\n",
       "      <th>Channel_58</th>\n",
       "      <th>Channel_59</th>\n",
       "      <th>Channel_60</th>\n",
       "      <th>Channel_61</th>\n",
       "      <th>Channel_62</th>\n",
       "      <th>Channel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Channel_0  Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  \\\n",
       "0       -0.000057  -0.000013  -0.000015  -0.000012  -0.000013  -0.000008   \n",
       "1       -0.000049  -0.000011  -0.000010  -0.000012  -0.000019  -0.000024   \n",
       "2       -0.000055  -0.000017  -0.000016  -0.000019  -0.000024  -0.000029   \n",
       "3       -0.000073  -0.000042  -0.000040  -0.000037  -0.000037  -0.000040   \n",
       "4       -0.000087  -0.000053  -0.000052  -0.000051  -0.000045  -0.000043   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "599995   0.000025   0.000034   0.000019   0.000012   0.000017   0.000013   \n",
       "599996   0.000061   0.000068   0.000057   0.000048   0.000050   0.000044   \n",
       "599997   0.000066   0.000065   0.000059   0.000050   0.000051   0.000051   \n",
       "599998   0.000081   0.000087   0.000066   0.000059   0.000069   0.000060   \n",
       "599999   0.000102   0.000097   0.000083   0.000072   0.000071   0.000058   \n",
       "\n",
       "        Channel_6  Channel_7  Channel_8  Channel_9  ...  Channel_54  \\\n",
       "0       -0.000040  -0.000054  -0.000012  -0.000014  ...   -0.000048   \n",
       "1       -0.000058  -0.000051  -0.000019  -0.000023  ...   -0.000055   \n",
       "2       -0.000066  -0.000061  -0.000030  -0.000036  ...   -0.000054   \n",
       "3       -0.000071  -0.000078  -0.000053  -0.000053  ...   -0.000065   \n",
       "4       -0.000071  -0.000087  -0.000065  -0.000064  ...   -0.000075   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "599995   0.000018   0.000029   0.000014   0.000010  ...    0.000020   \n",
       "599996   0.000043   0.000048   0.000049   0.000043  ...    0.000013   \n",
       "599997   0.000054   0.000031   0.000040   0.000035  ...   -0.000002   \n",
       "599998   0.000064   0.000054   0.000043   0.000041  ...    0.000011   \n",
       "599999   0.000047   0.000064   0.000065   0.000058  ...    0.000002   \n",
       "\n",
       "        Channel_55  Channel_56  Channel_57  Channel_58  Channel_59  \\\n",
       "0        -0.000038   -0.000042   -0.000068   -0.000076   -0.000103   \n",
       "1        -0.000055   -0.000063   -0.000082   -0.000087   -0.000099   \n",
       "2        -0.000063   -0.000072   -0.000091   -0.000092   -0.000091   \n",
       "3        -0.000052   -0.000066   -0.000100   -0.000105   -0.000105   \n",
       "4        -0.000082   -0.000090   -0.000117   -0.000119   -0.000118   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "599995    0.000008   -0.000002    0.000019    0.000013    0.000005   \n",
       "599996    0.000010   -0.000007    0.000011    0.000012    0.000003   \n",
       "599997   -0.000025   -0.000032   -0.000006   -0.000002   -0.000013   \n",
       "599998    0.000000   -0.000006    0.000014    0.000014   -0.000003   \n",
       "599999   -0.000004   -0.000011    0.000010   -0.000001   -0.000025   \n",
       "\n",
       "        Channel_60  Channel_61  Channel_62  Channel_63  \n",
       "0        -0.000051   -0.000056   -0.000124   -0.000028  \n",
       "1        -0.000059   -0.000070   -0.000149   -0.000040  \n",
       "2        -0.000067   -0.000077   -0.000153   -0.000037  \n",
       "3        -0.000067   -0.000072   -0.000148   -0.000026  \n",
       "4        -0.000075   -0.000082   -0.000161   -0.000035  \n",
       "...            ...         ...         ...         ...  \n",
       "599995    0.000013    0.000007    0.000006   -0.000060  \n",
       "599996    0.000013    0.000020    0.000016   -0.000027  \n",
       "599997   -0.000019   -0.000010   -0.000002   -0.000059  \n",
       "599998    0.000005    0.000000    0.000005   -0.000064  \n",
       "599999    0.000000   -0.000018   -0.000020   -0.000087  \n",
       "\n",
       "[600000 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "459d7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(dataframe):\n",
    "    x=dataframe.iloc[:,:-1].values\n",
    "    y=dataframe.iloc[:,-1].values\n",
    "    scaler =StandardScaler()\n",
    "    x=scaler.fit_transform(x)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aabeaa2",
   "metadata": {},
   "source": [
    "## 0-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3172e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain8=xtrain.iloc[:,:8]\n",
    "xvalid8=xvalid.iloc[:,:8]\n",
    "xtest8=xtest.iloc[:,:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "904c30f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1204/394288547.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtrain8['id']=ytrain\n",
      "/tmp/ipykernel_1204/394288547.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtest8['id']=ytest\n",
      "/tmp/ipykernel_1204/394288547.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xvalid8['id']=yvalid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_0</th>\n",
       "      <th>Channel_1</th>\n",
       "      <th>Channel_2</th>\n",
       "      <th>Channel_3</th>\n",
       "      <th>Channel_4</th>\n",
       "      <th>Channel_5</th>\n",
       "      <th>Channel_6</th>\n",
       "      <th>Channel_7</th>\n",
       "      <th>Channel_8</th>\n",
       "      <th>Channel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Channel_54</th>\n",
       "      <th>Channel_55</th>\n",
       "      <th>Channel_56</th>\n",
       "      <th>Channel_57</th>\n",
       "      <th>Channel_58</th>\n",
       "      <th>Channel_59</th>\n",
       "      <th>Channel_60</th>\n",
       "      <th>Channel_61</th>\n",
       "      <th>Channel_62</th>\n",
       "      <th>Channel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Channel_0  Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  \\\n",
       "0       -0.000057  -0.000013  -0.000015  -0.000012  -0.000013  -0.000008   \n",
       "1       -0.000049  -0.000011  -0.000010  -0.000012  -0.000019  -0.000024   \n",
       "2       -0.000055  -0.000017  -0.000016  -0.000019  -0.000024  -0.000029   \n",
       "3       -0.000073  -0.000042  -0.000040  -0.000037  -0.000037  -0.000040   \n",
       "4       -0.000087  -0.000053  -0.000052  -0.000051  -0.000045  -0.000043   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "599995   0.000025   0.000034   0.000019   0.000012   0.000017   0.000013   \n",
       "599996   0.000061   0.000068   0.000057   0.000048   0.000050   0.000044   \n",
       "599997   0.000066   0.000065   0.000059   0.000050   0.000051   0.000051   \n",
       "599998   0.000081   0.000087   0.000066   0.000059   0.000069   0.000060   \n",
       "599999   0.000102   0.000097   0.000083   0.000072   0.000071   0.000058   \n",
       "\n",
       "        Channel_6  Channel_7  Channel_8  Channel_9  ...  Channel_54  \\\n",
       "0       -0.000040  -0.000054  -0.000012  -0.000014  ...   -0.000048   \n",
       "1       -0.000058  -0.000051  -0.000019  -0.000023  ...   -0.000055   \n",
       "2       -0.000066  -0.000061  -0.000030  -0.000036  ...   -0.000054   \n",
       "3       -0.000071  -0.000078  -0.000053  -0.000053  ...   -0.000065   \n",
       "4       -0.000071  -0.000087  -0.000065  -0.000064  ...   -0.000075   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "599995   0.000018   0.000029   0.000014   0.000010  ...    0.000020   \n",
       "599996   0.000043   0.000048   0.000049   0.000043  ...    0.000013   \n",
       "599997   0.000054   0.000031   0.000040   0.000035  ...   -0.000002   \n",
       "599998   0.000064   0.000054   0.000043   0.000041  ...    0.000011   \n",
       "599999   0.000047   0.000064   0.000065   0.000058  ...    0.000002   \n",
       "\n",
       "        Channel_55  Channel_56  Channel_57  Channel_58  Channel_59  \\\n",
       "0        -0.000038   -0.000042   -0.000068   -0.000076   -0.000103   \n",
       "1        -0.000055   -0.000063   -0.000082   -0.000087   -0.000099   \n",
       "2        -0.000063   -0.000072   -0.000091   -0.000092   -0.000091   \n",
       "3        -0.000052   -0.000066   -0.000100   -0.000105   -0.000105   \n",
       "4        -0.000082   -0.000090   -0.000117   -0.000119   -0.000118   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "599995    0.000008   -0.000002    0.000019    0.000013    0.000005   \n",
       "599996    0.000010   -0.000007    0.000011    0.000012    0.000003   \n",
       "599997   -0.000025   -0.000032   -0.000006   -0.000002   -0.000013   \n",
       "599998    0.000000   -0.000006    0.000014    0.000014   -0.000003   \n",
       "599999   -0.000004   -0.000011    0.000010   -0.000001   -0.000025   \n",
       "\n",
       "        Channel_60  Channel_61  Channel_62  Channel_63  \n",
       "0        -0.000051   -0.000056   -0.000124   -0.000028  \n",
       "1        -0.000059   -0.000070   -0.000149   -0.000040  \n",
       "2        -0.000067   -0.000077   -0.000153   -0.000037  \n",
       "3        -0.000067   -0.000072   -0.000148   -0.000026  \n",
       "4        -0.000075   -0.000082   -0.000161   -0.000035  \n",
       "...            ...         ...         ...         ...  \n",
       "599995    0.000013    0.000007    0.000006   -0.000060  \n",
       "599996    0.000013    0.000020    0.000016   -0.000027  \n",
       "599997   -0.000019   -0.000010   -0.000002   -0.000059  \n",
       "599998    0.000005    0.000000    0.000005   -0.000064  \n",
       "599999    0.000000   -0.000018   -0.000020   -0.000087  \n",
       "\n",
       "[600000 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain8['id']=ytrain\n",
    "xtest8['id']=ytest\n",
    "xvalid8['id']=yvalid\n",
    "display(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b732f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x8,y8=scale_dataset(xtrain8)\n",
    "xt8,yt8=scale_dataset(xtest8)\n",
    "xv8,yv8=scale_dataset(xvalid8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b271d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(64, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(109, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0aee87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18750/18750 [==============================] - 23s 1ms/step - loss: 2.0915 - val_loss: 2.2535\n",
      "Epoch 2/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.6643 - val_loss: 2.2405\n",
      "Epoch 3/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.5790 - val_loss: 2.2791\n",
      "Epoch 4/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.5303 - val_loss: 2.3559\n",
      "Epoch 5/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.4971 - val_loss: 2.3528\n",
      "Epoch 6/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.4728 - val_loss: 2.3463\n",
      "Epoch 7/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.4543 - val_loss: 2.3879\n",
      "Epoch 8/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.4373 - val_loss: 2.4360\n",
      "Epoch 9/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.4258 - val_loss: 2.4888\n",
      "Epoch 10/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.4144 - val_loss: 2.3934\n",
      "Epoch 11/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.4048 - val_loss: 2.4870\n",
      "Epoch 12/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.3957 - val_loss: 2.5009\n",
      "Epoch 13/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.3890 - val_loss: 2.4747\n",
      "Epoch 14/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.3815 - val_loss: 2.4718\n",
      "Epoch 15/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.3757 - val_loss: 2.5700\n",
      "Epoch 16/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.3710 - val_loss: 2.5312\n",
      "Epoch 17/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.3657 - val_loss: 2.5928\n",
      "Epoch 18/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.3611 - val_loss: 2.5398\n",
      "Epoch 19/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.3569 - val_loss: 2.5749\n",
      "Epoch 20/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 1.3523 - val_loss: 2.5504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f58c96d85b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x8,y8,epochs=20,validation_data=(xv8,yv8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "badca670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 211/2343 [=>............................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2343/2343 [==============================] - 2s 707us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.08      0.11      1499\n",
      "           1       0.22      0.14      0.17      1499\n",
      "           2       0.25      0.45      0.32      1499\n",
      "           3       0.54      0.49      0.51      1499\n",
      "           4       0.70      0.65      0.68      1499\n",
      "           5       0.43      0.52      0.47      1499\n",
      "           6       0.45      0.62      0.52      1499\n",
      "           7       0.64      0.39      0.49      1499\n",
      "           8       0.52      0.60      0.55      1499\n",
      "           9       0.53      0.32      0.40      1499\n",
      "          10       0.27      0.28      0.28      1499\n",
      "          11       0.25      0.21      0.23      1499\n",
      "          12       0.27      0.27      0.27      1499\n",
      "          13       0.18      0.23      0.20      1499\n",
      "          14       0.17      0.23      0.20      1499\n",
      "          15       0.49      0.35      0.41      1499\n",
      "          16       0.15      0.09      0.11      1499\n",
      "          17       0.54      0.59      0.56      1499\n",
      "          18       0.18      0.16      0.17      1499\n",
      "          19       0.19      0.25      0.22      1499\n",
      "          20       0.59      0.77      0.66      1499\n",
      "          21       0.48      0.52      0.50      1499\n",
      "          22       0.22      0.09      0.12      1499\n",
      "          23       0.50      0.50      0.50      1499\n",
      "          24       0.57      0.62      0.60      1499\n",
      "          25       0.37      0.31      0.34      1499\n",
      "          26       0.65      0.53      0.58      1499\n",
      "          27       0.22      0.13      0.16      1499\n",
      "          28       0.29      0.13      0.18      1499\n",
      "          29       0.59      0.43      0.50      1499\n",
      "          30       0.25      0.34      0.29      1499\n",
      "          31       0.22      0.28      0.25      1499\n",
      "          32       0.22      0.20      0.21      1499\n",
      "          33       0.10      0.06      0.07      1499\n",
      "          34       0.80      0.69      0.74      1499\n",
      "          35       0.46      0.68      0.55      1499\n",
      "          36       0.37      0.29      0.32      1499\n",
      "          37       0.18      0.26      0.22      1499\n",
      "          38       0.15      0.19      0.17      1499\n",
      "          39       0.43      0.55      0.48      1499\n",
      "          40       0.30      0.22      0.25      1499\n",
      "          41       0.55      0.70      0.62      1499\n",
      "          42       0.24      0.35      0.28      1499\n",
      "          43       0.31      0.57      0.40      1499\n",
      "          44       0.57      0.70      0.63      1499\n",
      "          45       0.05      0.02      0.02      1499\n",
      "          46       0.41      0.57      0.48      1499\n",
      "          47       0.33      0.25      0.28      1499\n",
      "          48       0.54      0.66      0.59      1499\n",
      "          49       0.26      0.16      0.20      1499\n",
      "\n",
      "    accuracy                           0.37     74950\n",
      "   macro avg       0.37      0.37      0.36     74950\n",
      "weighted avg       0.37      0.37      0.36     74950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model.predict(xt8)).numpy(),axis=1)\n",
    "print(classification_report(yt8,y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d7d010",
   "metadata": {},
   "source": [
    "## 0-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "268bff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain16=xtrain.iloc[:,:16]\n",
    "xtest16=xtest.iloc[:,:16]\n",
    "xvalid16=xvalid.iloc[:,:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "000e1a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1204/4039718790.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtrain16['id']=ytrain\n",
      "/tmp/ipykernel_1204/4039718790.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtest16['id']=ytest\n",
      "/tmp/ipykernel_1204/4039718790.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xvalid16['id']=yvalid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel_0</th>\n",
       "      <th>Channel_1</th>\n",
       "      <th>Channel_2</th>\n",
       "      <th>Channel_3</th>\n",
       "      <th>Channel_4</th>\n",
       "      <th>Channel_5</th>\n",
       "      <th>Channel_6</th>\n",
       "      <th>Channel_7</th>\n",
       "      <th>Channel_8</th>\n",
       "      <th>Channel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Channel_54</th>\n",
       "      <th>Channel_55</th>\n",
       "      <th>Channel_56</th>\n",
       "      <th>Channel_57</th>\n",
       "      <th>Channel_58</th>\n",
       "      <th>Channel_59</th>\n",
       "      <th>Channel_60</th>\n",
       "      <th>Channel_61</th>\n",
       "      <th>Channel_62</th>\n",
       "      <th>Channel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000049</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000149</td>\n",
       "      <td>-0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000118</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599995</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599996</th>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599997</th>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599998</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599999</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600000 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Channel_0  Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  \\\n",
       "0       -0.000057  -0.000013  -0.000015  -0.000012  -0.000013  -0.000008   \n",
       "1       -0.000049  -0.000011  -0.000010  -0.000012  -0.000019  -0.000024   \n",
       "2       -0.000055  -0.000017  -0.000016  -0.000019  -0.000024  -0.000029   \n",
       "3       -0.000073  -0.000042  -0.000040  -0.000037  -0.000037  -0.000040   \n",
       "4       -0.000087  -0.000053  -0.000052  -0.000051  -0.000045  -0.000043   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "599995   0.000025   0.000034   0.000019   0.000012   0.000017   0.000013   \n",
       "599996   0.000061   0.000068   0.000057   0.000048   0.000050   0.000044   \n",
       "599997   0.000066   0.000065   0.000059   0.000050   0.000051   0.000051   \n",
       "599998   0.000081   0.000087   0.000066   0.000059   0.000069   0.000060   \n",
       "599999   0.000102   0.000097   0.000083   0.000072   0.000071   0.000058   \n",
       "\n",
       "        Channel_6  Channel_7  Channel_8  Channel_9  ...  Channel_54  \\\n",
       "0       -0.000040  -0.000054  -0.000012  -0.000014  ...   -0.000048   \n",
       "1       -0.000058  -0.000051  -0.000019  -0.000023  ...   -0.000055   \n",
       "2       -0.000066  -0.000061  -0.000030  -0.000036  ...   -0.000054   \n",
       "3       -0.000071  -0.000078  -0.000053  -0.000053  ...   -0.000065   \n",
       "4       -0.000071  -0.000087  -0.000065  -0.000064  ...   -0.000075   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "599995   0.000018   0.000029   0.000014   0.000010  ...    0.000020   \n",
       "599996   0.000043   0.000048   0.000049   0.000043  ...    0.000013   \n",
       "599997   0.000054   0.000031   0.000040   0.000035  ...   -0.000002   \n",
       "599998   0.000064   0.000054   0.000043   0.000041  ...    0.000011   \n",
       "599999   0.000047   0.000064   0.000065   0.000058  ...    0.000002   \n",
       "\n",
       "        Channel_55  Channel_56  Channel_57  Channel_58  Channel_59  \\\n",
       "0        -0.000038   -0.000042   -0.000068   -0.000076   -0.000103   \n",
       "1        -0.000055   -0.000063   -0.000082   -0.000087   -0.000099   \n",
       "2        -0.000063   -0.000072   -0.000091   -0.000092   -0.000091   \n",
       "3        -0.000052   -0.000066   -0.000100   -0.000105   -0.000105   \n",
       "4        -0.000082   -0.000090   -0.000117   -0.000119   -0.000118   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "599995    0.000008   -0.000002    0.000019    0.000013    0.000005   \n",
       "599996    0.000010   -0.000007    0.000011    0.000012    0.000003   \n",
       "599997   -0.000025   -0.000032   -0.000006   -0.000002   -0.000013   \n",
       "599998    0.000000   -0.000006    0.000014    0.000014   -0.000003   \n",
       "599999   -0.000004   -0.000011    0.000010   -0.000001   -0.000025   \n",
       "\n",
       "        Channel_60  Channel_61  Channel_62  Channel_63  \n",
       "0        -0.000051   -0.000056   -0.000124   -0.000028  \n",
       "1        -0.000059   -0.000070   -0.000149   -0.000040  \n",
       "2        -0.000067   -0.000077   -0.000153   -0.000037  \n",
       "3        -0.000067   -0.000072   -0.000148   -0.000026  \n",
       "4        -0.000075   -0.000082   -0.000161   -0.000035  \n",
       "...            ...         ...         ...         ...  \n",
       "599995    0.000013    0.000007    0.000006   -0.000060  \n",
       "599996    0.000013    0.000020    0.000016   -0.000027  \n",
       "599997   -0.000019   -0.000010   -0.000002   -0.000059  \n",
       "599998    0.000005    0.000000    0.000005   -0.000064  \n",
       "599999    0.000000   -0.000018   -0.000020   -0.000087  \n",
       "\n",
       "[600000 rows x 64 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtrain16['id']=ytrain\n",
    "xtest16['id']=ytest\n",
    "xvalid16['id']=yvalid\n",
    "display(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03b98fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x16,y16=scale_dataset(xtrain16)\n",
    "xt16,yt16=scale_dataset(xtest16)\n",
    "xv16,yv16=scale_dataset(xvalid16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7844baeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model1 = Sequential(\n",
    "    [\n",
    "        Dense(64, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(109, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7980b449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18750/18750 [==============================] - 26s 1ms/step - loss: 1.4957 - val_loss: 1.9843\n",
      "Epoch 2/20\n",
      "18750/18750 [==============================] - 24s 1ms/step - loss: 0.8323 - val_loss: 1.9573\n",
      "Epoch 3/20\n",
      "18750/18750 [==============================] - 25s 1ms/step - loss: 0.7108 - val_loss: 2.1479\n",
      "Epoch 4/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.6497 - val_loss: 2.1520\n",
      "Epoch 5/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.6083 - val_loss: 2.1886\n",
      "Epoch 6/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.5785 - val_loss: 2.1889\n",
      "Epoch 7/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.5564 - val_loss: 2.3994\n",
      "Epoch 8/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.5390 - val_loss: 2.4482\n",
      "Epoch 9/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.5242 - val_loss: 2.3509\n",
      "Epoch 10/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.5144 - val_loss: 2.5626\n",
      "Epoch 11/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.5032 - val_loss: 2.5385\n",
      "Epoch 12/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.4936 - val_loss: 2.3923\n",
      "Epoch 13/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.4871 - val_loss: 2.4060\n",
      "Epoch 14/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.4785 - val_loss: 2.4914\n",
      "Epoch 15/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.4733 - val_loss: 2.4066\n",
      "Epoch 16/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.4669 - val_loss: 2.6761\n",
      "Epoch 17/20\n",
      "18750/18750 [==============================] - 22s 1ms/step - loss: 0.4626 - val_loss: 2.7214\n",
      "Epoch 18/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.4563 - val_loss: 2.5038\n",
      "Epoch 19/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.4532 - val_loss: 2.5966\n",
      "Epoch 20/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.4480 - val_loss: 2.7101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f58f31772b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model1.fit(\n",
    "    x16,y16,epochs=20,validation_data=(xv16,yv16)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d07cf8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 362/2343 [===>..........................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2343/2343 [==============================] - 2s 701us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.40      0.44      1499\n",
      "           1       0.43      0.35      0.39      1499\n",
      "           2       0.28      0.43      0.34      1499\n",
      "           3       0.51      0.47      0.49      1499\n",
      "           4       0.90      0.83      0.86      1499\n",
      "           5       0.65      0.52      0.58      1499\n",
      "           6       0.72      0.84      0.78      1499\n",
      "           7       0.90      0.52      0.66      1499\n",
      "           8       0.45      0.80      0.57      1499\n",
      "           9       0.63      0.67      0.65      1499\n",
      "          10       0.40      0.23      0.30      1499\n",
      "          11       0.61      0.46      0.52      1499\n",
      "          12       0.41      0.62      0.50      1499\n",
      "          13       0.27      0.42      0.33      1499\n",
      "          14       0.26      0.43      0.32      1499\n",
      "          15       0.57      0.10      0.18      1499\n",
      "          16       0.31      0.17      0.22      1499\n",
      "          17       0.71      0.67      0.69      1499\n",
      "          18       0.38      0.58      0.46      1499\n",
      "          19       0.33      0.31      0.32      1499\n",
      "          20       0.92      0.79      0.85      1499\n",
      "          21       0.53      0.51      0.52      1499\n",
      "          22       0.41      0.27      0.33      1499\n",
      "          23       0.69      0.80      0.74      1499\n",
      "          24       0.71      0.51      0.60      1499\n",
      "          25       0.49      0.05      0.10      1499\n",
      "          26       0.66      0.55      0.60      1499\n",
      "          27       0.38      0.49      0.43      1499\n",
      "          28       0.55      0.33      0.41      1499\n",
      "          29       0.79      0.61      0.69      1499\n",
      "          30       0.51      0.53      0.52      1499\n",
      "          31       0.29      0.55      0.38      1499\n",
      "          32       0.37      0.53      0.43      1499\n",
      "          33       0.42      0.15      0.22      1499\n",
      "          34       0.90      0.79      0.84      1499\n",
      "          35       0.67      0.75      0.71      1499\n",
      "          36       0.54      0.35      0.43      1499\n",
      "          37       0.34      0.57      0.42      1499\n",
      "          38       0.44      0.17      0.25      1499\n",
      "          39       0.54      0.76      0.63      1499\n",
      "          40       0.54      0.32      0.40      1499\n",
      "          41       0.76      0.80      0.78      1499\n",
      "          42       0.40      0.64      0.49      1499\n",
      "          43       0.32      0.58      0.41      1499\n",
      "          44       0.75      0.83      0.78      1499\n",
      "          45       0.44      0.25      0.32      1499\n",
      "          46       0.55      0.78      0.65      1499\n",
      "          47       0.58      0.33      0.42      1499\n",
      "          48       0.70      0.64      0.67      1499\n",
      "          49       0.34      0.35      0.35      1499\n",
      "\n",
      "    accuracy                           0.51     74950\n",
      "   macro avg       0.53      0.51      0.50     74950\n",
      "weighted avg       0.53      0.51      0.50     74950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model1.predict(xt16)).numpy(),axis=1)\n",
    "print(classification_report(yt16,y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e57e7",
   "metadata": {},
   "source": [
    "## 0-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a408e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain32=xtrain.iloc[:,:32]\n",
    "xtest32=xtest.iloc[:,:32]\n",
    "xvalid32=xvalid.iloc[:,:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "26f15468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1204/1675347936.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtrain32['id']=ytrain\n",
      "/tmp/ipykernel_1204/1675347936.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xtest32['id']=ytest\n",
      "/tmp/ipykernel_1204/1675347936.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xvalid32['id']=yvalid\n"
     ]
    }
   ],
   "source": [
    "xtrain32['id']=ytrain\n",
    "xtest32['id']=ytest\n",
    "xvalid32['id']=yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ddddf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x32,y32=scale_dataset(xtrain32)\n",
    "xt32,yt32=scale_dataset(xtest32)\n",
    "xv32,yv32=scale_dataset(xvalid32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8f654ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model2 = Sequential(\n",
    "    [\n",
    "        Dense(64, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(109, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "300aa492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18750/18750 [==============================] - 23s 1ms/step - loss: 1.0213 - val_loss: 1.6089\n",
      "Epoch 2/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.3814 - val_loss: 1.5283\n",
      "Epoch 3/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.2710 - val_loss: 1.5620\n",
      "Epoch 4/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.2236 - val_loss: 1.4365\n",
      "Epoch 5/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1937 - val_loss: 1.4429\n",
      "Epoch 6/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1738 - val_loss: 1.5108\n",
      "Epoch 7/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1593 - val_loss: 1.5520\n",
      "Epoch 8/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1472 - val_loss: 1.4733\n",
      "Epoch 9/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1385 - val_loss: 1.6842\n",
      "Epoch 10/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1310 - val_loss: 1.6170\n",
      "Epoch 11/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1248 - val_loss: 1.5233\n",
      "Epoch 12/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1188 - val_loss: 1.4761\n",
      "Epoch 13/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1152 - val_loss: 1.4695\n",
      "Epoch 14/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1106 - val_loss: 1.5845\n",
      "Epoch 15/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1080 - val_loss: 1.6987\n",
      "Epoch 16/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1044 - val_loss: 1.6714\n",
      "Epoch 17/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1024 - val_loss: 1.3952\n",
      "Epoch 18/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0996 - val_loss: 1.7183\n",
      "Epoch 19/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0981 - val_loss: 1.9696\n",
      "Epoch 20/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0948 - val_loss: 1.6924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f585f31ece0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model2.fit(\n",
    "    x32,y32,epochs=20,validation_data=(xv32,yv32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eedffd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 591/2343 [======>.......................] - ETA: 1s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2343/2343 [==============================] - 2s 688us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      1499\n",
      "           1       0.74      0.80      0.77      1499\n",
      "           2       0.70      0.74      0.72      1499\n",
      "           3       0.66      0.52      0.58      1499\n",
      "           4       0.90      0.96      0.93      1499\n",
      "           5       0.91      0.96      0.94      1499\n",
      "           6       0.94      0.96      0.95      1499\n",
      "           7       0.96      0.77      0.86      1499\n",
      "           8       0.43      0.85      0.57      1499\n",
      "           9       0.81      0.84      0.82      1499\n",
      "          10       0.91      0.90      0.90      1499\n",
      "          11       0.96      0.97      0.97      1499\n",
      "          12       0.78      0.83      0.80      1499\n",
      "          13       0.67      0.90      0.77      1499\n",
      "          14       0.60      0.82      0.69      1499\n",
      "          15       0.85      0.19      0.31      1499\n",
      "          16       0.54      0.45      0.49      1499\n",
      "          17       0.83      0.91      0.87      1499\n",
      "          18       0.73      0.77      0.75      1499\n",
      "          19       0.53      0.43      0.48      1499\n",
      "          20       0.99      0.99      0.99      1499\n",
      "          21       0.78      0.82      0.80      1499\n",
      "          22       0.83      0.78      0.80      1499\n",
      "          23       0.95      0.97      0.96      1499\n",
      "          24       0.81      0.91      0.86      1499\n",
      "          25       0.38      0.26      0.31      1499\n",
      "          26       0.68      0.71      0.69      1499\n",
      "          27       0.70      0.63      0.66      1499\n",
      "          28       0.89      0.42      0.58      1499\n",
      "          29       0.83      0.93      0.88      1499\n",
      "          30       0.93      0.86      0.90      1499\n",
      "          31       0.68      0.85      0.75      1499\n",
      "          32       0.71      0.92      0.80      1499\n",
      "          33       0.86      0.33      0.48      1499\n",
      "          34       0.89      0.99      0.93      1499\n",
      "          35       0.90      0.89      0.89      1499\n",
      "          36       0.84      0.64      0.73      1499\n",
      "          37       0.60      0.85      0.70      1499\n",
      "          38       0.57      0.39      0.46      1499\n",
      "          39       0.74      0.78      0.76      1499\n",
      "          40       0.71      0.57      0.63      1499\n",
      "          41       0.85      0.61      0.71      1499\n",
      "          42       0.69      0.61      0.65      1499\n",
      "          43       0.67      0.85      0.74      1499\n",
      "          44       0.89      0.96      0.92      1499\n",
      "          45       0.81      0.61      0.70      1499\n",
      "          46       0.58      0.80      0.67      1499\n",
      "          47       0.87      0.68      0.76      1499\n",
      "          48       0.84      0.95      0.89      1499\n",
      "          49       0.67      0.77      0.71      1499\n",
      "\n",
      "    accuracy                           0.76     74950\n",
      "   macro avg       0.77      0.76      0.75     74950\n",
      "weighted avg       0.77      0.76      0.75     74950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model2.predict(xt32)).numpy(),axis=1)\n",
    "print(classification_report(yt32,y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead93bfd",
   "metadata": {},
   "source": [
    "## 0-64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "85c5c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain['id']=ytrain\n",
    "xtest['id']=ytest\n",
    "xvalid['id']=yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "21e76096",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=scale_dataset(xtrain)\n",
    "xt,yt=scale_dataset(xtest)\n",
    "xv,yv=scale_dataset(xvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1dad4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
    "model3 = Sequential(\n",
    "    [\n",
    "        Dense(64, activation = 'relu',   name = \"L1\"),\n",
    "        Dense(256, activation = 'relu', name = \"L2\"),\n",
    "        Dense(128, activation = 'relu', name = \"L3\"),\n",
    "        Dense(64, activation = 'relu',   name = \"L4\"),\n",
    "        Dense(32, activation = 'relu', name = \"L5\"),\n",
    "        Dense(109, activation = 'linear', name = \"L6\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3361defb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18750/18750 [==============================] - 24s 1ms/step - loss: 0.7995 - val_loss: 1.6315\n",
      "Epoch 2/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.2948 - val_loss: 1.6663\n",
      "Epoch 3/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.2131 - val_loss: 1.8182\n",
      "Epoch 4/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1737 - val_loss: 1.6373\n",
      "Epoch 5/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1490 - val_loss: 1.6532\n",
      "Epoch 6/20\n",
      "18750/18750 [==============================] - 24s 1ms/step - loss: 0.1307 - val_loss: 1.8135\n",
      "Epoch 7/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1169 - val_loss: 1.7905\n",
      "Epoch 8/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.1073 - val_loss: 1.8474\n",
      "Epoch 9/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0990 - val_loss: 1.7226\n",
      "Epoch 10/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0924 - val_loss: 1.7388\n",
      "Epoch 11/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0862 - val_loss: 1.6175\n",
      "Epoch 12/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0823 - val_loss: 1.6261\n",
      "Epoch 13/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0771 - val_loss: 1.6953\n",
      "Epoch 14/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0742 - val_loss: 1.7713\n",
      "Epoch 15/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0711 - val_loss: 1.6442\n",
      "Epoch 16/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0691 - val_loss: 1.6285\n",
      "Epoch 17/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0656 - val_loss: 1.9280\n",
      "Epoch 18/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0655 - val_loss: 1.6661\n",
      "Epoch 19/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0625 - val_loss: 1.5128\n",
      "Epoch 20/20\n",
      "18750/18750 [==============================] - 23s 1ms/step - loss: 0.0619 - val_loss: 1.6422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f58509526e0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model3.fit(\n",
    "    x,y,epochs=20,validation_data=(xv,yv)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43017064",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2343/2343 [==============================] - 2s 701us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85      1499\n",
      "           1       0.91      0.89      0.90      1499\n",
      "           2       0.73      0.73      0.73      1499\n",
      "           3       0.92      0.94      0.93      1499\n",
      "           4       0.93      0.99      0.96      1499\n",
      "           5       0.96      0.97      0.96      1499\n",
      "           6       0.94      0.99      0.96      1499\n",
      "           7       0.97      0.85      0.90      1499\n",
      "           8       0.53      0.87      0.66      1499\n",
      "           9       0.71      0.87      0.78      1499\n",
      "          10       0.90      0.83      0.86      1499\n",
      "          11       0.98      0.90      0.94      1499\n",
      "          12       0.61      0.92      0.74      1499\n",
      "          13       0.74      0.92      0.82      1499\n",
      "          14       0.67      0.87      0.76      1499\n",
      "          15       0.89      0.63      0.74      1499\n",
      "          16       0.57      0.46      0.51      1499\n",
      "          17       0.93      0.86      0.89      1499\n",
      "          18       0.95      0.68      0.79      1499\n",
      "          19       0.86      0.67      0.75      1499\n",
      "          20       0.99      0.99      0.99      1499\n",
      "          21       0.79      0.82      0.80      1499\n",
      "          22       0.82      0.80      0.81      1499\n",
      "          23       0.94      1.00      0.97      1499\n",
      "          24       0.98      0.87      0.92      1499\n",
      "          25       0.57      0.30      0.39      1499\n",
      "          26       0.70      0.25      0.37      1499\n",
      "          27       0.89      0.71      0.79      1499\n",
      "          28       0.87      0.45      0.59      1499\n",
      "          29       0.70      0.75      0.73      1499\n",
      "          30       0.97      0.90      0.94      1499\n",
      "          31       0.75      0.93      0.83      1499\n",
      "          32       0.85      0.96      0.90      1499\n",
      "          33       0.87      0.46      0.60      1499\n",
      "          34       1.00      1.00      1.00      1499\n",
      "          35       0.83      0.86      0.85      1499\n",
      "          36       0.56      0.84      0.67      1499\n",
      "          37       0.79      0.78      0.79      1499\n",
      "          38       0.48      0.19      0.27      1499\n",
      "          39       0.64      0.77      0.70      1499\n",
      "          40       0.65      0.85      0.73      1499\n",
      "          41       0.80      0.31      0.45      1499\n",
      "          42       0.44      0.84      0.58      1499\n",
      "          43       0.81      0.82      0.81      1499\n",
      "          44       0.94      0.90      0.92      1499\n",
      "          45       0.79      0.62      0.69      1499\n",
      "          46       0.46      0.65      0.54      1499\n",
      "          47       0.94      0.48      0.63      1499\n",
      "          48       0.56      0.95      0.71      1499\n",
      "          49       0.73      0.77      0.75      1499\n",
      "\n",
      "    accuracy                           0.77     74950\n",
      "   macro avg       0.79      0.77      0.76     74950\n",
      "weighted avg       0.79      0.77      0.76     74950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = np.argmax(tf.nn.softmax(model3.predict(xt)).numpy(),axis=1)\n",
    "print(classification_report(yt,y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
